[{"title":"算法-排序-快速排序","url":"http://ilovenorth.cn/2020/03/08/算法-排序-快速排序/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"算法-排序-快速排序\"><a href=\"#算法-排序-快速排序\" class=\"headerlink\" title=\"算法-排序-快速排序\"></a>算法-排序-快速排序</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><h3 id=\"基本概念须知\"><a href=\"#基本概念须知\" class=\"headerlink\" title=\"基本概念须知\"></a>基本概念须知</h3><h4 id=\"1-经典快排\"><a href=\"#1-经典快排\" class=\"headerlink\" title=\"1. 经典快排\"></a>1. 经典快排</h4><blockquote>\n<p>每次只搞定一个位置的数</p>\n</blockquote>\n<ul>\n<li><p>把数组最后的数作为划分值</p>\n<p>  <img src=\"https://tva1.sinaimg.cn/large/00831rSTly1gcmmptw7qqj312206mt8i.jpg\" alt=\"\"></p>\n</li>\n<li><p>小于等于X的放左边，大于X的放右边</p>\n<p>  <img src=\"https://tva1.sinaimg.cn/large/00831rSTly1gcmmreulfjj313u06aglg.jpg\" alt=\"\"></p>\n</li>\n<li><p>然后，小于等于区域继续这么干，大于区域也这么干</p>\n<p>  <img src=\"https://tva1.sinaimg.cn/large/00831rSTly1gcmn25njr9j310u060wec.jpg\" alt=\"\"></p>\n</li>\n</ul>\n<h4 id=\"2-随机快排\"><a href=\"#2-随机快排\" class=\"headerlink\" title=\"2. 随机快排\"></a>2. 随机快排</h4><p>因为经典快排是每次取每一段数组最后一个数作为划分值，容易出现数据倾斜的情况。</p>\n<blockquote>\n<p>比如：1234567 7654321</p>\n</blockquote>\n<p>随机快排就是在经典快排的基础上，在取划分值这一步，进行调整。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">swap(arr, l + (<span class=\"keyword\">int</span>) (Math.random() * (r - l + <span class=\"number\">1</span>)), r);</span><br></pre></td></tr></table></figure>\n<p>l 和 r 分别为数组的左右邻接，这里不需要看懂，只需要理解这种取数逻辑。</p>\n<h4 id=\"3-改进后的随机快排\"><a href=\"#3-改进后的随机快排\" class=\"headerlink\" title=\"3. 改进后的随机快排\"></a>3. 改进后的随机快排</h4><p>在随机快排的基础上，维护一份数组，数组里记录每次等于划分值的左右下标，这样就可以一次定位多个数的位置。</p>\n<h3 id=\"code详解\"><a href=\"#code详解\" class=\"headerlink\" title=\"code详解\"></a>code详解</h3><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">quickSort</span><span class=\"params\">(<span class=\"keyword\">int</span>[] arr)</span> </span>&#123;</span><br><span class=\"line\">       <span class=\"keyword\">if</span> (arr == <span class=\"keyword\">null</span> || arr.length &lt; <span class=\"number\">2</span>) &#123;</span><br><span class=\"line\">           <span class=\"keyword\">return</span>;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       quickSort(arr, <span class=\"number\">0</span>, arr.length - <span class=\"number\">1</span>);</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">quickSort</span><span class=\"params\">(<span class=\"keyword\">int</span>[] arr, <span class=\"keyword\">int</span> l, <span class=\"keyword\">int</span> r)</span> </span>&#123;</span><br><span class=\"line\">       <span class=\"keyword\">if</span> (l &lt; r) &#123;</span><br><span class=\"line\">           <span class=\"comment\">// 这一步为随机快排的步骤 随机快排：防止数据倾斜 1234567 7654321</span></span><br><span class=\"line\">           swap(arr, l + (<span class=\"keyword\">int</span>) (Math.random() * (r - l + <span class=\"number\">1</span>)), r);</span><br><span class=\"line\"></span><br><span class=\"line\">           <span class=\"comment\">// 首先找到等于区域的下标</span></span><br><span class=\"line\">           <span class=\"comment\">// p[] : 长度为2</span></span><br><span class=\"line\">           <span class=\"comment\">// p[0] 为等于这次划分值区域的第一个数</span></span><br><span class=\"line\">           <span class=\"comment\">// p[1] 为等于这次划分值区域的最后一个数</span></span><br><span class=\"line\">           <span class=\"keyword\">int</span>[] p = partition(arr, l, r);</span><br><span class=\"line\"></span><br><span class=\"line\">           <span class=\"comment\">// 排序的范围为：L ~ (p[0] - 1)   (p[1] + 1) ~ R</span></span><br><span class=\"line\">           quickSort(arr, l, p[<span class=\"number\">0</span>] - <span class=\"number\">1</span>);</span><br><span class=\"line\">           quickSort(arr, p[<span class=\"number\">1</span>] + <span class=\"number\">1</span>, r);</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">int</span>[] partition(<span class=\"keyword\">int</span>[] arr, <span class=\"keyword\">int</span> l, <span class=\"keyword\">int</span> r) &#123;</span><br><span class=\"line\">       <span class=\"keyword\">int</span> less = l - <span class=\"number\">1</span>;</span><br><span class=\"line\">       <span class=\"keyword\">int</span> more = r;</span><br><span class=\"line\">       <span class=\"comment\">// 循环的前提一定是 l &lt; more</span></span><br><span class=\"line\">       <span class=\"keyword\">while</span> (l &lt; more) &#123;</span><br><span class=\"line\">           <span class=\"comment\">// 如果小于划分值r</span></span><br><span class=\"line\">           <span class=\"keyword\">if</span> (arr[l] &lt; arr[r]) &#123;</span><br><span class=\"line\">               <span class=\"comment\">// less+1 并与l交换 l++ 其实就是less永远都是对应在位置上已经确认的额最后一个比r小的数</span></span><br><span class=\"line\">               swap(arr, ++less, l++);</span><br><span class=\"line\">           <span class=\"comment\">// 如果大于划分值r</span></span><br><span class=\"line\">           &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (arr[l] &gt; arr[r]) &#123;</span><br><span class=\"line\">               <span class=\"comment\">// more-1 并与l交换 more就是永远都是对应在位置上已经确认的第一个比r大的数</span></span><br><span class=\"line\">               swap(arr, --more, l);</span><br><span class=\"line\">           &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">               <span class=\"comment\">// 如果等于划分值r 则l挪到下一个位置</span></span><br><span class=\"line\">               l++;</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       <span class=\"comment\">// 此时 more所在位置就是第一个大于划分值r的数的下标</span></span><br><span class=\"line\">       <span class=\"comment\">// 交换后 确定了r的位置（如果有多个相等的r 则一次确定好了多个位置）</span></span><br><span class=\"line\">       swap(arr, more, r);</span><br><span class=\"line\">       <span class=\"comment\">// 返回等于划分值区域的下标数组 数组里存的是等于区域的下标</span></span><br><span class=\"line\">       <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[] &#123; less + <span class=\"number\">1</span>, more &#125;;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n","categories":["算法"],"tags":["算法 排序"]},{"title":"算法-排序-堆","url":"http://ilovenorth.cn/2020/03/07/算法-排序-堆/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"算法-排序-堆\"><a href=\"#算法-排序-堆\" class=\"headerlink\" title=\"算法-排序-堆\"></a>算法-排序-堆</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><h3 id=\"基本概念须知\"><a href=\"#基本概念须知\" class=\"headerlink\" title=\"基本概念须知\"></a>基本概念须知</h3><ol>\n<li>堆 ==&gt; 完全二叉树，可以用数组来实现<font color=\"red\">逻辑上</font>的堆。</li>\n</ol>\n<p><img src=\"https://tva1.sinaimg.cn/large/00831rSTly1gcmeedw5qwj30zm0diaaj.jpg\" alt=\"\"></p>\n<ol start=\"2\">\n<li><p>通过数据下标找到其左右孩子以及父节点：</p>\n<ul>\n<li>左孩子：2 * i + 1</li>\n<li>右孩子：2 * i + 2</li>\n<li>父节点：i - 1 / 2</li>\n</ul>\n</li>\n<li><p>大根堆</p>\n<blockquote>\n<p>任意一颗树或子树的最大值都是树的头部</p>\n</blockquote>\n<p> <img src=\"https://tva1.sinaimg.cn/large/00831rSTly1gcmegqbturj31420dmmxo.jpg\" alt=\"\"></p>\n</li>\n<li><p>小根堆</p>\n<blockquote>\n<p> 任意一颗树或子树的最小值都是树的头部</p>\n</blockquote>\n<p> <img src=\"https://tva1.sinaimg.cn/large/00831rSTly1gcmehip9vqj313u0d0jru.jpg\" alt=\"\"></p>\n</li>\n</ol>\n<h3 id=\"堆排序思路概述\"><a href=\"#堆排序思路概述\" class=\"headerlink\" title=\"堆排序思路概述\"></a>堆排序思路概述</h3><ol>\n<li>先将堆调整为大根堆，那么此时 arr[0] 为最大元素</li>\n<li>让 arr[0] 与 arr[length - 1] 交换，那么此时arr[length - 1]为最大元素</li>\n<li>让数组整体的 length - 1 ，因为最大的元素已经在队尾，已经是有序的了，不需要考虑。剩下的数组继续调整为大根堆【此步为调整堆的大小，维护一个变量记为<font color=\"red\">需要继续排序的堆的大小</font>】</li>\n<li>重复 2 ~ 4</li>\n</ol>\n<h3 id=\"结合code详解\"><a href=\"#结合code详解\" class=\"headerlink\" title=\"结合code详解\"></a>结合code详解</h3><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">heapSort</span><span class=\"params\">(<span class=\"keyword\">int</span>[] arr)</span> </span>&#123;</span><br><span class=\"line\">       <span class=\"keyword\">if</span> (arr == <span class=\"keyword\">null</span> || arr.length &lt; <span class=\"number\">2</span>) &#123;</span><br><span class=\"line\">           <span class=\"keyword\">return</span>;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; arr.length; i++) &#123;</span><br><span class=\"line\">           <span class=\"comment\">// 将原数组调整为大根堆</span></span><br><span class=\"line\">           heapInsert(arr, i);</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       <span class=\"keyword\">int</span> size = arr.length;</span><br><span class=\"line\">       <span class=\"comment\">// 将大根堆的堆顶 移动到数组最后面 然后将size-1 准备将剩下的部分继续用来堆排序</span></span><br><span class=\"line\">       swap(arr, <span class=\"number\">0</span>, --size);</span><br><span class=\"line\">       <span class=\"comment\">// 开始进行堆排序 也就是基本思路的2~4</span></span><br><span class=\"line\">       <span class=\"keyword\">while</span> (size &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">           <span class=\"comment\">// 排序成功一次 也就意味一个最大的元素在堆顶arr[0]</span></span><br><span class=\"line\">           heapify(arr, <span class=\"number\">0</span>, size);</span><br><span class=\"line\">           <span class=\"comment\">// 1. 将arr[0]挪到此时数组的arr[size - 1]的位置</span></span><br><span class=\"line\">           <span class=\"comment\">// 2. 整体size再减一 作为下一次循环是 所提供的数组整体的大小</span></span><br><span class=\"line\">           swap(arr, <span class=\"number\">0</span>, --size);</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">heapInsert</span><span class=\"params\">(<span class=\"keyword\">int</span>[] arr, <span class=\"keyword\">int</span> index)</span> </span>&#123;</span><br><span class=\"line\">       <span class=\"comment\">// 当前i位置如果比父位置大</span></span><br><span class=\"line\">       <span class=\"keyword\">while</span> (arr[index] &gt; arr[(index - <span class=\"number\">1</span>) / <span class=\"number\">2</span>]) &#123;</span><br><span class=\"line\">           <span class=\"comment\">// 就交换</span></span><br><span class=\"line\">           swap(arr, index, (index - <span class=\"number\">1</span>) / <span class=\"number\">2</span>);</span><br><span class=\"line\">           <span class=\"comment\">// 然后i位置变为父位置</span></span><br><span class=\"line\">           index = (index - <span class=\"number\">1</span>) / <span class=\"number\">2</span>;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">heapify</span><span class=\"params\">(<span class=\"keyword\">int</span>[] arr, <span class=\"keyword\">int</span> index, <span class=\"keyword\">int</span> size)</span> </span>&#123;</span><br><span class=\"line\">       <span class=\"comment\">// 定位左孩子的下标</span></span><br><span class=\"line\">       <span class=\"keyword\">int</span> left = index * <span class=\"number\">2</span> + <span class=\"number\">1</span>;</span><br><span class=\"line\">       <span class=\"comment\">// 只要左孩子的下标小于数组大小</span></span><br><span class=\"line\">       <span class=\"keyword\">while</span> (left &lt; size) &#123;</span><br><span class=\"line\">           <span class=\"comment\">// 找到index中 左右孩子中较大的一个</span></span><br><span class=\"line\">           <span class=\"keyword\">int</span> largest = left + <span class=\"number\">1</span> &lt; size &amp;&amp; arr[left + <span class=\"number\">1</span>] &gt; arr[left] ? left + <span class=\"number\">1</span> : left;</span><br><span class=\"line\">           <span class=\"comment\">// 找到后 与index所在数组的值比较</span></span><br><span class=\"line\">           <span class=\"comment\">// largest记录其中较大的一个下标</span></span><br><span class=\"line\">           largest = arr[largest] &gt; arr[index] ? largest : index;</span><br><span class=\"line\">           <span class=\"comment\">// 如果下标相等 就跳出循环</span></span><br><span class=\"line\">           <span class=\"keyword\">if</span> (largest == index) &#123;</span><br><span class=\"line\">               <span class=\"keyword\">break</span>;</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\">           <span class=\"comment\">// 如果不相等 将两个值进行交换 实现较大的一个真实值在堆的结构上向上移动</span></span><br><span class=\"line\">           swap(arr, largest, index);</span><br><span class=\"line\">           <span class=\"comment\">// 向下遍历 以largest下标为起点</span></span><br><span class=\"line\">           index = largest;</span><br><span class=\"line\">           <span class=\"comment\">// 找到largest的左孩子 【下一次循环的比较条件就是找出largest的左孩子的左右孩子中较大的一个】</span></span><br><span class=\"line\">           left = index * <span class=\"number\">2</span> + <span class=\"number\">1</span>;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">swap</span><span class=\"params\">(<span class=\"keyword\">int</span>[] arr, <span class=\"keyword\">int</span> i, <span class=\"keyword\">int</span> j)</span> </span>&#123;</span><br><span class=\"line\">       <span class=\"keyword\">int</span> tmp = arr[i];</span><br><span class=\"line\">       arr[i] = arr[j];</span><br><span class=\"line\">       arr[j] = tmp;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n","categories":["算法"],"tags":["算法 排序"]},{"title":"2020 have fun.","url":"http://ilovenorth.cn/2020/01/17/2020 have fun/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"2020-have-fun\"><a href=\"#2020-have-fun\" class=\"headerlink\" title=\"2020 have fun.\"></a>2020 have fun.</h1><p>不知从什么时候起，每个新年朋友圈都会发一个have fun。<br>或许在我潜意识里，生活是否自得还是占很大权重的。</p>\n<p>从18年毕业，现在在北京也有一年半了，不能说有很好的规划，但是也是完成了自己一些的目标。</p>\n<p>想着自己的期望，奋斗的生活很美好，今年依然有着不同的目标，一个个去实现，就像玩游戏闯关一样，很有成就感。</p>\n<p>说到游戏，最近和我的发小玩的《泰拉瑞亚》很有意思。</p>\n<p>有些朋友，就拿我发小来说，快15年的交情，尽管他人在日本留学，有时几个月不联系一次，有时一聊就聊好几小时，19年我也失去了一个朋友，感情这种东西真的有趣，就像好多3A大作通了删、删了再下，但总有那么一款游戏，永远都会留在机器里。</p>\n<p>说到机器，3月份左右想组一个台式，这样就能和北方一起打猎了，到现在还没打上大贼龙。</p>\n<p>今年大学室友二哥结婚了，因为一些事情没能参加，也是有些遗憾的，这胖子居然第一个结婚了，神奇哈哈。</p>\n<p>没有以前多愁善感了，写着写着就觉得没什么话了，可能更多的情绪都在心里慢慢的淡了，淡了也好，都是些想不起来的东西，记着也没什么意思。</p>\n<p>老邢他们也没事惦记着我，让我有时心里很暖，但他想吃老八秘制小汉堡，让我觉得这个人很有问题。</p>\n<p>过年陪陪家人，更多也是陪陪我，和朋友聚一聚，和发小打个球，挺好。</p>\n<p>之前进澳洲代购传销ABM的一个女生现在也没信了，不知道怎么样了，人啊，还是多读读书挺好。刚才翻了翻，好像把我给删了 -。-</p>\n<p>年会中了MBP16 哈哈哈。</p>\n<p>和北方的新朋友一起搓麻，很开心 ✌️</p>\n","categories":["随笔"],"tags":["2020 心路历程"]},{"title":"BD-MapReduce9-MapReduce框架原理之MapReduce开发总结","url":"http://ilovenorth.cn/2019/11/10/BD-MapReduce9/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n\n<h1 id=\"BD-MapReduce9-MapReduce框架原理之MapReduce开发总结\"><a href=\"#BD-MapReduce9-MapReduce框架原理之MapReduce开发总结\" class=\"headerlink\" title=\"BD-MapReduce9-MapReduce框架原理之MapReduce开发总结\"></a>BD-MapReduce9-MapReduce框架原理之MapReduce开发总结</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><h2 id=\"一、MapReduce工作流程\"><a href=\"#一、MapReduce工作流程\" class=\"headerlink\" title=\"一、MapReduce工作流程\"></a>一、MapReduce工作流程</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7e6fujlh9j30re0d6q3u.jpg\" alt=\"\"></p>\n<h2 id=\"二、MapReduce开发总结\"><a href=\"#二、MapReduce开发总结\" class=\"headerlink\" title=\"二、MapReduce开发总结\"></a>二、MapReduce开发总结</h2><h3 id=\"1-输入数据接口：InputFormat\"><a href=\"#1-输入数据接口：InputFormat\" class=\"headerlink\" title=\"1. 输入数据接口：InputFormat\"></a>1. 输入数据接口：InputFormat</h3><ol>\n<li>默认使用的实现类是：TextInputFormat</li>\n<li>TextInputFormat的功能逻辑是：一次读一行文本，然后将该行的起始偏移量作为key，行内容作为value返回。</li>\n<li>KeyValueTextInputFormat每一行均为一条记录，被分隔符分割为key，value。默认分隔符是tab（\\t）。</li>\n<li>NlineInputFormat按照指定的行数N来划分切片。</li>\n<li>CombineTextInputFormat可以把多个小文件合并成一个切片处理，提高处理效率。</li>\n<li>用户还可以自定义InputFormat。</li>\n</ol>\n<h3 id=\"2-逻辑处理接口：Mapper\"><a href=\"#2-逻辑处理接口：Mapper\" class=\"headerlink\" title=\"2. 逻辑处理接口：Mapper\"></a>2. 逻辑处理接口：Mapper</h3><p>用户根据业务需求实现其中三个方法：map()   setup()   cleanup () </p>\n<h3 id=\"3-Partitioner分区\"><a href=\"#3-Partitioner分区\" class=\"headerlink\" title=\"3. Partitioner分区\"></a>3. Partitioner分区</h3><ol>\n<li>有默认实现 HashPartitioner，逻辑是根据key的哈希值和numReduces来返回一个分区号；key.hashCode()&amp;Integer.MAXVALUE % numReduces</li>\n<li>如果业务上有特别的需求，可以自定义分区。</li>\n</ol>\n<h3 id=\"4．Comparable排序\"><a href=\"#4．Comparable排序\" class=\"headerlink\" title=\"4．Comparable排序\"></a>4．Comparable排序</h3><ol>\n<li>当我们用自定义的对象作为key来输出时，就必须要实现WritableComparable接口，重写其中的compareTo()方法。</li>\n<li>部分排序：对最终输出的每一个文件进行内部排序。</li>\n<li>全排序：对所有数据进行排序，通常只有一个Reduce。</li>\n<li>二次排序：排序的条件有两个。</li>\n</ol>\n<h3 id=\"5．Combiner合并\"><a href=\"#5．Combiner合并\" class=\"headerlink\" title=\"5．Combiner合并\"></a>5．Combiner合并</h3><p>Combiner合并可以提高程序执行效率，减少IO传输。但是使用时必须不能影响原有的业务处理结果。</p>\n<h3 id=\"6．Reduce端分组：GroupingComparator\"><a href=\"#6．Reduce端分组：GroupingComparator\" class=\"headerlink\" title=\"6．Reduce端分组：GroupingComparator\"></a>6．Reduce端分组：GroupingComparator</h3><p>在Reduce端对key进行分组。应用于：在接收的key为bean对象时，想让一个或几个字段相同（全部字段比较不相同）的key进入到同一个reduce方法时，可以采用分组排序。</p>\n<h3 id=\"7．逻辑处理接口：Reducer\"><a href=\"#7．逻辑处理接口：Reducer\" class=\"headerlink\" title=\"7．逻辑处理接口：Reducer\"></a>7．逻辑处理接口：Reducer</h3><p>用户根据业务需求实现其中三个方法：reduce()   setup()   cleanup () </p>\n<h3 id=\"8-输出数据接口：OutputFormat\"><a href=\"#8-输出数据接口：OutputFormat\" class=\"headerlink\" title=\"8. 输出数据接口：OutputFormat\"></a>8. 输出数据接口：OutputFormat</h3><ol>\n<li>默认实现类是TextOutputFormat，功能逻辑是：将每一个KV对，向目标文本文件输出一行。</li>\n<li>将SequenceFileOutputFormat输出作为后续 MapReduce任务的输入，这便是一种好的输出格式，因为它的格式紧凑，很容易被压缩。</li>\n<li>用户还可以自定义OutputFormat。</li>\n</ol>\n","categories":["Hadoop-MR"],"tags":[]},{"title":"BD-Yarn-Yarn资源调度器之Yarn工作机制","url":"http://ilovenorth.cn/2019/11/07/BD-Yarn-Yarn资源调度器之Yarn工作机制/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"BD-Yarn-Yarn资源调度器之Yarn工作机制\"><a href=\"#BD-Yarn-Yarn资源调度器之Yarn工作机制\" class=\"headerlink\" title=\"BD-Yarn-Yarn资源调度器之Yarn工作机制\"></a>BD-Yarn-Yarn资源调度器之Yarn工作机制</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><ol>\n<li>基本架构</li>\n<li>工作机制（作业提交流程）</li>\n</ol>\n<h2 id=\"基本架构\"><a href=\"#基本架构\" class=\"headerlink\" title=\"基本架构\"></a>基本架构</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7z0nlllpoj30sr0een03.jpg\" alt=\"\"></p>\n<h2 id=\"工作机制（作业提交流程）\"><a href=\"#工作机制（作业提交流程）\" class=\"headerlink\" title=\"工作机制（作业提交流程）\"></a>工作机制（作业提交流程）</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7yzkzcsenj310z08s0tw.jpg\" alt=\"\"></p>\n<p>在Driver中最后一步，我们调用waitForCompletion()后，会向ResourceManager申请一个ApplicationId，有了这个Id，就知道Job要用的临时文件提交到哪个文件的下面（我们临时申请的工作目录）。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7yzo10l7pj311u0k476h.jpg\" alt=\"\"></p>\n<p>提交后，如果是HDFS，我们会看到在根目录生成了一个tmp的文件夹，在我们临时申请的工作目录，会放着这三个文件。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7yzrr028wj31130k340y.jpg\" alt=\"\"></p>\n<p>提交完了以后，就会告诉yarn，job任务提交完了，申请一个AppMaster负责跟进我们的任务</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7yztoedwuj311h0k6jud.jpg\" alt=\"\"></p>\n<p>所有的自愿申请进入到RM，都会被包装成一个个Task，Yarn收到这些Task之后，就把Task扔到调度队列里（稍后再说），根据自己的调度逻辑来判断到底需不需要执行。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7yzw8j6trj31180k9whl.jpg\" alt=\"\"></p>\n<p>假设按照规则，轮到这个Task执行了，就会找一个NM来接收这个任务。假如我们AppMaster需要2核1G的资源，那么就会找一个有2核1G的NM来接收它。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7yzyjm23oj31100kcq6b.jpg\" alt=\"\"></p>\n<p>NM就会运行Container（2核1G），里面跑着这个AppMaster。AppMaster出现以后，就以任务为己任，因为我们会发现其实Yarn并不管我们跑的是什么任务、什么数据等等，只有AppMaster管。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7z0296iawj312l0k9djk.jpg\" alt=\"\"></p>\n<p>下一步开始，AppMaster下载job资源到本地，然后根据任务切片信息，申请相应数量的MapTask。申请这个过程会被包装成一个Task进入队列，等着调度。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7z04xap8gj315l0kajvu.jpg\" alt=\"\"></p>\n<p>当轮到这个Task的时候，就会启动相应数量的Container来执行这两个MapTask（假如我们有两个切片），</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7z07hs168j315t0k7jwb.jpg\" alt=\"\"></p>\n<p>MapTask的执行是由AppMaster把jar包和启动脚本发送过去，然后开始执行。出现了输出文件（0、1为分区），接着就会回收这两个Container。文件出来，RM、NM都不关心这个文件，只有AppMaster关心，AppMaster会一直问这个MapTask执行到哪了。当所有的MapTask执行到100%Lee，也就开始下一步了。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7z0c0sf8tj315g0li0yi.jpg\" alt=\"\"></p>\n<p>根据我们程序里写的ReduceTask的数量，来申请相应数量的ReduceTask。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7z0f26hyjj315l0lagro.jpg\" alt=\"\"></p>\n<p>每个ReduceTask接收相应分区的数据。处理完的结果会写回到HDFS。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7z0gdawf3j315s0l80yy.jpg\" alt=\"\"></p>\n<p>都搞定以后，Container就会被回收，AppMaster发现都执行了完了，会向RM注销自己。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7z0gywkszj30k40iwgoh.jpg\" alt=\"\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7z0lhok8uj30vz0u0qd5.jpg\" alt=\"\"></p>\n","categories":["Hadoop-Yarn"],"tags":[]},{"title":"BD-MapReduce8-MapReduce框架原理之ReduceTask工作机制","url":"http://ilovenorth.cn/2019/11/05/BD-MapReduce8-MapReduce框架原理之ReduceTask工作机制/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"BD-MapReduce8-MapReduce框架原理之ReduceTask工作机制\"><a href=\"#BD-MapReduce8-MapReduce框架原理之ReduceTask工作机制\" class=\"headerlink\" title=\"BD-MapReduce8-MapReduce框架原理之ReduceTask工作机制\"></a>BD-MapReduce8-MapReduce框架原理之ReduceTask工作机制</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><h2 id=\"一、MapReduce工作流程\"><a href=\"#一、MapReduce工作流程\" class=\"headerlink\" title=\"一、MapReduce工作流程\"></a>一、MapReduce工作流程</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7e6fujlh9j30re0d6q3u.jpg\" alt=\"\"></p>\n<h2 id=\"二、ReduceTask工作机制\"><a href=\"#二、ReduceTask工作机制\" class=\"headerlink\" title=\"二、ReduceTask工作机制\"></a>二、ReduceTask工作机制</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7yvt99jhxj30sp0dkq5n.jpg\" alt=\"\"></p>\n<h3 id=\"Copy-阶段\"><a href=\"#Copy-阶段\" class=\"headerlink\" title=\"Copy 阶段\"></a>Copy 阶段</h3><p>ReduceTask从各个MapTask上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。</p>\n<h3 id=\"Merge阶段\"><a href=\"#Merge阶段\" class=\"headerlink\" title=\"Merge阶段\"></a>Merge阶段</h3><p>在远程拷贝数据的同时，ReduceTask启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。</p>\n<h3 id=\"Sort阶段\"><a href=\"#Sort阶段\" class=\"headerlink\" title=\"Sort阶段\"></a>Sort阶段</h3><p>按照MapReduce语义，用户编写reduce()函数输入数据是按key进行聚集的一组数据。为了将key相同的数据聚在一起，Hadoop采用了基于排序的策略。由于各个MapTask已经实现对自己的处理结果进行了局部排序，因此，ReduceTask只需对所有数据进行一次归并排序即可。</p>\n<h3 id=\"Reduce阶段\"><a href=\"#Reduce阶段\" class=\"headerlink\" title=\"Reduce阶段\"></a>Reduce阶段</h3><p>reduce()函数将计算结果写到HDFS上。</p>\n<h3 id=\"设置ReduceTask并行度（个数）\"><a href=\"#设置ReduceTask并行度（个数）\" class=\"headerlink\" title=\"设置ReduceTask并行度（个数）\"></a>设置ReduceTask并行度（个数）</h3><p>ReduceTask的并行度同样影响整个Job的执行并发度和执行效率，但与MapTask的并发数由切片数决定不同，ReduceTask数量的决定是可以直接手动设置：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 默认值是1，手动设置为4</span></span><br><span class=\"line\">job.setNumReduceTasks(<span class=\"number\">4</span>);</span><br></pre></td></tr></table></figure>\n","categories":["Hadoop-MR"],"tags":[]},{"title":"BD-MapReduce7-MapReduce框架原理之MapTask工作机制","url":"http://ilovenorth.cn/2019/11/04/BD-MapReduce7-MapReduce框架原理之OutputFormat数据输出/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"BD-MapReduce7-MapReduce框架原理之MapTask工作机制\"><a href=\"#BD-MapReduce7-MapReduce框架原理之MapTask工作机制\" class=\"headerlink\" title=\"BD-MapReduce7-MapReduce框架原理之MapTask工作机制\"></a>BD-MapReduce7-MapReduce框架原理之MapTask工作机制</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><h2 id=\"一、MapReduce工作流程\"><a href=\"#一、MapReduce工作流程\" class=\"headerlink\" title=\"一、MapReduce工作流程\"></a>一、MapReduce工作流程</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7e6fujlh9j30re0d6q3u.jpg\" alt=\"\"></p>\n<h2 id=\"二、MapTask工作机制\"><a href=\"#二、MapTask工作机制\" class=\"headerlink\" title=\"二、MapTask工作机制\"></a>二、MapTask工作机制</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7yvis2mmtj30sd0emq64.jpg\" alt=\"\"></p>\n<h3 id=\"1-Read-阶段\"><a href=\"#1-Read-阶段\" class=\"headerlink\" title=\"1. Read 阶段\"></a>1. Read 阶段</h3><p>MapTask通过用户编写的RecordReader，从输入InputSplit中解析出一个个key/value。</p>\n<h3 id=\"2-Map-阶段\"><a href=\"#2-Map-阶段\" class=\"headerlink\" title=\"2. Map 阶段\"></a>2. Map 阶段</h3><p>该节点主要是将解析出的key/value交给用户编写map()函数处理，并产生一系列新的key/value。</p>\n<h3 id=\"3-Collect-收集阶段\"><a href=\"#3-Collect-收集阶段\" class=\"headerlink\" title=\"3. Collect 收集阶段\"></a>3. Collect 收集阶段</h3><p>在用户编写map()函数中，当数据处理完成后，一般会调用OutputCollector.collect()输出结果。在该函数内部，它会将生成的key/value分区（调用Partitioner），并写入一个环形内存缓冲区中。</p>\n<h3 id=\"4-Spill-阶段\"><a href=\"#4-Spill-阶段\" class=\"headerlink\" title=\"4. Spill 阶段\"></a>4. Spill 阶段</h3><p>即“溢写”，当环形缓冲区满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。</p>\n<h4 id=\"溢写阶段详情：\"><a href=\"#溢写阶段详情：\" class=\"headerlink\" title=\"溢写阶段详情：\"></a>溢写阶段详情：</h4><ol>\n<li><p>利用快速排序算法对缓存区内的数据进行排序，排序方式是，先按照分区编号Partition进行排序，然后按照key进行排序。这样，经过排序后，数据以分区为单位聚集在一起，且同一分区内所有数据按照key有序。</p>\n</li>\n<li><p>按照分区编号由小到大依次将每个分区中的数据写入任务工作目录下的临时文件output/spillN.out（N表示当前溢写次数）中。如果用户设置了Combiner，则写入文件之前，对每个分区中的数据进行一次聚集操作。</p>\n</li>\n<li><p>将分区数据的元信息写到内存索引数据结构SpillRecord中，其中每个分区的元信息包括在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过1MB，则将内存索引写到文件output/spillN.out.index中。</p>\n</li>\n</ol>\n<h3 id=\"5-Combine-阶段\"><a href=\"#5-Combine-阶段\" class=\"headerlink\" title=\"5. Combine 阶段\"></a>5. Combine 阶段</h3><p>当所有数据处理完成后，MapTask对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。</p>\n<p>当所有数据处理完后，MapTask会将所有临时文件合并成一个大文件，并保存到文件output/file.out中，同时生成相应的索引文件output/file.out.index。</p>\n<p>在进行文件合并过程中，MapTask以分区为单位进行合并。对于某个分区，它将采用多轮递归合并的方式。每轮合并io.sort.factor（默认10）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件。</p>\n<p>让每个MapTask最终只生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机读取带来的开销。</p>\n","categories":["Hadoop-MR"],"tags":[]},{"title":"BD-MapReduce6-MapReduce框架原理之排序、合并、分组","url":"http://ilovenorth.cn/2019/11/03/BD-MapReduce6-MapReduce框架原理之排序、合并、分组/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"BD-MapReduce6-MapReduce框架原理之排序、合并、分组\"><a href=\"#BD-MapReduce6-MapReduce框架原理之排序、合并、分组\" class=\"headerlink\" title=\"BD-MapReduce6-MapReduce框架原理之排序、合并、分组\"></a>BD-MapReduce6-MapReduce框架原理之排序、合并、分组</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><ol>\n<li>WritableComparable排序</li>\n<li>Combiner合并</li>\n<li>GroupingComparator分组</li>\n<li>Shuffle机制查缺补漏</li>\n</ol>\n<h2 id=\"一、WritableComparable排序\"><a href=\"#一、WritableComparable排序\" class=\"headerlink\" title=\"一、WritableComparable排序\"></a>一、WritableComparable排序</h2><h3 id=\"1-1-排序概述\"><a href=\"#1-1-排序概述\" class=\"headerlink\" title=\"1.1 排序概述\"></a>1.1 排序概述</h3><p><strong><font color=\"red\">排序是MapReduce框架中最重要的操作之一。<br></font></strong></p>\n<p>MapTask和ReduceTask均会对数据<font color=\"red\">按照key</font>进行排序。该操作属于Hadoop的默认行为。<font color=\"red\">任何应用程序中的数据均会被排序，而不管逻辑上是否需要。</font></p>\n<p>默认排序是按照<font color=\"red\">字典顺序排序</font>，且实现该排序的方法是<font color=\"red\">快速排序.</font></p>\n<p>对于MapTask，它会将处理的结果暂时放到环形缓冲区中，<font color=\"red\">当环形缓冲区使用率达到一定阈值后，再对缓冲区中的数据进行一次快速排序</font>，并将这些有序数据溢写到磁盘上，而当数据处理完毕后，它会<font color=\"red\">对磁盘上所有文件进行归并排序。</font></p>\n<p>对于ReduceTask，它从每个MapTask上远程拷贝相应的数据文件，如果文件大小超过一定阈值，则溢写磁盘上，否则存储在内存中。如果磁盘上文件数目达到一定阈值，则进行一次归并排序以生成一个更大文件；如果内存中文件大小或者数目超过一定阈值，则进行一次合并后将数据溢写到磁盘上。当所有数据拷贝完毕后，<font color=\"red\">ReduceTask统一对内存和磁盘上的所有数据进行一次归并排序。</font></p>\n<h3 id=\"1-2-排序分类\"><a href=\"#1-2-排序分类\" class=\"headerlink\" title=\"1.2 排序分类\"></a>1.2 排序分类</h3><p><strong>1. 部分排序：</strong>MapReduce根据输入记录的键对数据集排序。保证输出的每个文件内部有序。<br><strong>2. 全排序：</strong>最终输出结果只有一个文件，且文件内部有序。实现方式是只设置一个ReduceTask。但该方法在处理大型文件时效率极低，因为一台机器处理所有文件，完全丧失了MapReduce所提供的并行架构。<br><strong>3. 辅助排序：（GroupingComparator分组）：</strong>在Reduce端对key进行分组。应用于：在接收的key为bean对象时，想让一个或几个字段相同（全部字段比较不相同）的key进入到同一个reduce方法时，可以采用分组排序。</p>\n<p><strong>4. 二次排序：</strong>在自定义排序过程中，如果compareTo中的判断条件为两个即为二次排序。</p>\n<h2 id=\"二、Combiner合并\"><a href=\"#二、Combiner合并\" class=\"headerlink\" title=\"二、Combiner合并\"></a>二、Combiner合并</h2><ol>\n<li>Combiner是MR程序中Mapper和Reducer之外的一种组件。</li>\n<li>Combiner组件的父类就是Reducer。</li>\n<li>Combiner和Reducer的区别在于运行的位置<ul>\n<li><font color=\"red\">Combiner是在每一个MapTask所在的节点运行;</font></li>\n<li><font color=\"red\">Reducer是接收全局所有Mapper的输出结果；</font></li>\n</ul>\n</li>\n<li>Combiner的意义就是对每一个MapTask的输出进行局部汇总，以减小网络传输量。</li>\n<li><font color=\"red\">Combiner能够应用的前提是不能影响最终的业务逻辑，</font>而且，Combiner的输出kv应该跟Reducer的输入kv类型要对应起来。<font color=\"red\">Combiner输入输出类型必须一样。</font>\n\n</li>\n</ol>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7u93ttqkgj30os03q3yp.jpg\" alt=\"\"></p>\n<h2 id=\"三、GroupingComparator分组\"><a href=\"#三、GroupingComparator分组\" class=\"headerlink\" title=\"三、GroupingComparator分组\"></a>三、GroupingComparator分组</h2><p>对Reduce阶段的数据根据某一个或几个字段进行分组。</p>\n<h2 id=\"四、Shuffle机制查缺补漏\"><a href=\"#四、Shuffle机制查缺补漏\" class=\"headerlink\" title=\"四、Shuffle机制查缺补漏\"></a>四、Shuffle机制查缺补漏</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7t1sbljalj30q00ax75f.jpg\" alt=\"\"></p>\n<p>我们知道Map方法出来的数据，首先写到环形缓冲区，当缓冲区满了就会发生溢写，溢写之前要先发生分区和排序。<br>数据进入缓冲区之前是&lt;K,V&gt;，当数据进入缓冲区的时候会获得一个分区号P，显示为&lt;K,V,P&gt;，然后这个数据进入缓冲区，注意，此时只是获得分区号，并没有进行物理分区。    </p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7t1udhqi0j30xg0ahjsz.jpg\" alt=\"\"></p>\n<p>物理的分区发生在缓冲区满了需要写磁盘的时候，先按照分区号进行排序，分区号相同的再按Key进行排序(实际上分区排序是一个过程，也就是二次排序)。排完的结果是相同的分区在一起并且区内又序。</p>\n<p>分区排序后，在落盘前，如果我们启用了Combiner，这个数据在落盘前会先到Combiner中进行合并（把Key值相同的合并，\\&lt;a,1&gt; \\&lt;a,1&gt; —-&gt; \\&lt;a,2&gt;），合并完成后再真正的落盘。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7t1yyyevsj315u0ceadg.jpg\" alt=\"\"></p>\n<p>会多次放生溢写生成的文件会通过归并排序之后，在Combiner中合并（压缩以后再说），最终落到磁盘上。这就是MapTask最终的输出文件，这个文件的特点就是分区且区内有序。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7u3rgstmcj31600llwjj.jpg\" alt=\"\"></p>\n<p>图片上有两个，假设我们有N个MapTask，每个MapTask分了3个区（1区、2区、3区），最后生成了N个文件，每个文件3个qu且区内有序。然后启用3个ReduceTask，ReduceTask与MapTask数量并没有直接关系。<font color=\"red\">每个ReduceTask都会处理所有MapTask相应分区的数据。</font>ReduceTask在Reduce端有一个内存缓存，这些数据以序列化的形式（文件）最开始都放在内存缓存中，如果缓存满了才用磁盘。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7t24yn8ycj315v0lh7a3.jpg\" alt=\"\"></p>\n<p>最后我们把这是文件进行了归并排序，合成了一整个的输出文件，这个文件的特点就是按照Key有序，下一步对文件进行分组（自定义规则，注意排序的粒度一定要比分组的粒度细），并放到Reduce方法中，</p>\n<p><strong>接下来说一下缓冲区</strong>    </p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7u43e5ibkj30qr0913zi.jpg\" alt=\"\"></p>\n<p>所谓的环形缓冲区，好处是没头没尾，从哪里写入都一样。假如我们中正中间开始写，顺时针写KV，逆时针写索引。<br><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7u84ilt40j30bb098q3i.jpg\" alt=\"\"></p>\n<p>这个索引就是KV在环形缓冲区的位置索引。一直写，直到写到80%的时候就开始溢写，在溢写的时候，同样会有新的数据会进入缓冲区，这时就会从缓冲区剩下的20%中选择一点写入缓冲区。逆时针写KV，顺时针写索引。80%的数据在溢写腾空缓冲区的速度还是挺快的。而且这个大小是可以根据实际情况进行设置的，默认是100M的0.8。</p>\n<p>排序就发生在环形缓冲区。在排序的时候，如果KV1和KV2通过比较需要交换顺序，不直接移动右侧的数据，而是交换他们的索引值，因为索引占用很小，这样可以节省IO。排好序后，根据索引的序列开始落盘，通过索引找到对应的数据。</p>\n<p>学会手画。</p>\n","categories":["Hadoop-MR"],"tags":[]},{"title":"BD-MapReduce5-MapReduce框架原理之Shuffle机制","url":"http://ilovenorth.cn/2019/11/02/BD-MapReduce5-MapReduce框架原理之Shuffle机制/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"BD-MapReduce3-MapReduce框架原理之Shuffle机制\"><a href=\"#BD-MapReduce3-MapReduce框架原理之Shuffle机制\" class=\"headerlink\" title=\"BD-MapReduce3-MapReduce框架原理之Shuffle机制\"></a>BD-MapReduce3-MapReduce框架原理之Shuffle机制</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><ol>\n<li>MapReduce工作流程</li>\n<li>Partition分区</li>\n<li>Shuffle 机制</li>\n</ol>\n<h2 id=\"一、MapReduce工作流程\"><a href=\"#一、MapReduce工作流程\" class=\"headerlink\" title=\"一、MapReduce工作流程\"></a>一、MapReduce工作流程</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7e6fujlh9j30re0d6q3u.jpg\" alt=\"\"></p>\n<h2 id=\"二、Partition分区\"><a href=\"#二、Partition分区\" class=\"headerlink\" title=\"二、Partition分区\"></a>二、Partition分区</h2><p>给数据打标签，告诉数据去哪个ReduceTask。</p>\n<h3 id=\"2-1-问题引出\"><a href=\"#2-1-问题引出\" class=\"headerlink\" title=\"2.1 问题引出\"></a>2.1 问题引出</h3><p>要求将统计结果<font color=\"red\">按照条件输出到不同文件中（分区）</font>。比如：将统计结果按照手机归属地不同省份输出到不同文件中（分区）</p>\n<h3 id=\"2-2-默认Partitioner分区\"><a href=\"#2-2-默认Partitioner分区\" class=\"headerlink\" title=\"2.2 默认Partitioner分区\"></a>2.2 默认Partitioner分区</h3><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">HashPartitioner</span>&lt;<span class=\"title\">K</span>, <span class=\"title\">V</span>&gt; <span class=\"keyword\">extends</span> <span class=\"title\">Partitioner</span>&lt;<span class=\"title\">K</span>, <span class=\"title\">V</span>&gt; </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">int</span> <span class=\"title\">getPartition</span><span class=\"params\">(K key, V value, <span class=\"keyword\">int</span> numReduceTasks)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>默认分区是根据key的hashCode对ReduceTasks个数取模得到的。用户没法控制哪个key存储到哪个分区。</p>\n<h3 id=\"2-3-自定义Partitioner步骤\"><a href=\"#2-3-自定义Partitioner步骤\" class=\"headerlink\" title=\"2.3 自定义Partitioner步骤\"></a>2.3 自定义Partitioner步骤</h3><ol>\n<li>自定义类继承Partitioner，重写getPartition()方法</li>\n</ol>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CustomPartitioner</span> <span class=\"keyword\">extends</span> <span class=\"title\">Partitioner</span>&lt;<span class=\"title\">Text</span>, <span class=\"title\">FlowBean</span>&gt; </span>&#123;</span><br><span class=\"line\"> \t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">int</span> <span class=\"title\">getPartition</span><span class=\"params\">(Text key, FlowBean value, <span class=\"keyword\">int</span> numPartitions)</span> </span>&#123;</span><br><span class=\"line\">          <span class=\"comment\">// 控制分区代码逻辑</span></span><br><span class=\"line\">    … …</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> partition;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>在Job驱动中，设置自定义Partitioner</li>\n</ol>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">job.setPartitionerClass(CustomPartitioner<span class=\"class\">.<span class=\"keyword\">class</span>)</span>;</span><br></pre></td></tr></table></figure>\n<ol start=\"3\">\n<li>自定义Partition后，要根据自定义Partitioner的逻辑设置相应数量的ReduceTask</li>\n</ol>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">job.setNumReduceTasks(<span class=\"number\">5</span>);</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-4-分区总结\"><a href=\"#2-4-分区总结\" class=\"headerlink\" title=\"2.4 分区总结\"></a>2.4 分区总结</h3><ol>\n<li><p>如果ReduceTask的数量&gt; getPartition的结果数，则会多产生几个空的输出文件part-r-000xx；</p>\n</li>\n<li><p>如果1&lt;ReduceTask的数量&lt;getPartition的结果数，则有一部分分区数据无处安放，会Exception；</p>\n</li>\n<li><p>如果ReduceTask的数量=1，则不管MapTask端输出多少个分区文件，最终结果都交给这一个ReduceTask，最终也就只会产生一个结果文件 part-r-00000；</p>\n</li>\n<li><p>分区号必须从零开始，逐一累加。</p>\n</li>\n</ol>\n<h3 id=\"2-5-案例分析\"><a href=\"#2-5-案例分析\" class=\"headerlink\" title=\"2.5 案例分析\"></a>2.5 案例分析</h3><p>例如：假设自定义分区数为5，则</p>\n<ol>\n<li>job.setNumReduceTasks(1);=======&gt;会正常运行，只不过会产生一个输出文件</li>\n<li>job.setNumReduceTasks(2);=======&gt;会报错</li>\n<li>job.setNumReduceTasks(6);=======&gt;大于5，程序会正常运行，会产生空文件</li>\n</ol>\n<h2 id=\"二、Shuffle-机制\"><a href=\"#二、Shuffle-机制\" class=\"headerlink\" title=\"二、Shuffle 机制\"></a>二、Shuffle 机制</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7t1sbljalj30q00ax75f.jpg\" alt=\"\"></p>\n<p>我们知道，缓冲区会存在满了的情况，如果满了就写到磁盘上，把缓冲区再腾出来。在落盘之前会完成<strong><em>分区和排序的工作。</em></strong></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7t1udhqi0j30xg0ahjsz.jpg\" alt=\"\"></p>\n<p>分区文件的特点：分区且区内有序。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7t1vsjh74j30x90ae40t.jpg\" alt=\"\"></p>\n<p>多次满了落盘的时候，会生成多个分区文件。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7t1wv0c6wj315o0a441e.jpg\" alt=\"\"></p>\n<p>按照分区进行归并排序。（Combiner我们回头再说）</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7t1yyyevsj315u0ceadg.jpg\" alt=\"\"></p>\n<p>归并完了的输出文件特点是依然是分区且区内有序（就是一个MapTask的输出）。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7t20lc1q0j315h0lgwiw.jpg\" alt=\"\"></p>\n<p>多个MapTask就会生成多个分区且区内有序的输出文件。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7t24ct26wj315i0ljdkv.jpg\" alt=\"\"></p>\n<p>分区1的文件会交给ReduceTask1，同样MapTask2的分区1的文件也会交给ReduceTask1。分区2同理，这里就不展示了。<br>ReduceTask1拿到文件的特点是，每个文件都是有序的。而且这些文件首先是放在Reduce端的内存缓存中的，如果缓存满了才用磁盘。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7t24yn8ycj315v0lh7a3.jpg\" alt=\"\"></p>\n<p>ReduceTask1接着对文件进行归并排序合成一整个输出文件（按照Key有序）、分组、输出到Reduce方法里，通过OutPutFormat输出到分区文件中。如果我们有两个ReduceTask，也就会输出两个分区文件，一个ReduceTask对应一个输出文件</p>\n","categories":["Hadoop-MR"],"tags":[]},{"title":"BD-MapReduce4-MapReduce框架原理之MapReduce工作流程","url":"http://ilovenorth.cn/2019/11/01/BD-MapReduce4-MapReduce框架原理之MapReduce工作流程/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"BD-MapReduce3-MapReduce框架原理之MapReduce工作流程\"><a href=\"#BD-MapReduce3-MapReduce框架原理之MapReduce工作流程\" class=\"headerlink\" title=\"BD-MapReduce3-MapReduce框架原理之MapReduce工作流程\"></a>BD-MapReduce3-MapReduce框架原理之MapReduce工作流程</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><ol>\n<li>MapReduce工作流程</li>\n</ol>\n<h2 id=\"一、MapReduce工作流程\"><a href=\"#一、MapReduce工作流程\" class=\"headerlink\" title=\"一、MapReduce工作流程\"></a>一、MapReduce工作流程</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7e6fujlh9j30re0d6q3u.jpg\" alt=\"\"></p>\n<p>上一篇文章我们讲了InputFormat阶段的事情，这篇文章我们重点介绍一下MR的工作流程。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7rq6mvpqej30hx0e8wf9.jpg\" alt=\"\"></p>\n<p>首先，客户端在提交前，会先获取待处理数据的信息，然后根据这些信息，对文件进行切片。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7rq8wub04j30is0fb75o.jpg\" alt=\"\"></p>\n<p>客户端先通知一下Yarn，然后Yarn会返回一个ID，客户端再去完成提交信息，包括切片信息、任务配置的xml、自己的jar包。一并提交给Yarn，Yarn是管理资源分配的，所以Yarn根据切片信息得知需要分配多少资源，一个切片对应一个MapTask，所以Yarn就会计算出MapTask的数量。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7rqemskvxj30h20lgwg9.jpg\" alt=\"\"></p>\n<p>根据切片规则，我们得知会有两个切片，这里我们以第一个切片为例，讲解工作流程。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7rqfrokpuj30i00lh40p.jpg\" alt=\"\"></p>\n<p>MapTask1拿到第一个切片的数据后，它调用InputFormat生成一个RecordReader，RecordReader就会把这个MapTask处理的这一个切片变成KV值。所以一个切片对应一个MapTask，一个MapTask对应RecordReader，也就是说一个RecordReader只处理一个切片。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7rqxbyyrfj30h80lemzl.jpg\" alt=\"\"></p>\n<p>生成KV值，交给了Mapper，Mapper中写的是任务的核心逻辑代码，逻辑处理完成以后，通过一步<strong><em>context.write(k,v)</em></strong>写给了框架。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">map</span><span class=\"params\">(KEYIN key, VALUEIN value, </span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                   Context context)</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">  context.write((KEYOUT) key, (VALUEOUT) value);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>但是这种说法很糙，我们具体说一下。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7rr2rwrszj30qd0lj77j.jpg\" alt=\"\"></p>\n<p><strong><em>context.write(k,v)</em></strong>经过<strong><em>outputCollector</em></strong>将KV数据写到了环形缓冲区，这个环形缓冲区我们以后会说。这里简单理解，缓冲区就是临时存一下数据，而且缓冲区会存在满了的情况，如果满了就写到磁盘上，把缓冲区再腾出来。</p>\n<p>根据文章最开始的那个图我们知道，从Mapper出来到Reducer的过程叫Shuffle，Shuffle阶段完成的工作就是分组。</p>\n<p>目前这个KV对是散乱的，再到Reducer之前把KV对都分好组，怎么做？<br>最容易想到的就是遍历Key，对于java来说是可以的，但这么做的一个非常重要的前提是：数据必须都在内存里。在大数据背景下，是很难做到把数据都放到内存里。那么MapRudece的思路是什么呢？就是全排序。从Mapper出来的数据，按照Key做了一个全排序，也就自然而然的完成了分组（相同key都在一起，前一个与后一个相等，就在一组）。<br>那么新的问题，大数据背景下，如何全排序？</p>\n<p>因为没法把全部数据都放到内存中进行排序，所以把数据分块对局部进行排序，每个局部都是key有序的，当把这些局部合并成一个整体的时候，用的是归并排序。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7sw3siitzj315w0le0ww.jpg\" alt=\"\"></p>\n<p>回到之前说的<strong><em>如果满了就写到磁盘上，把缓冲区再腾出来</em></strong>，当缓冲区满了的时候会开始写磁盘，在写磁盘之前，首先会在内存中完成一次排序工作。分区我们下面的文章会讲。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7sw76kp3gj315t0lh42z.jpg\" alt=\"\"></p>\n<p>排序之后，把数据落到一个文件上，这个文件是内部有序的。此时，缓冲区还是在存数据的，依然会满，就会再生成一个文件，以此类推，每一个文件都是内部有序的。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7sw98aut0j31600lf798.jpg\" alt=\"\"></p>\n<p>然后进行归并排序。到了这一步，Map所有输入的数据都变成了一个输出文件，这里，我们的MapTask阶段就结束了，他最后生成一个文件，并且这个文件按照Key的大小排好序了。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7swdb0njbj314p0l93zt.jpg\" alt=\"\"></p>\n<p>到此，我们两个MapTask输出的文件都排好了序，下一步就启动一个Reducer。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7swsuxo3ij31460kvq6t.jpg\" alt=\"\"></p>\n<p>我们只看上面的Reducer，下面的先不管。MapTask1和MapTask2的文件都发给ReduceTask1，这些文件的特点是有序。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7swv2rx2cj310d0ksgom.jpg\" alt=\"\"></p>\n<p>接下来，ReduceTask会对这些文件再进行一次排序，合并后的文件依然为Key有序。到此，从Map输入数据开始，到这里全部数据完成了排序。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7swzy08hpj315t0kogpp.jpg\" alt=\"\"></p>\n<p>下一步就对文件中的Key进行分组输入到Reducer中，Reducer处理完的数据交给OutPutFormat，由OutPutFormat输出到我们要存的文件中。中间省略了很多步骤，之后会进行详细讲解。</p>\n<p><strong>上面的流程是整个MapReduce最全工作流程，但是Shuffle过程只是从第7步开始到第16步结束，具体Shuffle过程详解，如下：</strong></p>\n<ol>\n<li>MapTask收集我们的map()方法输出的kv对，放到内存缓冲区中</li>\n<li>从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件</li>\n<li>多个溢出文件会被合并成大的溢出文件</li>\n<li>在溢出过程及合并的过程中，都要调用Partitioner进行分区和针对key进行排序</li>\n<li>ReduceTask根据自己的分区号，去各个MapTask机器上取相应的结果分区数据</li>\n<li>ReduceTask会取到同一个分区的来自不同MapTask的结果文件，ReduceTask会将这些文件再进行合并（归并排序）</li>\n<li>合并成大文件后，Shuffle的过程也就结束了，后面进入ReduceTask的逻辑运算过程（从文件中取出一个一个的键值对Group，调用用户自定义的reduce()方法）</li>\n</ol>\n<p>下一篇文章会对Shuffle机制进行详解，这篇中分区问题就会解决了。</p>\n","categories":["Hadoop-MR"],"tags":[]},{"title":"BD-MapReduce3-MapReduce框架原理之InputFormat数据输入","url":"http://ilovenorth.cn/2019/10/08/BD-MapReduce3-MapReduce框架原理之InputFormat数据输入/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p><meta name=\"referrer\" content=\"no-referrer\"></p>\n<h1 id=\"BD-MapReduce3-MapReduce框架原理之InputFormat数据输入\"><a href=\"#BD-MapReduce3-MapReduce框架原理之InputFormat数据输入\" class=\"headerlink\" title=\"BD-MapReduce3-MapReduce框架原理之InputFormat数据输入\"></a>BD-MapReduce3-MapReduce框架原理之InputFormat数据输入</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><h2 id=\"一、切片与MapTask并行度决定机制\"><a href=\"#一、切片与MapTask并行度决定机制\" class=\"headerlink\" title=\"一、切片与MapTask并行度决定机制\"></a>一、切片与MapTask并行度决定机制</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7e6fujlh9j30re0d6q3u.jpg\" alt=\"\"></p>\n<ul>\n<li>我们知道Mapper处理数据的时候是将数据变成KV键值对的形式，<br>这个转变的过程正式InputFormat来实现的。</li>\n<li>Mapper输出的KV键值对是无序的，到了Reducer，它把相同的数据汇到了同一组，这个过程叫做Shuffle。<font color=\"red\">这个Shuffle过程其实是我们人为划分的，其实Shuffle阶段是由MapTask的后半段和ReduceTask的前半段共同组成的。</font></li>\n<li>Reducer将KV值结果输出到外部文件，通过OutPutFormat来实现。</li>\n</ul>\n<p>这就是我们接下来要介绍的主要部分。</p>\n<h3 id=\"1-1-切片与MapTask并行度决定机制\"><a href=\"#1-1-切片与MapTask并行度决定机制\" class=\"headerlink\" title=\"1.1 切片与MapTask并行度决定机制\"></a>1.1 切片与MapTask并行度决定机制</h3><h4 id=\"1-问题引出\"><a href=\"#1-问题引出\" class=\"headerlink\" title=\"1. 问题引出\"></a>1. 问题引出</h4><p><strong><em>MapTask的并行度决定Map阶段的任务处理并发度，进而影响到整个Job的处理速度。</em></strong></p>\n<font color=\"#5555FF\">Q：1G的数据，启动8个MapTask，可以提高集群的并发处理能力。那么1K的数据，也启动8个MapTask，会提高集群性能吗？MapTask并行任务是否越多越好呢？哪些因素影响了MapTask并行度？</font>\n\n<p>数据划分就是由InputFormat来完成的，假如我们划分了8份，一份128M，启动了响应数量的Maptask来处理数据，并行度也就为8。</p>\n<h4 id=\"2-MapTask并行度决定机制\"><a href=\"#2-MapTask并行度决定机制\" class=\"headerlink\" title=\"2. MapTask并行度决定机制\"></a>2. MapTask并行度决定机制</h4><p><strong>数据块</strong>：Block是HDFS在物理上把数据分成一块一块的单位。<br><strong>数据切片</strong>：数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其切分成片进行存储。</p>\n<p>现在我们有一个300M的文件，HDFS的块大小默认为128M，默认情况下，我们也按照128M的大小来切文件。可以设想一下，如果我们按100M的大小来切分文件，会是什么效果。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7f307bsrsj31qe0u0dmp.jpg\" alt=\"\"></p>\n<p>按100M切分，每个MapTask确实处理文件大小变小了，每个MapTask处理文件的时间也变短了<strong><em>（节点上的这个文件会交给该节点上的MapTask来处理，这是yarn的一个优化原则，本地数据尽量在本地的MapTask上处理，也就是hadoop002上的文件一般都会交给hadoop002机器的MR来处理，为了避免网络传输）</em></strong>。但是MR框架就不爽了，因为一块的大小为128M，然而我们的MapTask按100M的大小切文件，将0~100M交给DN1的MapTask来处理，第二个100M交给DN2的MapTask来处理，<font color=\"red\">但是第二块100M，其中，有28M在第一个DN中，这就面临着28M的网络传输，同理算上第三块，一共产生了84M的网络传输。尽管MapTask处理效率上升了，但是得不偿失，失在了网络传输上了。</font></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7f4419qdmj31r90u0wmb.jpg\" alt=\"\"></p>\n<p>如果我们的MapTask按照128M来切分文件，尽管每个MapTask处理的文件变大了，但是省去了网路传输，整体的性能其实是更优的。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7f4785r6oj31q50u0tkt.jpg\" alt=\"\"></p>\n<p>在总结中，说一下第四点。    </p>\n<p>也就是说如果我们总共有500M的文件，不过是3个文件汇总的，300、100、100，此时，切片是针对单一文件的，也就说300M切位3片，100M为一片，最后的100M为一片。</p>\n<h2 id=\"二、Job提交流程源码和切片源码详解\"><a href=\"#二、Job提交流程源码和切片源码详解\" class=\"headerlink\" title=\"二、Job提交流程源码和切片源码详解\"></a>二、Job提交流程源码和切片源码详解</h2><h3 id=\"2-1-Job提交流程源码详解\"><a href=\"#2-1-Job提交流程源码详解\" class=\"headerlink\" title=\"2.1 Job提交流程源码详解\"></a>2.1 Job提交流程源码详解</h3><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">waitForCompletion()</span><br><span class=\"line\"></span><br><span class=\"line\">submit();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 1建立连接</span></span><br><span class=\"line\">\tconnect();\t</span><br><span class=\"line\">\t\t<span class=\"comment\">// 1）创建提交Job的代理</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">new</span> Cluster(getConfiguration());</span><br><span class=\"line\">\t\t\t<span class=\"comment\">// （1）判断是本地yarn还是远程</span></span><br><span class=\"line\">\t\t\tinitialize(jobTrackAddr, conf); </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 2 提交job</span></span><br><span class=\"line\">submitter.submitJobInternal(Job.<span class=\"keyword\">this</span>, cluster)</span><br><span class=\"line\">\t<span class=\"comment\">// 1）创建给集群提交数据的Stag路径</span></span><br><span class=\"line\">\tPath jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 2）获取jobid ，并创建Job路径</span></span><br><span class=\"line\">\tJobID jobId = submitClient.getNewJobID();</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 3）拷贝jar包到集群</span></span><br><span class=\"line\">copyAndConfigureFiles(job, submitJobDir);\t</span><br><span class=\"line\">\trUploader.uploadFiles(job, jobSubmitDir);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 4）计算切片，生成切片规划文件</span></span><br><span class=\"line\">writeSplits(job, submitJobDir);</span><br><span class=\"line\">\t\tmaps = writeNewSplits(job, jobSubmitDir);</span><br><span class=\"line\">\t\t<span class=\"comment\">// 切片规则 被切文件大小是否大于128M的1.1倍</span></span><br><span class=\"line\">\t\tinput.getSplits(job);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 5）向Stag路径写XML配置文件</span></span><br><span class=\"line\">writeConf(conf, submitJobFile);</span><br><span class=\"line\">\tconf.writeXml(out);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 6）提交Job,返回提交状态</span></span><br><span class=\"line\">status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7f6a601a8j31mi0u0tlf.jpg\" alt=\"\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7f6c20bedj31nz0u0qgn.jpg\" alt=\"\"></p>\n<h2 id=\"三、FileInputFormat实现类\"><a href=\"#三、FileInputFormat实现类\" class=\"headerlink\" title=\"三、FileInputFormat实现类\"></a>三、FileInputFormat实现类</h2><p>思考：<font color=\"red\">在运行MapReduce程序时，输入的文件格式包括：基于行的日志文件、二进制格式文件、数据库表等。</font>那么，针对不同的数据类型，MapReduce是如何读取这些数据的呢？</p>\n<p>FileInputFormat常见的接口实现类包括：<font color=\"red\">TextInputFormat、KeyValueTextInputFormat、NLineInputFormat、CombineTextInputFormat和自定义InputFormat等。</font></p>\n<h2 id=\"3-1-TextInputFormat\"><a href=\"#3-1-TextInputFormat\" class=\"headerlink\" title=\"3.1 TextInputFormat\"></a>3.1 TextInputFormat</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7f92en4g8j30ky0j2tao.jpg\" alt=\"\"></p>\n<p>TextInputFormat是默认的FileInputFormat实现类。按行读取每条记录。键是存储该行在整个文件中的起始字节偏移量， LongWritable类型。值是这行的内容，不包括任何行终止符（换行符和回车符），Text类型。</p>\n<p>以下是一个示例，比如，一个分片包含了如下4条文本记录。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Rich learning form</span><br><span class=\"line\">Intelligent learning engine</span><br><span class=\"line\">Learning more convenient</span><br><span class=\"line\">From the real demand for more close to the enterprise</span><br></pre></td></tr></table></figure>\n<p>每条记录表示为以下键/值对：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">(0,Rich learning form)</span><br><span class=\"line\">(19,Intelligent learning engine)</span><br><span class=\"line\">(47,Learning more convenient)</span><br><span class=\"line\">(72,From the real demand for more close to the enterprise)</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-2-KeyValueTextInputFormat\"><a href=\"#3-2-KeyValueTextInputFormat\" class=\"headerlink\" title=\"3.2 KeyValueTextInputFormat\"></a>3.2 KeyValueTextInputFormat</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7g6uduvx0j30ki0jmdhv.jpg\" alt=\"\"></p>\n<p>每一行均为一条记录，被分隔符分割为key，value。可以通过在驱动类中设置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">conf.set(KeyValueLineRecordReader.KEY_VALUE_SEPERATOR, &quot;\\t&quot;);来设定分隔符。</span><br></pre></td></tr></table></figure>\n<p>默认分隔符是tab（\\t）。</p>\n<p>以下是一个示例，输入是一个包含4条记录的分片。其中——&gt;表示一个（水平方向的）制表符。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">line1 ——&gt;Rich learning form</span><br><span class=\"line\">line2 ——&gt;Intelligent learning engine</span><br><span class=\"line\">line3 ——&gt;Learning more convenient</span><br><span class=\"line\">line4 ——&gt;From the real demand for more close to the enterprise</span><br></pre></td></tr></table></figure>\n<p>每条记录表示为以下键/值对：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">(line1,Rich learning form)</span><br><span class=\"line\">(line2,Intelligent learning engine)</span><br><span class=\"line\">(line3,Learning more convenient)</span><br><span class=\"line\">(line4,From the real demand for more close to the enterprise)</span><br></pre></td></tr></table></figure>\n<p>此时的键是每行排在制表符之前的Text序列。</p>\n<h2 id=\"3-3-NLineInputFormat\"><a href=\"#3-3-NLineInputFormat\" class=\"headerlink\" title=\"3.3 NLineInputFormat\"></a>3.3 NLineInputFormat</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7g719tuyoj309609yjrt.jpg\" alt=\"\"></p>\n<p>如果使用NlineInputFormat，代表每个map进程处理的<font color=\"red\">InputSplit不再按Block块去划分，而是按NlineInputFormat指定的行数N来划分。</font>即输入文件的总行数/N=切片数，如果不整除，切片数=商+1。</p>\n<p>以下是一个示例，仍然以上面的4行输入为例。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Rich learning form</span><br><span class=\"line\">Intelligent learning engine</span><br><span class=\"line\">Learning more convenient</span><br><span class=\"line\">From the real demand for more close to the enterprise</span><br></pre></td></tr></table></figure>\n<p>例如，如果N是2，则每个输入分片包含两行。开启2个MapTask。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">(0,Rich learning form)</span><br><span class=\"line\">(19,Intelligent learning engine)</span><br></pre></td></tr></table></figure>\n<p>另一个 mapper 则收到后两行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">(47,Learning more convenient)</span><br><span class=\"line\">(72,From the real demand for more close to the enterprise)</span><br></pre></td></tr></table></figure>\n<p>这里的键和值与TextInputFormat生成的一样。</p>\n<p>总结一下：</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7g73ye1czj31k406aac2.jpg\" alt=\"\"></p>\n<h2 id=\"3-4-CombineTextInputFormat的切片机制\"><a href=\"#3-4-CombineTextInputFormat的切片机制\" class=\"headerlink\" title=\"3.4 CombineTextInputFormat的切片机制\"></a>3.4 CombineTextInputFormat的切片机制</h2><p>框架默认的TextInputFormat切片机制是对任务按文件规划切片，<font color=\"red\">不管文件多小，都会是一个单独的切片，</font>都会交给一个MapTask，这样如果有大量小文件，<font color=\"red\">就会产生大量的MapTask，处理效率极其低下。</font></p>\n<h3 id=\"3-4-1-应用场景\"><a href=\"#3-4-1-应用场景\" class=\"headerlink\" title=\"3.4.1 应用场景\"></a>3.4.1 应用场景</h3><p>CombineTextInputFormat用于小文件过多的场景，<font color=\"red\">它可以将多个小文件从逻辑上规划到一个切片中，</font>这样，多个小文件就可以交给一个MapTask处理。</p>\n<h3 id=\"3-4-2-虚拟存储切片最大值设置\"><a href=\"#3-4-2-虚拟存储切片最大值设置\" class=\"headerlink\" title=\"3.4.2 虚拟存储切片最大值设置\"></a>3.4.2 虚拟存储切片最大值设置</h3><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">CombineTextInputFormat.setMaxInputSplitSize(job, <span class=\"number\">4194304</span>);<span class=\"comment\">// 4M</span></span><br></pre></td></tr></table></figure>\n<p>注意：虚拟存储切片最大值设置最好根据实际的小文件大小情况来设置具体的值。</p>\n<h3 id=\"3-4-3-切片机制\"><a href=\"#3-4-3-切片机制\" class=\"headerlink\" title=\"3.4.3 切片机制\"></a>3.4.3 切片机制</h3><p>生成切片过程包括：虚拟存储过程和切片过程二部分。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7qktxrqvdj31550kzn0h.jpg\" alt=\"\"></p>\n<p><strong>1.虚拟存储过程：</strong></p>\n<p>将输入目录下所有文件大小，依次和设置的setMaxInputSplitSize值比较，如果不大于设置的最大值，逻辑上划分一个块。如果输入文件大于设置的最大值且大于两倍，那么以最大值切割一块；<font color=\"red\">当剩余数据大小超过设置的最大值且不大于最大值2倍，此时将文件均分成2个虚拟存储块（防止出现太小切片）。</font></p>\n<p>例如setMaxInputSplitSize值为4M，输入文件大小为8.02M，则先逻辑上分成一个4M。剩余的大小为4.02M，如果按照4M逻辑划分，就会出现0.02M的小的虚拟存储文件，所以将剩余的4.02M文件切分成（2.01M和2.01M）两个文件。</p>\n<p><strong>2.切片过程</strong></p>\n<ul>\n<li>判断虚拟存储的文件大小是否大于setMaxInputSplitSize值，大于等于则单独形成一个切片。</li>\n<li>如果不大于则跟下一个虚拟存储文件进行合并，共同形成一个切片。</li>\n<li><font color=\"red\">测试举例：有4个小文件大小分别为1.7M、5.1M、3.4M以及6.8M这四个小文件，则虚拟存储之后形成6个文件块，大小分别为：</font>\n\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">1.7M、（2.55M、2.55M）、3.4M、以及（3.4M、3.4M）</span><br><span class=\"line\">最终会形成3个切片，大小分别为：</span><br><span class=\"line\">（1.7+2.55）M、（2.55+3.4）M、（3.4+3.4）M</span><br></pre></td></tr></table></figure>\n<h2 id=\"四、自定义InputFormat实现类\"><a href=\"#四、自定义InputFormat实现类\" class=\"headerlink\" title=\"四、自定义InputFormat实现类\"></a>四、自定义InputFormat实现类</h2><h3 id=\"4-1-自定义InputFormat准备步骤\"><a href=\"#4-1-自定义InputFormat准备步骤\" class=\"headerlink\" title=\"4.1 自定义InputFormat准备步骤\"></a>4.1 自定义InputFormat准备步骤</h3><p>在企业开发中，Hadoop框架自带的InputFormat类型不能满足所有应用场景，需要自定义InputFormat来解决实际问题。</p>\n<p><strong>自定义InputFormat准备步骤如下：</strong></p>\n<ol>\n<li>自定义一个类继承FileInputFormat。（准备步骤）</li>\n<li>改写RecordReader，实现一次读取一个完整文件封装为KV。（准备步骤）</li>\n<li>在输出时使用SequenceFileOutPutFormat输出合并文件。</li>\n</ol>\n<h4 id=\"4-1-自定义一个类继承FileInputFormat。\"><a href=\"#4-1-自定义一个类继承FileInputFormat。\" class=\"headerlink\" title=\"4.1 自定义一个类继承FileInputFormat。\"></a>4.1 自定义一个类继承FileInputFormat。</h4><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.Text;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.InputSplit;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.RecordReader;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.io.IOException;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * 泛型: K 为 Text（文件名） V 为 BytesWritable（一段2进制数值）</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@ClassName</span> : WholeFileInputFormat</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Description</span> : TODO</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Author</span> : murasaki</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Date</span> : 2019-10-08 10:58</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Version</span> : 1.0</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">WholeFileInputFormat</span> <span class=\"keyword\">extends</span> <span class=\"title\">FileInputFormat</span>&lt;<span class=\"title\">Text</span>, <span class=\"title\">BytesWritable</span>&gt; </span>&#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> RecordReader&lt;Text, BytesWritable&gt; <span class=\"title\">createRecordReader</span><span class=\"params\">(InputSplit split, TaskAttemptContext context)</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"4-2-改写RecordReader，实现一次读取一个完整文件封装为KV。\"><a href=\"#4-2-改写RecordReader，实现一次读取一个完整文件封装为KV。\" class=\"headerlink\" title=\"4.2 改写RecordReader，实现一次读取一个完整文件封装为KV。\"></a>4.2 改写RecordReader，实现一次读取一个完整文件封装为KV。</h4><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.Text;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.InputSplit;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.RecordReader;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.io.IOException;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * 自定义RR，处理一个文件：把这个文件直接都城一个KV值</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@ClassName</span> : WholeFileRecordReader</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Description</span> : TODO</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Author</span> : murasaki</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Date</span> : 2019-10-08 11:02</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Version</span> : 1.0</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">WholeFileRecordReader</span> <span class=\"keyword\">extends</span> <span class=\"title\">RecordReader</span>&lt;<span class=\"title\">Text</span>, <span class=\"title\">BytesWritable</span>&gt; </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 初始化方法，框架会在开始的时候调用一次</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@Author</span> MurasakiSeiFu</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@Date</span> 11:06 2019-10-08</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@Param</span> [split, context]</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> void</span></span><br><span class=\"line\"><span class=\"comment\">     **/</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">initialize</span><span class=\"params\">(InputSplit split, TaskAttemptContext context)</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 读取下一组KV值</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@Author</span> MurasakiSeiFu</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@Date</span> 11:09 2019-10-08</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@Param</span> []</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> 如果读到了，返回true；读完了，返回false</span></span><br><span class=\"line\"><span class=\"comment\">     **/</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">boolean</span> <span class=\"title\">nextKeyValue</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获取当前读到的Key</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> 当前的Key</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> IOException</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> InterruptedException</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Text <span class=\"title\">getCurrentKey</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获取当前读到的Value</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> 当前的Value</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> IOException</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> InterruptedException</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> BytesWritable <span class=\"title\">getCurrentValue</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获取当前数据读取进度（我们执行MR的时候，会看到Maper执行到百分之几，就是从这里来的）</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> 当前的进度</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> IOException</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> InterruptedException</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">float</span> <span class=\"title\">getProgress</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 关闭资源</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> IOException</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">close</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> IOException </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"4-2-自定义InputFormat案例实操\"><a href=\"#4-2-自定义InputFormat案例实操\" class=\"headerlink\" title=\"4.2 自定义InputFormat案例实操\"></a>4.2 自定义InputFormat案例实操</h3><p>无论HDFS还是MapReduce，在处理小文件时效率都非常低，但又难免面临处理大量小文件的场景，此时，就需要有相应解决方案。可以自定义InputFormat实现小文件的合并。</p>\n<h4 id=\"4-2-1-需求\"><a href=\"#4-2-1-需求\" class=\"headerlink\" title=\"4.2.1 需求\"></a>4.2.1 需求</h4><p>将多个小文件合并成一个SequenceFile文件（SequenceFile文件是Hadoop用来存储二进制形式的key-value对的文件格式），SequenceFile里面存储着多个文件，存储的形式为【文件路径+名称】为key，【文件内容】为value。</p>\n<ol>\n<li>输入数据: one.txt two.txt three.txt</li>\n<li>期望输出文件格式: part-r-0000</li>\n</ol>\n<h4 id=\"4-2-2-需求分析\"><a href=\"#4-2-2-需求分析\" class=\"headerlink\" title=\"4.2.2 需求分析\"></a>4.2.2 需求分析</h4><p>因为需求中说<font color=\"red\">将多个小文件合并成一个SequenceFile文件</font>，所以我们需要在我们自定义的<strong>FileInputFormat</strong>类中重写<strong><em>isSplitable()</em></strong>方法，返回false，不可分割。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">boolean</span> <span class=\"title\">isSplitable</span><span class=\"params\">(JobContext context, Path filename)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>接下来，第一件事，我们先完成<strong>自定义RR</strong>中的<strong><em>getProgress()</em></strong>方法，开始读取数据的时候要么就是没读，要么就是读完，所以我们需要声明的一个boolean类型的变量来进行控制。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">boolean</span> notRead = <span class=\"keyword\">true</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">float</span> <span class=\"title\">getProgress</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> notRead ? <span class=\"number\">0</span> : <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>我们知道通过<strong><em>nextKeyValue()</em></strong>方法来读取下一组KV值，通过<strong><em>getCurrentKey()和getCurrentValue()</em></strong>来获取数据的Key和Value，可以看到key和value值得获取跨了方法，所以我们需要声明成员变量。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> Text key = <span class=\"keyword\">new</span> Text();</span><br><span class=\"line\"><span class=\"keyword\">private</span> BytesWritable value = <span class=\"keyword\">new</span> BytesWritable();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> Text <span class=\"title\">getCurrentKey</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> key;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> BytesWritable <span class=\"title\">getCurrentValue</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> value;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>因为我们最终要只处理一个文件，而且我们只读一次就把文件都读完了，于是<strong><em>nextKeyValue()方法</em></strong>在第一次调用的时候会返回ture表示能读到数据，第二次就会返回false。简单架子如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">boolean</span> <span class=\"title\">nextKeyValue</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (notRead) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 具体读文件的过程</span></span><br><span class=\"line\"></span><br><span class=\"line\">        notRead = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">true</span>;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</span><br><span class=\"line\">    &#125; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>接下来我们来具体实现需求，首先读取文件需要开启流，我们可以在<strong><em>initialize()</em></strong>方法里开启，也可以在<strong><em>nextKeyValue()</em></strong>中开启，我们以在<strong><em>initialize()</em></strong>方法中开启为例，我们在<strong><em>initialize()</em></strong>方法中开启流，在<strong><em>nextKeyValue()方法</em></strong>中使用，在<strong><em>close()</em></strong>方法中关闭流，因此我们需要声明一个成员变量。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 因为以后的操作需要用到path 这里就直接提出来了</span></span><br><span class=\"line\"><span class=\"keyword\">private</span> FileSplit fs;</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">initialize</span><span class=\"params\">(InputSplit split, TaskAttemptContext context)</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">       <span class=\"comment\">// 转换切片类型到文件切片『因为split本身就是FileSplit FileSplit继承InputSplit』</span></span><br><span class=\"line\">       fs = (FileSplit) split;</span><br><span class=\"line\">       <span class=\"comment\">// 结合之前文章：HDFS的数据流写入</span></span><br><span class=\"line\">       <span class=\"comment\">// 通过切片获取路径</span></span><br><span class=\"line\">       Path path = fs.getPath();</span><br><span class=\"line\">       <span class=\"comment\">// 通过路径获取文件系统</span></span><br><span class=\"line\">       FileSystem fileSystem = path.getFileSystem(context.getConfiguration());</span><br><span class=\"line\">       <span class=\"comment\">// 开流</span></span><br><span class=\"line\">       inputStream = fileSystem.open(path);</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">close</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> IOException </span>&#123;</span><br><span class=\"line\">       IOUtils.closeStream(inputStream);</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<p>现在我们完成读的过程。说白了就是读出Key和Value。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">boolean</span> <span class=\"title\">nextKeyValue</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">       <span class=\"keyword\">if</span> (notRead) &#123;</span><br><span class=\"line\">           <span class=\"comment\">// 具体读文件的过程</span></span><br><span class=\"line\">           <span class=\"comment\">// 读Key</span></span><br><span class=\"line\">           key.set(fs.getPath().toString());</span><br><span class=\"line\"></span><br><span class=\"line\">           <span class=\"comment\">// 读Value</span></span><br><span class=\"line\">           <span class=\"comment\">// 因为我们的value为BytesWritable 所以我们根据文件的大小声明一个byte数组</span></span><br><span class=\"line\">           <span class=\"keyword\">byte</span>[] buf = <span class=\"keyword\">new</span> <span class=\"keyword\">byte</span>[(<span class=\"keyword\">int</span>) fs.getLength()];</span><br><span class=\"line\">           <span class=\"comment\">// 将流中读取的字节存储到byte数组中</span></span><br><span class=\"line\">           inputStream.read(buf);</span><br><span class=\"line\">           value.set(buf, <span class=\"number\">0</span>, buf.length);</span><br><span class=\"line\"></span><br><span class=\"line\">           notRead = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">           <span class=\"keyword\">return</span> <span class=\"keyword\">true</span>;</span><br><span class=\"line\">       &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">           <span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<p>下面铺出全部WholeFileRecordReader、WholeFileInputFormat代码。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.fs.FSDataInputStream;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.fs.Path;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.Text;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.lib.input.FileSplit;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.InputSplit;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.RecordReader;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.io.IOException;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * 自定义RR，处理一个文件：把这个文件直接都城一个KV值</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@ClassName</span> : WholeFileRecordReader</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Description</span> : TODO</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Author</span> : murasaki</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Date</span> : 2019-10-08 11:02</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Version</span> : 1.0</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">WholeFileRecordReader</span> <span class=\"keyword\">extends</span> <span class=\"title\">RecordReader</span>&lt;<span class=\"title\">Text</span>, <span class=\"title\">BytesWritable</span>&gt; </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">boolean</span> notRead = <span class=\"keyword\">true</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> Text key = <span class=\"keyword\">new</span> Text();</span><br><span class=\"line\">    <span class=\"keyword\">private</span> BytesWritable value = <span class=\"keyword\">new</span> BytesWritable();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> FSDataInputStream inputStream;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> FileSplit fs;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 初始化方法，框架会在开始的时候调用一次</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@Author</span> MurasakiSeiFu</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@Date</span> 11:06 2019-10-08</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@Param</span> [split:切片, context:任务信息]</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> void</span></span><br><span class=\"line\"><span class=\"comment\">     **/</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">initialize</span><span class=\"params\">(InputSplit split, TaskAttemptContext context)</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 转换切片类型到文件切片『因为split本身就是FileSplit FileSplit继承InputSplit』</span></span><br><span class=\"line\">        fs = (FileSplit) split;</span><br><span class=\"line\">        <span class=\"comment\">// 结合之前文章：HDFS的数据流写入</span></span><br><span class=\"line\">        <span class=\"comment\">// 通过切片获取路径</span></span><br><span class=\"line\">        Path path = fs.getPath();</span><br><span class=\"line\">        <span class=\"comment\">// 通过路径获取文件系统</span></span><br><span class=\"line\">        FileSystem fileSystem = path.getFileSystem(context.getConfiguration());</span><br><span class=\"line\">        <span class=\"comment\">// 开流</span></span><br><span class=\"line\">        inputStream = fileSystem.open(path);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 读取下一组KV值</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@Author</span> MurasakiSeiFu</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@Date</span> 11:09 2019-10-08</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@Param</span> []</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> 如果读到了，返回true；读完了，返回false</span></span><br><span class=\"line\"><span class=\"comment\">     **/</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">boolean</span> <span class=\"title\">nextKeyValue</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (notRead) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 具体读文件的过程</span></span><br><span class=\"line\">            <span class=\"comment\">// 读Key</span></span><br><span class=\"line\">            key.set(fs.getPath().toString());</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">// 读Value</span></span><br><span class=\"line\">            <span class=\"keyword\">byte</span>[] buf = <span class=\"keyword\">new</span> <span class=\"keyword\">byte</span>[(<span class=\"keyword\">int</span>) fs.getLength()];</span><br><span class=\"line\">            inputStream.read(buf);</span><br><span class=\"line\">            value.set(buf, <span class=\"number\">0</span>, buf.length);</span><br><span class=\"line\"></span><br><span class=\"line\">            notRead = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"keyword\">true</span>;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获取当前读到的Key</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> 当前的Key</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> IOException</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> InterruptedException</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Text <span class=\"title\">getCurrentKey</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> key;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获取当前读到的Value</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> 当前的Value</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> IOException</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> InterruptedException</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> BytesWritable <span class=\"title\">getCurrentValue</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> value;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获取当前数据读取进度（我们执行MR的时候，会看到Maper执行到百分之几，就是从这里来的）</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> 当前的进度</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> IOException</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> InterruptedException</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">float</span> <span class=\"title\">getProgress</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> notRead ? <span class=\"number\">0</span> : <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 关闭资源</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> IOException</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">close</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> IOException </span>&#123;</span><br><span class=\"line\">        IOUtils.closeStream(inputStream);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.fs.Path;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.Text;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.InputSplit;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.JobContext;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.RecordReader;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.io.IOException;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * 泛型: K 为 Text（文件名） V 为 BytesWritable（一段2进制数值）</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@ClassName</span> : WholeFileInputFormat</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Description</span> : TODO</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Author</span> : murasaki</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Date</span> : 2019-10-08 10:58</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Version</span> : 1.0</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">WholeFileInputFormat</span> <span class=\"keyword\">extends</span> <span class=\"title\">FileInputFormat</span>&lt;<span class=\"title\">Text</span>, <span class=\"title\">BytesWritable</span>&gt; </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">boolean</span> <span class=\"title\">isSplitable</span><span class=\"params\">(JobContext context, Path filename)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> RecordReader&lt;Text, BytesWritable&gt; <span class=\"title\">createRecordReader</span><span class=\"params\">(InputSplit split, TaskAttemptContext context)</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> WholeFileRecordReader();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>最后，我们写一下Driver，这里我们没有重新Mapper和Reducer，因为不需要，所以这里使用的是默认的Mapper、Reducer。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.fs.Path;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.Text;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.io.IOException;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">WholeFileDriver</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> <span class=\"keyword\">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">        Job job = Job.getInstance(<span class=\"keyword\">new</span> Configuration());</span><br><span class=\"line\"></span><br><span class=\"line\">        job.setMapOutputKeyClass(Text<span class=\"class\">.<span class=\"keyword\">class</span>)</span>;</span><br><span class=\"line\">        job.setMapOutputValueClass(BytesWritable<span class=\"class\">.<span class=\"keyword\">class</span>)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        job.setOutputKeyClass(Text<span class=\"class\">.<span class=\"keyword\">class</span>)</span>;</span><br><span class=\"line\">        job.setOutputValueClass(BytesWritable<span class=\"class\">.<span class=\"keyword\">class</span>)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        job.setInputFormatClass(WholeFileInputFormat<span class=\"class\">.<span class=\"keyword\">class</span>)</span>;</span><br><span class=\"line\">        job.setOutputFormatClass(SequenceFileOutputFormat<span class=\"class\">.<span class=\"keyword\">class</span>)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// 我们自定义的InputFormat继承的是FileInputFormat 所以这里用FileInputFormat 如果继承了其他的 这里就换做继承的</span></span><br><span class=\"line\">        FileInputFormat.setInputPaths(job, <span class=\"keyword\">new</span> Path(<span class=\"string\">\"\"</span>));</span><br><span class=\"line\">        FileOutputFormat.setOutputPath(job, <span class=\"keyword\">new</span> Path(<span class=\"string\">\"\"</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">boolean</span> b = job.waitForCompletion(<span class=\"keyword\">true</span>);</span><br><span class=\"line\">        System.exit(b ? <span class=\"number\">0</span> : <span class=\"number\">1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>首先看一下我们input文件夹中的文件。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7qworfri6j31iu0dmgnc.jpg\" alt=\"\"></p>\n<p>执行之后我们看下output中的信息。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7qwpjdr9zj31ee0hy0w2.jpg\" alt=\"\"></p>\n<p>我们可以看到Keyw为路径，Value为文件内容。</p>\n","categories":["Hadoop-MR"],"tags":[]},{"title":"BD-MapReduce2-MapReduce序列化","url":"http://ilovenorth.cn/2019/09/27/BD-MapReduce2-MapReduce序列化/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"BD-MapReduce2-MapReduce序列化\"><a href=\"#BD-MapReduce2-MapReduce序列化\" class=\"headerlink\" title=\"BD-MapReduce2-MapReduce序列化\"></a>BD-MapReduce2-MapReduce序列化</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><ol>\n<li>序列化概述</li>\n<li>自定义Bean对象实现序列化接口（Writable）</li>\n</ol>\n<h2 id=\"一、序列化概述\"><a href=\"#一、序列化概述\" class=\"headerlink\" title=\"一、序列化概述\"></a>一、序列化概述</h2><h3 id=\"1-1-什么是序列化\"><a href=\"#1-1-什么是序列化\" class=\"headerlink\" title=\"1.1 什么是序列化\"></a>1.1 什么是序列化</h3><p><strong>序列化</strong>就是把<font color=\"red\">内存中的对象，转换成字节序列</font>（或其他数据传输协议）以便于存储到磁盘（持久化）和网络传输。 </p>\n<p><strong>反序列化</strong>就是将收到字节序列（或其他数据传输协议）或者是<font color=\"red\">磁盘的持久化数据，转换成内存中的对象。</font></p>\n<h3 id=\"1-2-为什么要序列化\"><a href=\"#1-2-为什么要序列化\" class=\"headerlink\" title=\"1.2 为什么要序列化\"></a>1.2 为什么要序列化</h3><p>一般来说，“活的”对象只生存在内存里，关机断电就没有了。而且“活的”对象只能由本地的进程使用，不能被发送到网络上的另外一台计算机。 然而<font color=\"red\">序列化可以存储“活的”对象，可以将“活的”对象发送到远程计算机。</font></p>\n<h3 id=\"1-3-为什么不用Java的序列化\"><a href=\"#1-3-为什么不用Java的序列化\" class=\"headerlink\" title=\"1.3 为什么不用Java的序列化\"></a>1.3 为什么不用Java的序列化</h3><p>Java的序列化是一个重量级序列化框架（Serializable），一个对象被序列化后，会附带很多额外的信息（各种校验信息，Header，继承体系等），不便于在网络中高效传输。所以，Hadoop自己开发了一套序列化机制（Writable）。</p>\n<p><strong>Hadoop序列化特点：</strong></p>\n<ol>\n<li><strong>紧凑</strong>：高效使用存储空间</li>\n<li><strong>快速</strong>：读写数据的额外开销小</li>\n<li><strong>可扩展</strong>：随着通信协议的升级而可升级</li>\n<li><strong>互操作</strong>：支持多语言的交互</li>\n</ol>\n<h2 id=\"二、自定义bean对象实现序列化接口（Writable）\"><a href=\"#二、自定义bean对象实现序列化接口（Writable）\" class=\"headerlink\" title=\"二、自定义bean对象实现序列化接口（Writable）\"></a>二、自定义bean对象实现序列化接口（Writable）</h2><p>在企业开发中往往常用的基本序列化类型不能满足所有需求，比如在Hadoop框架内部传递一个bean对象，那么该对象就需要实现序列化接口。</p>\n<p>具体实现bean对象序列化步骤如下7步。</p>\n<ol>\n<li><p>必须实现Writable接口</p>\n</li>\n<li><p>反序列化时，需要反射调用空参构造函数，所以必须有空参构造</p>\n</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">public FlowBean() &#123;</span><br><span class=\"line\">\tsuper();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ol start=\"3\">\n<li>重写序列化方法</li>\n</ol>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">write</span><span class=\"params\">(DataOutput out)</span> <span class=\"keyword\">throws</span> IOException </span>&#123;</span><br><span class=\"line\">\tout.writeLong(upFlow);</span><br><span class=\"line\">\tout.writeLong(downFlow);</span><br><span class=\"line\">\tout.writeLong(sumFlow);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ol start=\"4\">\n<li>重写反序列化方法</li>\n</ol>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">readFields</span><span class=\"params\">(DataInput in)</span> <span class=\"keyword\">throws</span> IOException </span>&#123;</span><br><span class=\"line\">\tupFlow = in.readLong();</span><br><span class=\"line\">\tdownFlow = in.readLong();</span><br><span class=\"line\">\tsumFlow = in.readLong();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ol start=\"5\">\n<li><font color=\"red\">注意反序列化的顺序和序列化的顺序完全一致</font>\n</li>\n<li><p>要想把结果显示在文件中，需要重写toString()，可用”\\t”分开，方便后续用</p>\n</li>\n<li><p>如果需要将自定义的bean放在key中传输，则还需要实现Comparable接口，因为MapReduce框中的Shuffle过程要求对key必须能排序</p>\n</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">@Override</span><br><span class=\"line\">public int compareTo(FlowBean o) &#123;</span><br><span class=\"line\">\t// 倒序排列，从大到小</span><br><span class=\"line\">\treturn this.sumFlow &gt; o.getSumFlow() ? -1 : 1;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n","categories":["Hadoop-MR"],"tags":[]},{"title":"BD-MapReduce1-MapReduce概述","url":"http://ilovenorth.cn/2019/09/27/BD-MapReduce1-MapReduce概述/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"BD-MapReduce1-MapReduce概述\"><a href=\"#BD-MapReduce1-MapReduce概述\" class=\"headerlink\" title=\"BD-MapReduce1-MapReduce概述\"></a>BD-MapReduce1-MapReduce概述</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><ol>\n<li>定义</li>\n<li>优缺点</li>\n<li>核心思想</li>\n<li>进程</li>\n<li>常用数据序列化类型</li>\n<li>MapReduce编程规范</li>\n</ol>\n<h2 id=\"一、MapReduce-定义\"><a href=\"#一、MapReduce-定义\" class=\"headerlink\" title=\"一、MapReduce 定义\"></a>一、MapReduce 定义</h2><p>MapReduce是<font color=\"red\">一个分布式运算程序的编程框架</font>，是用户开发“基于Hadoop数据分析应用”的核心框架。</p>\n<p>MapReduce核心功能是将<font color=\"red\">用户编写的业务逻辑代码</font>和<font color=\"red\">自带默认组件</font>整合成一个完整的<font color=\"red\">分布式运算程序</font>，并发运行在一个Hadoop集群上。</p>\n<h2 id=\"二、MapReduce-优缺点\"><a href=\"#二、MapReduce-优缺点\" class=\"headerlink\" title=\"二、MapReduce 优缺点\"></a>二、MapReduce 优缺点</h2><h3 id=\"2-1-优点：简单\"><a href=\"#2-1-优点：简单\" class=\"headerlink\" title=\"2.1 优点：简单\"></a>2.1 优点：简单</h3><h4 id=\"1-易于编程\"><a href=\"#1-易于编程\" class=\"headerlink\" title=\"1. 易于编程\"></a>1. 易于编程</h4><font color=\"red\">它简单的实现一些接口，就可以完成一个分布式程序</font>，这个分布式程序可以分布到大量廉价的PC机器上运行。也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得MapReduce变成变得非常流行。<br><br><br>#### 2. 良好的扩展性<br><br><br>当你的计算资源不能得到满足的时候，你可以通过<font color=\"red\">简单的增加机器</font>来扩展它的计算能力。<br><br><br>#### 3. 高容错性<br><br><br>MapReduce设计的初衷就是使程序能够部署在廉价的PC机器上，这就要求它具有很高的容错性。<font color=\"red\">比如其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行，不至于这个任务运行失败</font>，而且这个过程不需要人工参与，而完全是由Hadoop内部完成的。<br><br><br>### 2.2 缺点：慢<br><br><br>#### 1. 不擅长实时计算<br><br><br>MapReduce无法像MySQL一样，在毫秒或者秒级内返回结果。<br><br><br>#### 2. 不擅长流式计算<br><br><br>流式计算的输入数据是动态的(数据流)，而MapReduce的<font color=\"red\">输入数据集是静态的(文件)</font>，不能动态变化。这是因为MapReduce自身的设计特点决定了数据源必须是静态的。<br><br><br>#### 3. 不擅长DAG（有向图）计算<br><br><br>多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce并不是不能做，而是使用后，<font color=\"red\">每个MapReduce作业的输出结果都会写入到磁盘，会造成大量的磁盘IO，导致性能非常的低下。</font>\n\n<h2 id=\"三、MapReduce-核心思想\"><a href=\"#三、MapReduce-核心思想\" class=\"headerlink\" title=\"三、MapReduce 核心思想\"></a>三、MapReduce 核心思想</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7e2mbtsiej31qf0u0n46.jpg\" alt=\"\"></p>\n<p>MapReduce运算程序一般需要分成2个阶段：Map阶段和Reduce阶段。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7e2q0yszaj31qm0u0tjf.jpg\" alt=\"\"></p>\n<ul>\n<li>Map拿到数据之后，交给MapTask，完全并行运行，互不相干。</li>\n<li>MapTask对数据进行处理，首先读数据。</li>\n<li>然后将数据按空格切分行内单词。</li>\n<li>把数据映射成KV键值对的形式（单词，1）</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7e2zdpmclj31q80u0k6x.jpg\" alt=\"\"></p>\n<p>分区我们一会再说，在Map阶段我们已经把数据分成了一个单词一个&lt;单词，1&gt;的形式，在Reduce阶段，会将相同单词的1进行累加，变成&lt;单词，n&gt;的形式。总结一写，MapReduce的核心思想其实就是Map阶段将文件变成我们想要的形式，Reduce阶段把数据做处理。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7e34hgqk8j31qr0u07op.jpg\" alt=\"\"></p>\n<p>至于一些细节，会在后面的文章中慢慢渗透。</p>\n<h2 id=\"四、MapReduce-进程\"><a href=\"#四、MapReduce-进程\" class=\"headerlink\" title=\"四、MapReduce 进程\"></a>四、MapReduce 进程</h2><p>一个完整的MapReduce程序在分布式运行时有三类实例进程：</p>\n<ul>\n<li>MrAppMaster：程序管家，负责整个程序的过程调度及状态协调。</li>\n<li>MapTask：负责Map阶段的整个数据处理流程。</li>\n<li>ReduceTask：负责Reduce阶段的整个数据处理流程。</li>\n</ul>\n<h2 id=\"五、常用数据序列化类型\"><a href=\"#五、常用数据序列化类型\" class=\"headerlink\" title=\"五、常用数据序列化类型\"></a>五、常用数据序列化类型</h2><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">java类型</th>\n<th style=\"text-align:center\">Hadoop Writeable 类型</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">Boolean</td>\n<td style=\"text-align:center\">BooleanWriteable</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Byte</td>\n<td style=\"text-align:center\">ByteWriteable</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Int</td>\n<td style=\"text-align:center\">IntWriteable</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Float</td>\n<td style=\"text-align:center\">FloatWriteable</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Double</td>\n<td style=\"text-align:center\">DoubleWriteable</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><mark>String<mark></mark></mark></td>\n<td style=\"text-align:center\"><mark>Text<mark></mark></mark></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Map</td>\n<td style=\"text-align:center\">MapWriteable</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Array</td>\n<td style=\"text-align:center\">ArrayWriteable</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"六、MapReduce编程规范\"><a href=\"#六、MapReduce编程规范\" class=\"headerlink\" title=\"六、MapReduce编程规范\"></a>六、MapReduce编程规范</h2><h3 id=\"6-1-Mapper阶段\"><a href=\"#6-1-Mapper阶段\" class=\"headerlink\" title=\"6.1 Mapper阶段\"></a>6.1 Mapper阶段</h3><ol>\n<li>用户自定义的Mapper要继承自己的父类</li>\n<li>Mapper的输入数据是KV对的形式（KV的类型可自定义）</li>\n<li>Mapper中的业务逻辑写在map()方法中</li>\n<li>Mapper的输出数据是KV对的形式（KV的类型可自定义）</li>\n<li><font color=\"red\">map()方法（MapTask进程）对每一个&lt;K,V&gt;调用一次<br></font>\n\n</li>\n</ol>\n<h3 id=\"6-2-Reducer阶段\"><a href=\"#6-2-Reducer阶段\" class=\"headerlink\" title=\"6.2 Reducer阶段\"></a>6.2 Reducer阶段</h3><ol>\n<li>用户自定义的Reducer要继承自己的父类</li>\n<li>Reducer的输入数据类型对应Mapper的输出数据类型，也是KV</li>\n<li>Reducer的业务逻辑写在reduce()方法中</li>\n<li><font color=\"red\">ReduceTask进程对每一组相同k的&lt;k,v&gt;组调用一次reduce()方法</font>\n\n</li>\n</ol>\n<h3 id=\"6-3-Driver阶段\"><a href=\"#6-3-Driver阶段\" class=\"headerlink\" title=\"6.3 Driver阶段\"></a>6.3 Driver阶段</h3><p>相当于YARN集群的客户端，用于提交我们整个程序到YARN集群，提交的是封装了MapReduce程序相关运行参数的job对象</p>\n","categories":["Hadoop-MR"],"tags":[]},{"title":"BD-HDFS-DataNode","url":"http://ilovenorth.cn/2019/09/27/BD-HDFS-DataNode/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"BD-HDFS-DataNode\"><a href=\"#BD-HDFS-DataNode\" class=\"headerlink\" title=\"BD-HDFS-DataNode\"></a>BD-HDFS-DataNode</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><ol>\n<li>DataNode工作机制</li>\n<li>数据完整性</li>\n<li>掉线时限参数设置</li>\n</ol>\n<h2 id=\"一、DataNode工作机制\"><a href=\"#一、DataNode工作机制\" class=\"headerlink\" title=\"一、DataNode工作机制\"></a>一、DataNode工作机制</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7d85vvznmj31q30u0thj.jpg\" alt=\"\"></p>\n<p>一个数据块在DataNode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据信息包括数据块的长度，块数据的校验和，以及时间戳。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7duhrwl03j31pd0u0ti9.jpg\" alt=\"\"></p>\n<p>DataNode启动后向NameNode注册。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7dujhh0foj31p20u07fb.jpg\" alt=\"\"></p>\n<p>通过后，周期性（1小时）的向NameNode上报所有的块信息。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7dun1lo3ij31qo0u0n9e.jpg\" alt=\"\"></p>\n<p>心跳是每3秒一次，心跳返回结果带有NameNode给该DataNode的命令如复制块数据到另一台机器，或删除某个数据块。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7duocv9d1j30xa09zgmy.jpg\" alt=\"\"></p>\n<p>DN的心跳就是Last contact，我们一直刷新页面就会看到这个数值一直在0~2自增。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7durp72mvj31qn0u0gyl.jpg\" alt=\"\"></p>\n<p>如果超过10分钟没有收到某个DataNode的心跳，则认为该节点不可用。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7dwwbj7ttj30j000zweh.jpg\" alt=\"\"></p>\n<p>我们先把hadoop003机器上的datanode停了。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7dwxbo4cvj30yq0atmyj.jpg\" alt=\"\"></p>\n<p>现在这个哥们已经失联了。</p>\n<h2 id=\"二、数据完整性\"><a href=\"#二、数据完整性\" class=\"headerlink\" title=\"二、数据完整性\"></a>二、数据完整性</h2><p><strong><em>思考：如果电脑磁盘里面存储的数据是控制高铁信号灯的<font color=\"red\">红灯信号（1）</font>和 <font color=\"green\">绿灯信号（0）</font>，但是存储该数据的磁盘坏了，一直显示是绿灯，是否很危险？同理DataNode节点上的数据损坏了，却没有发现，是否也很危险，那么如何解决呢？</em></strong></p>\n<p>如下是DataNode节点保证数据完整性的方法。</p>\n<ol>\n<li>当DataNode读取Block的时候，它会计算CheckSum。</li>\n<li>如果计算后的CheckSum，与Block创建时值不一样，说明Block已经损坏。</li>\n<li>Client读取其他DataNode上的Block。</li>\n<li>DataNode在其文件创建后周期验证CheckSum。</li>\n</ol>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7dxaz0vioj31pg0u0qg7.jpg\" alt=\"\"></p>\n<p>奇偶校验法：通过判断数据奇数为个数来校验数据，如果两个位数不相同，则说明数据有问题，但是没法测出数据正确性，比如奇数位个数相同，但是位置不一样，用奇偶校验是检查不出来的。</p>\n<p>CRC校验：对原始数据进行重新crc计算生成新的散列码，然后和传输过来的crc检验位比较，看是否一直。由于crc校验位计算生成的散列码变动会非常大，所以大部分情况下都会满足校验需求。</p>\n<h2 id=\"三、掉线时限参数设置\"><a href=\"#三、掉线时限参数设置\" class=\"headerlink\" title=\"三、掉线时限参数设置\"></a>三、掉线时限参数设置</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7dx0tvnxrj31tf0u0qcw.jpg\" alt=\"\"></p>\n<p>需要注意的是<strong><em>hdfs-site.xml</em></strong> 配置文件中的heartbeat.recheck.interval的单位为<font color=\"red\">毫秒</font>，dfs.heartbeat.interval的单位为<font color=\"red\">秒</font>。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;property&gt;</span><br><span class=\"line\">\t &lt;!-- 默认检查心跳的间隔 默认5分钟 --&gt;</span><br><span class=\"line\">    &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;300000&lt;/value&gt;</span><br><span class=\"line\">&lt;/property&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;property&gt;</span><br><span class=\"line\">\t &lt;!-- 心跳间隔 默认3秒钟 --&gt;</span><br><span class=\"line\">    &lt;name&gt;dfs.heartbeat.interval&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;3&lt;/value&gt;</span><br><span class=\"line\">&lt;/property&gt;</span><br></pre></td></tr></table></figure>","categories":["Hadoop-HDFS"],"tags":[]},{"title":"BD-HDFS-NameNode和SecondaryNameNode","url":"http://ilovenorth.cn/2019/09/26/BD-HDFS-NameNode和SecondaryNameNode/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"BD-HDFS-NameNode和SecondaryNameNode\"><a href=\"#BD-HDFS-NameNode和SecondaryNameNode\" class=\"headerlink\" title=\"BD-HDFS-NameNode和SecondaryNameNode\"></a>BD-HDFS-NameNode和SecondaryNameNode</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><ol>\n<li>NN和2NN的工作机制</li>\n<li>Fsimage和Edits解析</li>\n<li>CheckPoint时间设置</li>\n<li>NameNode 故障处理</li>\n</ol>\n<h2 id=\"1-1-NN和2NN的工作机制\"><a href=\"#1-1-NN和2NN的工作机制\" class=\"headerlink\" title=\"1.1 NN和2NN的工作机制\"></a>1.1 NN和2NN的工作机制</h2><p>问题：元数据就是描述数据的数据，NameNode中的元数据相当于一本书的目录，可以找到DataNode中的块。那么NameNode中的元数据是存储在哪里的？</p>\n<p>首先，我们做个假设，如果元数据存储在NameNode节点的磁盘中，因为经常需要进行随机访问，还有响应客户请求，必然是效率过低。因此，元数据需要存放在内存中。但如果只存在内存中，一旦断电，元数据丢失，整个集群就无法工作了。<font color=\"red\">因此产生了在磁盘中备份元数据的FsImage。</font></p>\n<p>这样又会带来新的问题，当在内存中的元数据更新时，如果同时更新FsImage，就会导致效率过低，但如果不更新，就会发生一致性问题，一旦NameNode节点断电，就会产生数据丢失。<font color=\"red\">因此，引入Edits文件(只进行追加操作，效率很高)。每当元数据有更新或者添加元数据时，修改内存中的元数据并追加到Edits中。</font>这样，一旦NameNode节点断电，可以通过FsImage和Edits的合并，合成元数据。</p>\n<p>但是，如果长时间添加数据到Edits中，会导致该文件数据过大，效率降低，而且一旦断电，恢复元数据需要的时间过长。因此，需要定期进行FsImage和Edits的合并，如果这个操作由NameNode节点完成，又会效率过低。<font color=\"red\">因此，引入一个新的节点SecondaryNamenode，专门用于FsImage和Edits的合并。</font></p>\n<p>这么看确实很难理解，我们结合NN和2NN的工作机制，就很清晰了。</p>\n<h3 id=\"第一步\"><a href=\"#第一步\" class=\"headerlink\" title=\"第一步\"></a>第一步</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7br5bnf2dj313a0u0wj5.jpg\" alt=\"\"></p>\n<p>当我们集群首次启动的时候，NN会加载FsImage，因为FsImage加载起来比较快（相当于Redis的RDB快照），我们先不管edits_inprogress_001。</p>\n<h3 id=\"第二步\"><a href=\"#第二步\" class=\"headerlink\" title=\"第二步\"></a>第二步</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7br92hd3rj312y0u079u.jpg\" alt=\"\"></p>\n<p>加载完了以后就可以正常工作了。这时，来了一条元数据的增删改请求。</p>\n<h3 id=\"第三步\"><a href=\"#第三步\" class=\"headerlink\" title=\"第三步\"></a>第三步</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7breiswt0j310i0u00z4.jpg\" alt=\"\"></p>\n<p>此时面临一个选择：我们是先更新内存再更新文件？还是先更新文件再更新内存？因为HDFS对数据安全性较高，所以会选择先更新文件再更新内存，当文件更新完了就会通知客户端，如果此时断点，也不会丢失更新的部分。因此，将更新的操作日志记录在edits_inprogress_001中（3—&gt;4）</p>\n<h3 id=\"第四步\"><a href=\"#第四步\" class=\"headerlink\" title=\"第四步\"></a>第四步</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7brosqqh2j31ms0u0gu8.jpg\" alt=\"\"></p>\n<p>随着edits_inprogress_001记录的操作越来越多，使得这个文件越来越大，需要合并到，这时候2NN就登场了。首先，2NN每隔一段时间就会问NN一次，需不需要合并，注意并不是这个间隔时间到了之后一定要合并，而是进行询问是否需要合并。</p>\n<h3 id=\"第五步\"><a href=\"#第五步\" class=\"headerlink\" title=\"第五步\"></a>第五步</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7brvs9k5cj31ms0u0k1a.jpg\" alt=\"\"></p>\n<p>NN是否会同意进行合并，有两种出发条件：第一种，距离上一次合并，已经到达一定的时间了，第二种，Edits中的数据满了。这里我们先不管，后面会说。如果这两个条件触发了其中任何一个，都会发生合并，如果NN回答Yes，那么2NN将发起请求合并</p>\n<p>大家还记得当时NameNode是怎么加载数据的？先加载了一个FsImage，类似我们内存的存档或者一个进度，加载完了之后，我们又往NameNode的内存写了很多数据，写的数据又记录在edits_inprogress_001（edits.log）中，现在我们要进行合并，到底要把那部分发送给2NN呢？edits.log + FsImage，因为我们要完全还原我们的内存镜像，就是FsImage（存档）+ edits.log（存档之后的变动操作）。具体NN的做法如下图：</p>\n<h3 id=\"第六步\"><a href=\"#第六步\" class=\"headerlink\" title=\"第六步\"></a>第六步</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7bs6nieb2j31mq0u0dqw.jpg\" alt=\"\"></p>\n<p>首先，NN把我们正在编辑的文件edits_inprgress_001改个名字为edits_001，然后新建一个新的文件，取名为edits_inprogress_002，新的文件用来写新的操作记录，为了不让持久化操作影响新的数据更新。</p>\n<h3 id=\"第七步\"><a href=\"#第七步\" class=\"headerlink\" title=\"第七步\"></a>第七步</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7bscdx88kj31n00u0am2.jpg\" alt=\"\"></p>\n<p>然后NN将edits_001和fsimage拷贝到2NN（fsimage + fsimage之后发生的操作）。</p>\n<h3 id=\"第八步\"><a href=\"#第八步\" class=\"headerlink\" title=\"第八步\"></a>第八步</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7bshj5vs1j31mx0u07h0.jpg\" alt=\"\"></p>\n<p>接下来2NN开始进行合并，其实2NN合并的过程和NN启动的过程非常像，第一步，先加载fsimage，这个相当于NN的存档，第二步，加载完了之后再加载edits_001中的操作。此时2NN的内存状态为，edits_001这些数据截止的时候（我们稍后再说）。</p>\n<h3 id=\"第九步\"><a href=\"#第九步\" class=\"headerlink\" title=\"第九步\"></a>第九步</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7bsre61a8j31me0u0nbq.jpg\" alt=\"\"></p>\n<p>2NN合并完成后生成新的fsimage.chkpoint，并拷贝到NN。NameNode将fsimage.chkpoint重新命名成fsimage。这样，一次持久化的操作就完成了。</p>\n<p>Fsimage就相当于内存的存档，记录了内存的状态，edits就相当于存档之后和下一次存档之间，记录未录入存档的操作的小纸条。当我们下次启动开始读档的时候，会将小纸条上的操作一条条的执行一遍。2NN就像NN的秘书一样，NN将对于存档读档的管理交给2NN，由2NN来执行小纸条上的操作，并记录到新存档中，再将新存档交给NN。</p>\n<p><strong>精炼详解（配合着图片流程，同时回答了图流程中遗留的问题）：</strong></p>\n<ol>\n<li><p>NameNode启动时，先滚动Edits并生成一个空的edits.inprogress，然后加载Edits和Fsimage到内存中，此时NameNode内存就持有最新的元数据信息。</p>\n</li>\n<li><p>Client开始对NameNode发送元数据的增删改的请求，这些请求的操作首先会被记录到edits.inprogress中（查询元数据的操作不会被记录在Edits中，因为查询操作不会更改元数据信息），如果此时NameNode挂掉，重启后会从Edits中读取元数据的信息。然后，NameNode会在内存中执行元数据的增删改的操作。</p>\n</li>\n<li><p>由于Edits中记录的操作会越来越多，Edits文件会越来越大，导致NameNode在启动加载Edits时会很慢，所以需要对Edits和Fsimage进行合并（所谓合并，就是将Edits和Fsimage加载到内存中，照着Edits中的操作一步步执行，最终形成新的Fsimage）。SecondaryNameNode的作用就是帮助NameNode进行Edits和Fsimage的合并工作。</p>\n</li>\n<li><p>SecondaryNameNode首先会询问NameNode是否需要CheckPoint（触发CheckPoint需要满足两个条件中的任意一个，定时时间到和Edits中数据写满了）。直接带回NameNode是否检查结果。</p>\n</li>\n<li><p>SecondaryNameNode执行CheckPoint操作，首先会让NameNode滚动Edits并生成一个空的edits.inprogress，滚动Edits的目的是给Edits打个标记，以后所有新的操作都写入edits.inprogress。</p>\n</li>\n<li><p>其他未合并的Edits和Fsimage会拷贝到SecondaryNameNode的本地，然后将拷贝的Edits和Fsimage加载到内存中进行合并，生成fsimage.chkpoint。</p>\n</li>\n<li><p>然后将fsimage.chkpoint拷贝给NameNode。</p>\n</li>\n<li><p>重命名为Fsimage后替换掉原来的Fsimage。NameNode在启动时就只需要加载之前未合并的Edits和Fsimage即可，因为合并过的Edits中的元数据信息已经被记录在Fsimage中。</p>\n</li>\n</ol>\n<p><strong><em>我们可以发现，2NN与NN之间差了一个edits_inprogress_002，所以当NN挂了的时候，2NN不能盲目的顶上去。</em></strong></p>\n<h2 id=\"2-Fsimage和Edits解析\"><a href=\"#2-Fsimage和Edits解析\" class=\"headerlink\" title=\"2 Fsimage和Edits解析\"></a>2 Fsimage和Edits解析</h2><h3 id=\"2-1-Fsimage和Edits概念\"><a href=\"#2-1-Fsimage和Edits概念\" class=\"headerlink\" title=\"2.1 Fsimage和Edits概念\"></a>2.1 Fsimage和Edits概念</h3><ol>\n<li><p>Fsimage文件：HDFS文件系统元数据的一个永久性的检查点，其中包含HDFS文件系统的所有目录和文件inode的序列化信息。</p>\n</li>\n<li><p>Edits文件：存放HDFS文件系统的所有更新操作的路径，文件系统客户端执行的所有写操作首先会被记录到Edits文件中。</p>\n</li>\n<li><p>seen_txid文件保存的是一个数字，就是最后一个edits_的数字</p>\n</li>\n<li><p>每次NameNode启动的时候都会将Fsimage文件读入内存，加载Edits里面的更新操作，保证内存中的元数据信息是最新的、同步的，可以看成NameNode启动的时候就将Fsimage和Edits文件进行了合并。</p>\n</li>\n</ol>\n<p>我们并不能直接通过cat命令查看Fsimage和Edits文件，因为Fsimage是NN的元数据序列化以后的文件，所以我们需要使用HDFS提供的命令。</p>\n<h3 id=\"2-2-oiv查看Fsimage文件\"><a href=\"#2-2-oiv查看Fsimage文件\" class=\"headerlink\" title=\"2.2 oiv查看Fsimage文件\"></a>2.2 oiv查看Fsimage文件</h3><ol>\n<li>查看oiv和oev命令</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">oiv                  apply the offline fsimage viewer to an fsimage</span><br><span class=\"line\">oiv_legacy           apply the offline fsimage viewer to an legacy fsimage</span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>基本语法</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[fzz001@hadoop001 current]$ hdfs oiv</span><br><span class=\"line\">Usage: bin/hdfs oiv [OPTIONS] -i INPUTFILE -o OUTPUTFILE</span><br><span class=\"line\"></span><br><span class=\"line\">hdfs oiv -p 文件类型 -i镜像文件 -o 转换后文件输出路径</span><br><span class=\"line\"></span><br><span class=\"line\">-p,--processor &lt;arg&gt;   Select which type of processor to apply</span><br><span class=\"line\">                       against image file. (XML|FileDistribution|Web|Delimited)</span><br><span class=\"line\">                       (Web by default)</span><br><span class=\"line\">选择要应用于文件的处理器类型，一般我们都选择XML。</span><br></pre></td></tr></table></figure>\n<ol start=\"3\">\n<li>这里我们转一下。</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[fzz001@hadoop001 current]$ hdfs oiv -p XML -i fsimage_0000000000000000441 -o fsimage.xml</span><br><span class=\"line\">[fzz001@hadoop001 current]$ cat fsimage.xml</span><br></pre></td></tr></table></figure>\n<p>我们可以把xml文件粘贴到idea里格式化一下，会好看很多。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">inode</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>16386<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">type</span>&gt;</span>DIRECTORY<span class=\"tag\">&lt;/<span class=\"name\">type</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>wcinput<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">mtime</span>&gt;</span>1565909468032<span class=\"tag\">&lt;/<span class=\"name\">mtime</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">permission</span>&gt;</span>fzz001:supergroup:rwxr-xr-x<span class=\"tag\">&lt;/<span class=\"name\">permission</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">nsquota</span>&gt;</span>-1<span class=\"tag\">&lt;/<span class=\"name\">nsquota</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">dsquota</span>&gt;</span>-1<span class=\"tag\">&lt;/<span class=\"name\">dsquota</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">inode</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">inode</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>16387<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">type</span>&gt;</span>FILE<span class=\"tag\">&lt;/<span class=\"name\">type</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>wc.input<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">replication</span>&gt;</span>3<span class=\"tag\">&lt;/<span class=\"name\">replication</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">mtime</span>&gt;</span>1565909468006<span class=\"tag\">&lt;/<span class=\"name\">mtime</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">atime</span>&gt;</span>1565909466949<span class=\"tag\">&lt;/<span class=\"name\">atime</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">perferredBlockSize</span>&gt;</span>134217728<span class=\"tag\">&lt;/<span class=\"name\">perferredBlockSize</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">permission</span>&gt;</span>fzz001:supergroup:rw-r--r--<span class=\"tag\">&lt;/<span class=\"name\">permission</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">blocks</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">block</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>1073741825<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">genstamp</span>&gt;</span>1001<span class=\"tag\">&lt;/<span class=\"name\">genstamp</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">numBytes</span>&gt;</span>48<span class=\"tag\">&lt;/<span class=\"name\">numBytes</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">block</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">blocks</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">inode</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>我们可以看到有文件类型（DIRECTORY）、文件名称（wcinput）、时间戳（1565909468032）、权限、副本数量（replication）、块大小（perferredBlockSize）、块列表（blocks）、单块的ID等等，每一个inode都是一个元数据信息。</p>\n<p><strong><font color=\"red\">但我们发现，这里其实并没有记录块所在的DataNode的信息？</font></strong><br>这里简单说一下，因为在集群启动后，要求DataNode上报数据块信息，并间隔一段时间后再次上报，后面的安全模式会细讲。</p>\n<h3 id=\"2-3-oev查看Edits文件\"><a href=\"#2-3-oev查看Edits文件\" class=\"headerlink\" title=\"2.3 oev查看Edits文件\"></a>2.3 oev查看Edits文件</h3><ol>\n<li>基本语法和oiv一样</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">hdfs oev -p 文件类型 -i编辑日志 -o 转换后文件输出路径</span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>同样，我们也转一下。</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[fzz001@hadoop001 current]$ hdfs oev -p XML -i edits_0000000000000000110-0000000000000000210 -o edits.xml</span><br></pre></td></tr></table></figure>\n<p>我们可以把xml文件粘贴到idea里格式化一下，会好看很多。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">RECORD</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">OPCODE</span>&gt;</span>OP_ADD<span class=\"tag\">&lt;/<span class=\"name\">OPCODE</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">DATA</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">TXID</span>&gt;</span>130<span class=\"tag\">&lt;/<span class=\"name\">TXID</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">LENGTH</span>&gt;</span>0<span class=\"tag\">&lt;/<span class=\"name\">LENGTH</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">INODEID</span>&gt;</span>16407<span class=\"tag\">&lt;/<span class=\"name\">INODEID</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">PATH</span>&gt;</span>/hello7.txt<span class=\"tag\">&lt;/<span class=\"name\">PATH</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">REPLICATION</span>&gt;</span>2<span class=\"tag\">&lt;/<span class=\"name\">REPLICATION</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">MTIME</span>&gt;</span>1512943607866<span class=\"tag\">&lt;/<span class=\"name\">MTIME</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">ATIME</span>&gt;</span>1512943607866<span class=\"tag\">&lt;/<span class=\"name\">ATIME</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">BLOCKSIZE</span>&gt;</span>134217728<span class=\"tag\">&lt;/<span class=\"name\">BLOCKSIZE</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">CLIENT_NAME</span>&gt;</span>DFSClient_NONMAPREDUCE_-1544295051_1<span class=\"tag\">&lt;/<span class=\"name\">CLIENT_NAME</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">CLIENT_MACHINE</span>&gt;</span>172.16.239.100<span class=\"tag\">&lt;/<span class=\"name\">CLIENT_MACHINE</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">OVERWRITE</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">OVERWRITE</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">PERMISSION_STATUS</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">USERNAME</span>&gt;</span>fzz001<span class=\"tag\">&lt;/<span class=\"name\">USERNAME</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">GROUPNAME</span>&gt;</span>supergroup<span class=\"tag\">&lt;/<span class=\"name\">GROUPNAME</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">MODE</span>&gt;</span>420<span class=\"tag\">&lt;/<span class=\"name\">MODE</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">PERMISSION_STATUS</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">RPC_CLIENTID</span>&gt;</span>908eafd4-9aec-4288-96f1-e8011d181561<span class=\"tag\">&lt;/<span class=\"name\">RPC_CLIENTID</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">RPC_CALLID</span>&gt;</span>0<span class=\"tag\">&lt;/<span class=\"name\">RPC_CALLID</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">DATA</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">RECORD</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>我们可以看到TXID是自增的，就是名字上110~210之间的，也就是操作的序号。<br>依然是记录了元数据信息，但是这些都还是没有写的数据。</p>\n<ul>\n<li>OPCODE：一个添加操作</li>\n<li>PATH：文件路径</li>\n<li>REPLICATION：副本数量。</li>\n<li>CLIENT_NAME：客户端名字</li>\n<li>CLIENT_MACHINE：客户端的IP.</li>\n<li>PERMISSION_STATUS：权限信息</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;RECORD&gt;</span><br><span class=\"line\">\t&lt;OPCODE&gt;OP_ALLOCATE_BLOCK_ID&lt;/OPCODE&gt;</span><br><span class=\"line\">\t&lt;DATA&gt;</span><br><span class=\"line\">\t\t&lt;TXID&gt;131&lt;/TXID&gt;</span><br><span class=\"line\">\t\t&lt;BLOCK_ID&gt;1073741839&lt;/BLOCK_ID&gt;</span><br><span class=\"line\">\t&lt;/DATA&gt;</span><br><span class=\"line\">&lt;/RECORD&gt;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>OP_ALLOCATE_BLOCK_ID：为文件分配块Id，相当于返回的DN地址</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;RECORD&gt;</span><br><span class=\"line\">\t&lt;OPCODE&gt;OP_SET_GENSTAMP_V2&lt;/OPCODE&gt;</span><br><span class=\"line\">\t&lt;DATA&gt;</span><br><span class=\"line\">\t\t&lt;TXID&gt;132&lt;/TXID&gt;</span><br><span class=\"line\">\t\t&lt;GENSTAMPV2&gt;1016&lt;/GENSTAMPV2&gt;</span><br><span class=\"line\">\t&lt;/DATA&gt;</span><br><span class=\"line\">&lt;/RECORD&gt;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>OP_SET_GENSTAMP_V2：申请了一个时间戳</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;RECORD&gt;</span><br><span class=\"line\">\t\t&lt;OPCODE&gt;OP_ADD_BLOCK&lt;/OPCODE&gt;</span><br><span class=\"line\">\t\t&lt;DATA&gt;</span><br><span class=\"line\">\t\t\t&lt;TXID&gt;133&lt;/TXID&gt;</span><br><span class=\"line\">\t\t\t&lt;PATH&gt;/hello7.txt&lt;/PATH&gt;</span><br><span class=\"line\">\t\t\t&lt;BLOCK&gt;</span><br><span class=\"line\">\t\t\t\t&lt;BLOCK_ID&gt;1073741839&lt;/BLOCK_ID&gt;</span><br><span class=\"line\">\t\t\t\t&lt;NUM_BYTES&gt;0&lt;/NUM_BYTES&gt;</span><br><span class=\"line\">\t\t\t\t&lt;GENSTAMP&gt;1016&lt;/GENSTAMP&gt;</span><br><span class=\"line\">\t\t\t&lt;/BLOCK&gt;</span><br><span class=\"line\">\t\t\t&lt;RPC_CLIENTID&gt;&lt;/RPC_CLIENTID&gt;</span><br><span class=\"line\">\t\t\t&lt;RPC_CALLID&gt;-2&lt;/RPC_CALLID&gt;</span><br><span class=\"line\">\t\t&lt;/DATA&gt;</span><br><span class=\"line\">\t&lt;/RECORD&gt;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>OP_ADD_BLOCK：添加块，也就说数据已经写完，把块的信息添加到元数据里面。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;RECORD&gt;</span><br><span class=\"line\">\t\t&lt;OPCODE&gt;OP_CLOSE&lt;/OPCODE&gt;</span><br><span class=\"line\">\t\t&lt;DATA&gt;</span><br><span class=\"line\">\t\t\t&lt;TXID&gt;134&lt;/TXID&gt;</span><br><span class=\"line\">\t\t\t&lt;LENGTH&gt;0&lt;/LENGTH&gt;</span><br><span class=\"line\">\t\t\t&lt;INODEID&gt;0&lt;/INODEID&gt;</span><br><span class=\"line\">\t\t\t&lt;PATH&gt;/hello7.txt&lt;/PATH&gt;</span><br><span class=\"line\">\t\t\t&lt;REPLICATION&gt;2&lt;/REPLICATION&gt;</span><br><span class=\"line\">\t\t\t&lt;MTIME&gt;1512943608761&lt;/MTIME&gt;</span><br><span class=\"line\">\t\t\t&lt;ATIME&gt;1512943607866&lt;/ATIME&gt;</span><br><span class=\"line\">\t\t\t&lt;BLOCKSIZE&gt;134217728&lt;/BLOCKSIZE&gt;</span><br><span class=\"line\">\t\t\t&lt;CLIENT_NAME&gt;&lt;/CLIENT_NAME&gt;</span><br><span class=\"line\">\t\t\t&lt;CLIENT_MACHINE&gt;&lt;/CLIENT_MACHINE&gt;</span><br><span class=\"line\">\t\t\t&lt;OVERWRITE&gt;false&lt;/OVERWRITE&gt;</span><br><span class=\"line\">\t\t\t&lt;BLOCK&gt;</span><br><span class=\"line\">\t\t\t\t&lt;BLOCK_ID&gt;1073741839&lt;/BLOCK_ID&gt;</span><br><span class=\"line\">\t\t\t\t&lt;NUM_BYTES&gt;25&lt;/NUM_BYTES&gt;</span><br><span class=\"line\">\t\t\t\t&lt;GENSTAMP&gt;1016&lt;/GENSTAMP&gt;</span><br><span class=\"line\">\t\t\t&lt;/BLOCK&gt;</span><br><span class=\"line\">\t\t\t&lt;PERMISSION_STATUS&gt;</span><br><span class=\"line\">\t\t\t\t&lt;USERNAME&gt;atguigu&lt;/USERNAME&gt;</span><br><span class=\"line\">\t\t\t\t&lt;GROUPNAME&gt;supergroup&lt;/GROUPNAME&gt;</span><br><span class=\"line\">\t\t\t\t&lt;MODE&gt;420&lt;/MODE&gt;</span><br><span class=\"line\">\t\t\t&lt;/PERMISSION_STATUS&gt;</span><br><span class=\"line\">\t\t&lt;/DATA&gt;</span><br><span class=\"line\">\t&lt;/RECORD&gt;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>OP_CLOSE：关闭流。</li>\n</ul>\n<p><strong><font color=\"red\">思考：NameNode如何确定下次开机启动的时候合并哪些Edits？</font></strong><br>我们fsimage后面有个编号，说明这个编号以前的edits都已经合并了，合并接下来的就可以了。</p>\n<h2 id=\"3-CheckPoint时间设置\"><a href=\"#3-CheckPoint时间设置\" class=\"headerlink\" title=\"3 CheckPoint时间设置\"></a>3 CheckPoint时间设置</h2><ol>\n<li>通常情况下，2NN每隔一个小时触发一次合并。</li>\n</ol>\n<p><strong><em>hdfs-default.xml</em></strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;property&gt;</span><br><span class=\"line\">  &lt;name&gt;dfs.namenode.checkpoint.period&lt;/name&gt;</span><br><span class=\"line\">  &lt;value&gt;3600&lt;/value&gt;</span><br><span class=\"line\">&lt;/property&gt;</span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>一分钟检查一次操作次数，当操作次数达到1百万时，SecondaryNameNode执行一次。</li>\n</ol>\n<p><strong><em>hdfs-default.xml</em></strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;property&gt;</span><br><span class=\"line\">  &lt;name&gt;dfs.namenode.checkpoint.txns&lt;/name&gt;</span><br><span class=\"line\">  &lt;value&gt;1000000&lt;/value&gt;</span><br><span class=\"line\">&lt;description&gt;操作动作次数&lt;/description&gt;</span><br><span class=\"line\">&lt;/property&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;property&gt;</span><br><span class=\"line\">  &lt;name&gt;dfs.namenode.checkpoint.check.period&lt;/name&gt;</span><br><span class=\"line\">  &lt;value&gt;60&lt;/value&gt;</span><br><span class=\"line\">&lt;description&gt; 1分钟检查一次操作次数&lt;/description&gt;</span><br><span class=\"line\">&lt;/property &gt;</span><br></pre></td></tr></table></figure>\n<p>我们上传一个文件，肯定不是一次操作，比如我们上传1KB的文件和上传1GB的文件所进行操作数量肯定不一样。<br>在上面中我们提到CheckPoint出发有两个条件，其实还有第三个：每次NN刚刚启动的时候，也会进行一次CheckPoint（合并）。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7c4exas9xj31rk0u0gw4.jpg\" alt=\"\"></p>\n<p>我们可以很清楚的看到，在集群启动时候，执行三个操作：加载fsimage、加载edits.log、Saving checkpoint。具体在集群上怎么呈现的呢？</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7c4kkqzb3j310w0ds40z.jpg\" alt=\"\"></p>\n<p>我们可以看到我们的分布式集群中，hadoop001启动NameNode。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7c4mbq6dhj317c06mmz0.jpg\" alt=\"\"></p>\n<p>进入到name文件夹下，可以看到current文件夹和in_use.lock，in_use.lock表示这个NameNode正在执行，有这个锁就表示别的人不能动这个元数据了。我们进入到current文件夹。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7c4oogh79j315g0nyk5r.jpg\" alt=\"\"></p>\n<p>这就是我们元数据整体存在的位置。edits_0000000000000006670-0000000000000006671 意思为记录了我们第6670到第6671次操作。因为我设置的是一分钟间隔，所以可以看到每次记录都是间隔1分钟。edits_inprogress_0000000000000013725 为我们新写的inprogress。fsimage之所以有两个，因为fsimage也会越来越多，所以它只会保留最新的和第二新的，剩下都被删了，edits永远都不会被删。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7c54dmyslj311a09ejvs.jpg\" alt=\"\"></p>\n<p>seen_txid 记录着我们现在正在记录操作的edits.inprogress编号。</p>\n<h2 id=\"4-NameNode故障处理\"><a href=\"#4-NameNode故障处理\" class=\"headerlink\" title=\"4 NameNode故障处理\"></a>4 NameNode故障处理</h2><p>NameNode故障后，可以采用两种方法恢复数据。</p>\n<h3 id=\"4-1-将SecondaryNameNode中数据拷贝到NameNode存储数据的目录\"><a href=\"#4-1-将SecondaryNameNode中数据拷贝到NameNode存储数据的目录\" class=\"headerlink\" title=\"4.1 将SecondaryNameNode中数据拷贝到NameNode存储数据的目录\"></a>4.1 将SecondaryNameNode中数据拷贝到NameNode存储数据的目录</h3><ol>\n<li><p>kill -9 NameNode进程</p>\n</li>\n<li><p>删除NameNode存储的数据（/opt/module/hadoop-2.7.2/data/tmp/dfs/name）</p>\n</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[fzz001@hadoop001 hadoop-2.7.2]$ rm -rf /opt/module/hadoop-2.7.2/data/tmp/dfs/name/*</span><br></pre></td></tr></table></figure>\n<ol start=\"3\">\n<li>拷贝SecondaryNameNode中数据到原NameNode存储数据目录</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[fzz001@hadoop001 dfs]$ scp -r atguigu@hadoop104:/opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondary/* ./name/</span><br></pre></td></tr></table></figure>\n<ol start=\"4\">\n<li>重新启动NameNode</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[fzz001@hadoop001 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure>\n<h3 id=\"4-2-使用-importCheckpoint选项启动NameNode守护进程，从而将SecondaryNameNode中数据拷贝到NameNode目录中。\"><a href=\"#4-2-使用-importCheckpoint选项启动NameNode守护进程，从而将SecondaryNameNode中数据拷贝到NameNode目录中。\" class=\"headerlink\" title=\"4.2 使用-importCheckpoint选项启动NameNode守护进程，从而将SecondaryNameNode中数据拷贝到NameNode目录中。\"></a>4.2 使用-importCheckpoint选项启动NameNode守护进程，从而将SecondaryNameNode中数据拷贝到NameNode目录中。</h3><ol>\n<li>修改hdfs-site.xml</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;property&gt;</span><br><span class=\"line\">  &lt;name&gt;dfs.namenode.checkpoint.period&lt;/name&gt;</span><br><span class=\"line\">  &lt;value&gt;120&lt;/value&gt;</span><br><span class=\"line\">&lt;/property&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;property&gt;</span><br><span class=\"line\">  &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class=\"line\">  &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp/dfs/name&lt;/value&gt;</span><br><span class=\"line\">&lt;/property&gt;</span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li><p>kill -9 NameNode进程</p>\n</li>\n<li><p>删除NameNode存储的数据（/opt/module/hadoop-2.7.2/data/tmp/dfs/name）</p>\n</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[fzz001@hadoop002 hadoop-2.7.2]$ rm -rf /opt/module/hadoop-2.7.2/data/tmp/dfs/name/*</span><br></pre></td></tr></table></figure>\n<ol start=\"4\">\n<li>如果SecondaryNameNode不和NameNode在一个主机节点上，需要将SecondaryNameNode存储数据的目录拷贝到 NameNode存储数据的平级目录，并删除in_use.lock文件</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[fzz001@hadoop002 dfs]$ scp -r atguigu@hadoop104:/opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondary ./</span><br><span class=\"line\"></span><br><span class=\"line\">[fzz001@hadoop002 namesecondary]$ rm -rf in_use.lock</span><br><span class=\"line\"></span><br><span class=\"line\">[fzz001@hadoop002 dfs]$ pwd</span><br><span class=\"line\">/opt/module/hadoop-2.7.2/data/tmp/dfs</span><br><span class=\"line\"></span><br><span class=\"line\">[fzz001@hadoop002 dfs]$ ls</span><br><span class=\"line\">data  name  namesecondary</span><br></pre></td></tr></table></figure>\n<ol start=\"5\">\n<li>导入检查点数据（等待一会ctrl+c结束掉）</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[fzz001@hadoop002 hadoop-2.7.2]$ bin/hdfs namenode -importCheckpoint</span><br></pre></td></tr></table></figure>\n<ol start=\"6\">\n<li>启动NameNode</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[fzz001@hadoop002 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure>\n","categories":["Hadoop-HDFS"],"tags":[]},{"title":"BD-HDFS-HDFS的数据流读入","url":"http://ilovenorth.cn/2019/09/25/BD-HDFS-HDFS的数据流读入/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"BD-HDFS-HDFS的数据流读入\"><a href=\"#BD-HDFS-HDFS的数据流读入\" class=\"headerlink\" title=\"BD-HDFS-HDFS的数据流读入\"></a>BD-HDFS-HDFS的数据流读入</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><ol>\n<li>HDFS读数据流程</li>\n</ol>\n<h2 id=\"HDFS读数据流程\"><a href=\"#HDFS读数据流程\" class=\"headerlink\" title=\"HDFS读数据流程\"></a>HDFS读数据流程</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7bk7d8zc7j310u0i2dgl.jpg\" alt=\"\"></p>\n<p>Client通过 Distributed FileSystem 模块向NameNode申请下载文件。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7bk8s2kx8j310q0hq0tr.jpg\" alt=\"\"></p>\n<p>NameNode通过各种维度判断文件存在，若存在则会响应客户端，然后开启输入流（因为我们要从HDFS下载数据（读），文件从客户端盘到本地磁盘是输出流（写））。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7bkdm4dmqj310m0gc3zm.jpg\" alt=\"\"></p>\n<p>流开启之后，客户端请求下载第一个Block（0-128M）</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7bkdxhxqcj31190imjtd.jpg\" alt=\"\"></p>\n<p>NameNode收到请求后，会返回一个DataNode List，因为副本数是3个，所以返回了3个。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7bkfxowjcj311i0imdi0.jpg\" alt=\"\"></p>\n<p>与上传不同，Client不再会与3个DN建立通道，而是与DN1建立通道，收到DN1的应答成功后，表示通道建立成功，开始传输Packet，剩下的两个DN作为备胎，如果与DN1建立通道失败，Client则会依次向后请求，如果都建立失败，则此次传输失败。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7bkj34nztj313i0if76i.jpg\" alt=\"\"></p>\n<p>第一块下载成功后，就会开始请求下载第二块，省去其他步骤，我们看到DN变为4~6了，说明两次DN的选择的完全独立的过程，有可能与第一次一样，也有可能不一样，<font color=\"red\">也就是说同一个文件的两块可能不在同一个DN上</font></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7bklde1fbj31370iwdif.jpg\" alt=\"\"></p>\n<p>与第一块的步骤一样，不再赘述了。这里有一点需要注意一下，就是<strong><em>文件从客户端盘到本地磁盘的输出流（写）和客户端对于HDFS开启的输入流，一直都是同一个流，没有变过。</em></strong></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7bkniz5s2j313d0f1ab6.jpg\" alt=\"\"></p>\n<p>传输完成之后，NameNode会告诉客户端数据传输完毕，然后关闭流，下载过程结束。</p>\n","categories":["Hadoop-HDFS"],"tags":[]},{"title":"BD-HDFS-HDFS的数据流写入","url":"http://ilovenorth.cn/2019/09/24/BD-HDFS-HDFS的数据流写入/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"BD-HDFS-HDFS的数据流写入\"><a href=\"#BD-HDFS-HDFS的数据流写入\" class=\"headerlink\" title=\"BD-HDFS-HDFS的数据流写入\"></a>BD-HDFS-HDFS的数据流写入</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><ol>\n<li>剖析文件写入</li>\n<li>网络拓扑-节点距离计算</li>\n<li>机架感知（副本存储节点选择）</li>\n</ol>\n<h2 id=\"1-1-剖析文件写入\"><a href=\"#1-1-剖析文件写入\" class=\"headerlink\" title=\"1.1 剖析文件写入\"></a>1.1 剖析文件写入</h2><p><strong>HDFS的写数据流程（上传）。</strong></p>\n<h3 id=\"第一步\"><a href=\"#第一步\" class=\"headerlink\" title=\"第一步\"></a>第一步</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7aer0y6qzj30s20brwev.jpg\" alt=\"\"></p>\n<ol>\n<li>我们有个200M的本地文件要上传到HDFS，首先我们需要一个客户端Client，Client通过 <strong><em>Distributed FileSystem</em></strong> 模块向NameNode申请上传请求。</li>\n</ol>\n<blockquote>\n<p>Distributed FileSystem : 整个集群的抽象封装</p>\n</blockquote>\n<h3 id=\"第二步\"><a href=\"#第二步\" class=\"headerlink\" title=\"第二步\"></a>第二步</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7af0ekkwxj30sx0c874w.jpg\" alt=\"\"></p>\n<ul>\n<li>由NameNode来审核请求是否合法，会检查相同路径是否会有重名文件、有没有上传权限、父目录是否存在。</li>\n</ul>\n<ul>\n<li>当客户端收到NameNode响应之后，会对文件进行逻辑切分（举个例子：🍰–&gt;冰箱，在真正切之前，用笔在蛋糕上花上线，还没切），然后开启输出流（因为我们要往HDFS写数据，文件从本地磁盘到客户端是输入流）</li>\n</ul>\n<h3 id=\"第三步\"><a href=\"#第三步\" class=\"headerlink\" title=\"第三步\"></a>第三步</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7afd05j57j30sq0d0q3o.jpg\" alt=\"\"></p>\n<p>有了输入流和输出流之后，就要进行流对拷了，在这之前要向NameNode发送申请，请求上传第一个Block（0-128M）</p>\n<h3 id=\"第四步\"><a href=\"#第四步\" class=\"headerlink\" title=\"第四步\"></a>第四步</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7afoq902fj30ua0eqq47.jpg\" alt=\"\"></p>\n<p>这时NameNode会返回给客户端一个 <strong><em>DataNode List ，HDFS实际存数据是在DataNode上，所以我们写数据也是往DataNode上去写</em></strong>，<font color=\"red\">这个List的数量是由集群中设置的副本数量控制的，你定义了多少副本数量，list就会返回多少DataNode节点。</font></p>\n<p>返回的DataNode并不是随机返回，返回的第一个DN1，是离Client最近的一个，后两个是根据DN1选出来的。</p>\n<blockquote>\n<p>哪个最近？后两个怎么选的？我们下面再说，这里先跳过。</p>\n</blockquote>\n<h3 id=\"第五步\"><a href=\"#第五步\" class=\"headerlink\" title=\"第五步\"></a>第五步</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7afxhgadvj30v00flmyp.jpg\" alt=\"\"></p>\n<p>拿到Datanodelist 客户端就知道往哪里传数据了</p>\n<ul>\n<li>它就会向列表中的第一个DN（离它最近）发出建立通道的请求。</li>\n<li>DN1收到请求后，顺势向DN2发出建立通道的请求。</li>\n<li>DN2同理到了DN3，由于它是最后一个，DN3就不发出建立请求了，而是应答DN2建立成功。</li>\n<li>DN2收到DN3的应答后，就会向DN1发出应答成功。</li>\n<li>DN1同理会向客户端应答成功，此时通道就建立成功。</li>\n</ul>\n<blockquote>\n<p>而且这个请求是串行的（原因一会再说~）</p>\n</blockquote>\n<h3 id=\"第六步\"><a href=\"#第六步\" class=\"headerlink\" title=\"第六步\"></a>第六步</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7am58j25pj30vb0f2762.jpg\" alt=\"\"></p>\n<p>客户端知道建立好通道以后，就开始传数据了，传的是一个packet（64K）。</p>\n<ul>\n<li>当DN1收到这个packet以后（在内存的一个buggeer收到），它一边落盘本地写，一边把packet发给DN2。</li>\n<li>DN2同理。</li>\n<li>DN3落盘，DN3落盘以后，把成功信息发给DN2。</li>\n<li>DN2只有自己成功并且收到DN3的成功信号，才会向DN1返回。</li>\n<li>DN1同理，向client发送成功，此时，一个packet就发送成功了。</li>\n</ul>\n<p><strong><em>Client不是落盘一个packet成功后才发第二个，而是一个发送队列，DN中会有一个待写的packet队列，成功之后就移除。当128M传输完毕，那么第一块文件就同时存在了3个DN中，3个副本完全一样。</em></strong></p>\n<h3 id=\"第七步\"><a href=\"#第七步\" class=\"headerlink\" title=\"第七步\"></a>第七步</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7amlul8mpj30v40cagmk.jpg\" alt=\"\"></p>\n<p>传输成功后，我们第一块的文件就传完了，关闭流以后，client告诉hdfs数据传输完毕，NN收到消息后，增加元数据（描述数据的数据），相当于数据的目录。</p>\n<h3 id=\"另一块（第二块）\"><a href=\"#另一块（第二块）\" class=\"headerlink\" title=\"另一块（第二块）\"></a>另一块（第二块）</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7amty6sbkj30v30fugng.jpg\" alt=\"\"></p>\n<p>第二块同理，省去其他步骤，我们看到红色字的地方，DN变为4~6了，说明两次DN的选择的完全独立的过程，有可能与第一次一样，也有可能不一样，<font color=\"red\">也就是说同一个文件的两块可能不在同一个DN上</font></p>\n<h3 id=\"特定步骤失败的影响\"><a href=\"#特定步骤失败的影响\" class=\"headerlink\" title=\"特定步骤失败的影响\"></a>特定步骤失败的影响</h3><p>在客户端请求建立通道时失败，则这次上传就失败了。假设在数据传输的过程中失败，分两种情况，如果客户端向DN1发送Packet失败，则上传失败；如果DN1-DN2或者DN2-DN3失败，则上传仍然继续进行，并且返回成功信号，因为我们DN1已经有了一个副本，如果我们设置的副本数是3，它会自动进行备份，再去找两台机器。</p>\n<h2 id=\"2-1-网络拓扑-节点距离计算\"><a href=\"#2-1-网络拓扑-节点距离计算\" class=\"headerlink\" title=\"2.1 网络拓扑-节点距离计算\"></a>2.1 网络拓扑-节点距离计算</h2><blockquote>\n<p>上一章，我们留了两个问题：如何判断哪个DN最近？后两个DN怎么选的？看完这一章，就能解决这两个问题了。</p>\n</blockquote>\n<p>在HDFS写数据的过程中，NameNode会选择距离待上传数据最近距离的DataNode接收数据。那么这个最近距离怎么计算呢？</p>\n<p><strong><font color=\"red\">节点距离：两个节点到达最近的共同祖先的距离总和。</font></strong></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7ayagxsxlj31uw0u0adm.jpg\" alt=\"\"></p>\n<p>机架可以理解为路由器，D1为一个数据中心，<strong><em>一个R1+3个N构成了一个NAT网络，一个D1+3个R也构成了一个NAT网络。</em></strong>    </p>\n<p>N1到N2的距离怎么算？很简单，数直线就行了。所以N1到N2的距离为2。    </p>\n<p><code>/</code>为抽象意义上的根，一个D1为一个公网出口，任意两个公网出口之间的拓扑距离为2.</p>\n<h2 id=\"3-1-机架感知（副本存储节点选择）\"><a href=\"#3-1-机架感知（副本存储节点选择）\" class=\"headerlink\" title=\"3.1 机架感知（副本存储节点选择）\"></a>3.1 机架感知（副本存储节点选择）</h2><p>上一章我们知道了如何判断哪个DN最近，这一章我们来讲一下如何选择副本DN。</p>\n<p>官方的机架感知说明：</p>\n<p><strong><em>For the common case, when the replication factor is three, HDFS’s placement policy is to put one replica on one node in the local rack, another on a different node in the local rack, and the last on a different node in a different rack.</em></strong></p>\n<blockquote>\n<p>在常见情况下，当复制因子为3时，HDFS的放置策略是将一个副本放置在本地机架中的一个节点上，将另一个副本放置在本地机架中的另一个节点上，最后一个副本放置在不同机架中的另一个节点上。</p>\n</blockquote>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7bjjosbhbj30ys0p2mz8.jpg\" alt=\"\"></p>\n<p>第一个副本在Client所处的节点上。如果客户端在集群外，随机选一个。    </p>\n<p>第二个副本和第一个副本位于相同机架的随机节点。    </p>\n<p>第三个副本位于不同机架的随机节点。</p>\n","categories":["Hadoop-HDFS"],"tags":[]},{"title":"BD-HDFS-HDFS概述","url":"http://ilovenorth.cn/2019/09/23/BD-HDFS-HDFS概述/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"BD-HDFS-HDFS概述\"><a href=\"#BD-HDFS-HDFS概述\" class=\"headerlink\" title=\"BD-HDFS-HDFS概述\"></a>BD-HDFS-HDFS概述</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><ol>\n<li>产出背景及定义</li>\n<li>优缺点</li>\n<li>组成架构</li>\n<li>文件块大小</li>\n</ol>\n<h2 id=\"1-1-HDFS-产出背景及定义\"><a href=\"#1-1-HDFS-产出背景及定义\" class=\"headerlink\" title=\"1.1 HDFS 产出背景及定义\"></a>1.1 HDFS 产出背景及定义</h2><h3 id=\"1-1-1-HDFS产生背景\"><a href=\"#1-1-1-HDFS产生背景\" class=\"headerlink\" title=\"1.1.1 HDFS产生背景\"></a>1.1.1 HDFS产生背景</h3><p>随着数据量越来越大，在一个操作系统存不下所有的数据，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，迫切<font color=\"red\">需要一种系统来管理多台机器上的文件</font>，这就是分布式文件管理系统。HDFS只是<font color=\"red\">分布式文件管理系统中的一种。</font></p>\n<h3 id=\"1-1-2-HDFS定义\"><a href=\"#1-1-2-HDFS定义\" class=\"headerlink\" title=\"1.1.2 HDFS定义\"></a>1.1.2 HDFS定义</h3><font color=\"red\"></font><br><font color=\"red\">HDFS（Hadoop Distributed File System），它是一个文件系统</font>，用于存储文件，通过目录树来定位文件；<font color=\"red\">其次，它是分布式</font>，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。<br><br><font color=\"red\">HDFS的使用场景：适合一次写入，多次读出的场景，且不支持文件的修改。</font>适合用来做数据分析，并不适合用来网盘应用。<br><br>## 1.2 HDFS优缺点<br><br>### 1.2.1 优点<br><br><strong>1. 高容错性</strong><br><br><em> 数据自动保存多个副本。他通过增加副本的形式，提高容错性。<br>    <img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g79kehgoekj30d9049aa3.jpg\" alt=\"\">\n\n</em> 某一个副本丢失以后，他可以自动恢复。<br>    <img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g79kg97551j30ii0480sx.jpg\" alt=\"\"><br><br><strong>2. 适合处理大数据</strong><br><br><em> 数据规模：能够处理数据规模达到GB、TB、甚至<font color=\"red\">PB级别的数据</font>。\n</em> 文件规模：能够处理<font color=\"red\"> 百万 </font>规模以上的<font color=\"red\">文件数量</font>，数量相当之大。<br><br><strong>3. 可构建在廉价的机器上，通过多副本鸡翅，提高可靠性。</strong><br><br>### 1.2.2 缺点<br><br><strong>1. <font color=\"red\">不适合低延时数据访问</font>，比如毫秒级的存储数据，是做不到的。</strong><br><br><strong>2. <font color=\"red\">无法高效的对大量小文件进行存储</font></strong><br><br><em> 存储大量小文件的话，它会占用NameNode大量的内存来存储目录和块信息。这样是不可取的，因为NameNode的内存总是有限的。\n</em> 小文件存储的寻址时间会超过读取时间，它违反了HDFS的设计目标。<br>* 不支持并发写入，不允许文件随机修改。<br><br><strong>3. 一个文件只能有一个写，不允许多个线程同时写</strong><br><br><strong>4. <font color=\"red\">仅支持数据append(追加)</font>，不支持文件的随机修改</strong><br><br>## 1.3 HDFS组成架构<br><br><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g79knt9hkxj30mc0g4wg1.jpg\" alt=\"\"><br><br>#### <font color=\"#5599FF\">1. NameNode（nn）：就是Master，它是一个主管、管理者。</font>\n\n<blockquote>\n<p>HDFS 最重要的角色</p>\n</blockquote>\n<ol>\n<li>管理HDFS的名称空间。</li>\n<li>配置副本策略。</li>\n<li>管理数据块（Block）映射信息。</li>\n<li><font color=\"red\">处理所有客户端读写请求</font>。</li>\n</ol>\n<h4 id=\"2-DataNode（dn）：就是Slave。NameNode下达命令，DataNode执行实际的操作。\"><a href=\"#2-DataNode（dn）：就是Slave。NameNode下达命令，DataNode执行实际的操作。\" class=\"headerlink\" title=\"2. DataNode（dn）：就是Slave。NameNode下达命令，DataNode执行实际的操作。\"></a><font color=\"#5599FF\">2. DataNode（dn）：就是Slave。NameNode下达命令，DataNode执行实际的操作。</font></h4><ol>\n<li>存储实际的数据块。</li>\n<li>执行数据款的读写操作。</li>\n</ol>\n<h4 id=\"3-Client：就是客户端\"><a href=\"#3-Client：就是客户端\" class=\"headerlink\" title=\"3. Client：就是客户端\"></a><font color=\"#5599FF\">3. Client：就是客户端</font></h4><ol>\n<li>文件切分。文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行上传。</li>\n<li>与NameNode交互，获取文件的文职信息。</li>\n<li>与DataNode交互，读取或者写入数据。</li>\n<li>Client提供一些命令来管理HDFS，比如NameNode格式化。</li>\n<li>Client可以通过一些命令来访问HDFS，比如对HDFS增删改查操作。</li>\n</ol>\n<h4 id=\"4-Secondery-NameNode（2nn）：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。\"><a href=\"#4-Secondery-NameNode（2nn）：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。\" class=\"headerlink\" title=\"4. Secondery NameNode（2nn）：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。\"></a><font color=\"#5599FF\">4. Secondery NameNode（2nn）：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。</font></h4><ol>\n<li>辅助NameNode，分担其工作量，比如定期合并Fsimage和Edits，并推送给NameNode。</li>\n</ol>\n<h2 id=\"1-4-HDFS-文件块大小\"><a href=\"#1-4-HDFS-文件块大小\" class=\"headerlink\" title=\"1.4 HDFS 文件块大小\"></a>1.4 HDFS 文件块大小</h2><p>HDFS的文件在物理上是分块存储（block），块的大小可以通过配置参数（dfs.blocksize）来规定，默认大小在Hadoop 2.x版本中是128M，老版本中是64M。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g7ae4hv6bdj30qi0b7402.jpg\" alt=\"\"></p>\n<p><strong>Q&amp;A</strong></p>\n<p>Q： 为什么块的大小不能设置的太大，也不能设置的太小？</p>\n<ul>\n<li>HDFS的块设置<font color=\"red\">太小，会增加寻址时间</font>，程序一直在找块的开始位置。</li>\n<li>如果块设置的<font color=\"red\">太大</font>，从<font color=\"red\">磁盘传输数据的时间</font>会明显<font color=\"red\">大于定位这个块开始位置所需的时间</font>。导致MapReduce程序在处理大块数据时，会非常慢。</li>\n</ul>\n<p><strong><font color=\"red\">总结：HDFS块的大小设置取决于磁盘传输速率。</font></strong></p>\n","categories":["Hadoop-HDFS"],"tags":[]},{"title":"并发编程专题--现代计算机理论模型与工作原理","url":"http://ilovenorth.cn/2019/09/01/并发编程专题-现代计算机理论模型与工作原理/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"并发编程专题–现代计算机理论模型与工作原理\"><a href=\"#并发编程专题–现代计算机理论模型与工作原理\" class=\"headerlink\" title=\"并发编程专题–现代计算机理论模型与工作原理\"></a>并发编程专题–现代计算机理论模型与工作原理</h1><h2 id=\"现代计算机主要结构组成\"><a href=\"#现代计算机主要结构组成\" class=\"headerlink\" title=\"现代计算机主要结构组成\"></a>现代计算机主要结构组成</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g6j9rce0mvj30zk0mctbf.jpg\" alt=\"\"></p>\n<p>主要的部分其实就是CPU和存储器，也就是内存条，CPU通过IO总线从内存中取出数据，load到CPU的缓存中（高速缓冲存储器），因为CPU的速度非常高，一般在2.6GHz的运算速度，而内存的计算速度（DDR3为例），一般在1000M左右，是跟不上CPU的速度的。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g6j9ylyc2ij315q0ruqdj.jpg\" alt=\"\"></p>\n<p>如图，我们可以看到三级缓存的结构。因为CPU通过IO总线从内存中取出数据，但是我们能看到，很多的外设等都从IO总线通信，由于IO总线是有带宽的，就像公路堵车一样，如果CPU每次运算都从内存中取数据，就会造成IO堵塞。</p>\n<p>所以现在的解决方式是，先把内存条中要执行程序的指令复制一份出来，到CPU缓存中去。如Intel处理器，这几个元件的运算速度：</p>\n<blockquote>\n<p>寄存器 &gt; L1 &gt; L2 &gt; L3 &gt; 内存条。</p>\n</blockquote>\n<p>大家可能会问，既然高速缓冲存储器速断比内存条快那么多，为什么不都用高速缓冲存储器？</p>\n<blockquote>\n<p>因为不管内存条是什么，读写数据都需要走IO总线，这个速度是快不了的，而高速缓冲存储器则是内嵌在CPU中，因此速度快同样成本也是相当高的。</p>\n</blockquote>\n<p>举个例子来梳理一下CPU与内存之间的交互顺序：<br>假如有一个main()方法，定义 a=1 。</p>\n<ol>\n<li>首先第一步，从内存中将 a=1 copy一份，通过总线load到L3。</li>\n<li>然后逐级往上复制，L3-&gt;L2-&gt;L1-&gt;寄存器.</li>\n<li>从寄存器中取出指令码，送到ALU（运算逻辑单元）进行相应的运算。</li>\n<li>算完之后，将结果写回到寄存器中，然后同步到缓存。</li>\n<li>L1-&gt;L2-&gt;L3依次逐级往下复制，至于L3中运算结果何时写回内存是不确定的，看CPU什么时候有空闲，再写回到内存条。</li>\n</ol>\n<p>强制将运算结果写回内存的办法？</p>\n<blockquote>\n<p>缓存空间不够用的时候，会通过FIFO、最久未使用等算法将缓存空间让出来。</p>\n</blockquote>\n<p>然而何时写回内存，我们并不清楚，所以我们可以通过汇编的<code>#LOCK</code>信号，也就是接下来我们要聊一聊的重点：<strong>MESI 缓存一致性协议</strong></p>\n<p>在讲缓存一致性协议之前，我们先聊聊CPU多核缓存架构。</p>\n<h2 id=\"CPU多核缓存架构\"><a href=\"#CPU多核缓存架构\" class=\"headerlink\" title=\"CPU多核缓存架构\"></a>CPU多核缓存架构</h2><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g6jax5l7uqj30w70u0tar.jpg\" alt=\"\"></p>\n<p>CPU的每个核上都会配备寄存器，每个主板又会搭载多个CPU，对于我们来说，真正关心的部分就是如上图所示。<br>由于可以有多个CPU，我们根据下面的场景来谈谈其中的问题。</p>\n<p>假设，主内存中有一个变量<code>X = 1</code>，然后我们做一个加1运算。</p>\n<ol>\n<li>假设此时有两个线程在跑T1,T2，两个线程都需要这个变量X，CPU先从寄存器中通过指令查找X变量的地址。</li>\n<li>由于没找到，CPU会再去问CPU缓存L1，如果L1中有则返回，没有就逐级往下找，直到内从中取。</li>\n<li>如果都没有，就会从内存中复制一份X变零的值，再load到了CPU缓存L3中，逐级向上，将数据读到寄存器中，送到ALU（运算逻辑单元）进行相应的运算。</li>\n</ol>\n<p><strong>这里就有一个很明显的问题，我们两个跑在不同CPU上的线程，同时从内存中取到了 X=1 ，在其各自的CPU缓存中，各存在X=1的副本</strong></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g6jbcf6acmj31a30u0go1.jpg\" alt=\"\"></p>\n<p>现在，两个CPU同时对X变量进行+1操作。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g6jo6rn2m7j319r0u0413.jpg\" alt=\"\"></p>\n<p>然后将这个结果写会到主内存中，这个时候就会发生一个问题，本质上我们希望加两次，X=3，但因为CPU1和CPU2都是拷贝主内存的数据，所以CPU2并不知道CPU1也做了+1的运算，因为我们写回主存也是copy结果副本，所以结果出现了问题。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g6jp0818v1j315a0u0tbu.jpg\" alt=\"\"></p>\n<p>为了保证我们的结果是正确的，我们想出了两种解决问题方式。</p>\n<blockquote>\n<ol>\n<li>总线加锁</li>\n<li>缓存一致性协议</li>\n</ol>\n</blockquote>\n<h3 id=\"总线加锁\"><a href=\"#总线加锁\" class=\"headerlink\" title=\"总线加锁\"></a>总线加锁</h3><p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g6joidngawj314a0u0tbq.jpg\" alt=\"\"></p>\n<p>早期奔腾处理器，通过总线加锁来保证一致性，当CPU想要访问内存时，首先会对总线加锁，为了避免CPU2去抢资源，加锁之后，CPU2就没有办法读写内存数据了。</p>\n<p>这种的性能实在太低，相当于CPU2在获取数据时，直接就瘫痪了。</p>\n<h3 id=\"缓存一致性协议（MESI）\"><a href=\"#缓存一致性协议（MESI）\" class=\"headerlink\" title=\"缓存一致性协议（MESI）\"></a>缓存一致性协议（MESI）</h3><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">状态</th>\n<th style=\"text-align:center\">描述</th>\n<th style=\"text-align:center\">监听任务</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">M</td>\n<td style=\"text-align:center\">修改 (Modified)</td>\n<td style=\"text-align:center\">该Cache line有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。    缓存行必须时刻监听所有试图读该缓存行相对就主存的操作，这种操作必须在缓存将该缓存行写回主存并将状态变成S（共享）状态之前被延迟执行。</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">E</td>\n<td style=\"text-align:center\">独享、互斥 (Exclusive)</td>\n<td style=\"text-align:center\">该Cache line有效，数据和内存中的数据一致，数据只存在于本Cache中。    缓存行也必须监听其它缓存读主存中该缓存行的操作，一旦有这种操作，该缓存行需要变成S（共享）状态。</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">S</td>\n<td style=\"text-align:center\">共享 (Shared)</td>\n<td style=\"text-align:center\">该Cache line有效，数据和内存中的数据一致，数据存在于很多Cache中。    缓存行也必须监听其它缓存使该缓存行无效或者独享该缓存行的请求，并将该缓存行变成无效（Invalid）。</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">I</td>\n<td style=\"text-align:center\">无效 (Invalid)</td>\n<td style=\"text-align:center\">该Cache line无效。    无</td>\n</tr>\n</tbody>\n</table>\n<p>表格看起来很难理解，我们举个例子。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g6jp3ras18j313h0u0juj.jpg\" alt=\"\"></p>\n<p><strong>缓存一致性协议如何工作？数据的IO依然然通过bus总线，然而bus总线将遵循缓存一致性协议。这里我们就涉及一个概念：CPU缓存中，最小存储单元的概念</strong><br>缓存行。 </p>\n<p>首先，我们需要把X=1copy一份到我们的CPU1缓存当中，同时，把X置为<code>独占（E）</code>的状态。通过汇编的<code>#LOCK</code>信号，触发缓存一致性协议（MESI）</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g6jpkp4clhj31740u0whu.jpg\" alt=\"\"></p>\n<p>此时CPU1也会<strong>时刻监听（总线嗅探机制）</strong>BUS中，其他CPU对这块内存空间的操作。假如，在CPU1还没有写入结果时，CPU2从内存中读取X=1到了CPU2的缓存，这时，CPU1嗅探了CPU2的操作，<strong>于是，CPU1将X由独占（E）状态，改变为共享（S）状态</strong></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g6jpr80whej317k0u0n0t.jpg\" alt=\"\"></p>\n<p>CPU1继续做+1运算操作，X=2.并将结果写回到寄存器，并同步到CPU缓存，准备把结果写回到主存当中去。首先，<strong>锁住这个存放数据的缓存行，把共享（S）状态，改变为修改（M）状态，然后向总线发出一个消息：内容就是告诉其他CPU，我已经把状态改为M，要即将写回到内存中了</strong>，与此同时，其他的CPU也一直在监听BUS总线中的消息，当CPU2得知这个消息后，<strong>会把CPU2中这个存放数据的缓存行，把共享（S）状态，改变为无效（I）状态</strong>。    </p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g6jq9mw5ixj316s0u0wja.jpg\" alt=\"\"></p>\n<p>接着CPU1将X=2回写到主从当中来，回写完毕之后，<strong>CPU1将缓存中X=2的状态改变为独占（E）状态</strong>，由于CPU2中这个存放数据的缓存行为无效（I）状态，如果CPU2还想访问这个变量，将会把CPU缓存中的X丢弃，重新去主存中读取X变量。CPU1嗅探了CPU2的操作，<strong>于是，CPU1再次将X由独占（E）状态，改变为共享（S）状态</strong></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/006y8mN6ly1g6jqafklftj314b0u0n0z.jpg\" alt=\"\"></p>\n<p>Q1：如果两个CPU同时修改S状态为M状态，这时听谁的？</p>\n<blockquote>\n<p>A：一个指令周期内会进行裁决，有可能是CPU1，也有可能是CPU2，谁赢谁有效，另一个置为无效。如何裁决是通过硬件完成的，这里就不讨论了。</p>\n</blockquote>\n<p>Q2：什么失效了？</p>\n<blockquote>\n<p>裁决失败，整个这一条缓存行失效。缓存行（最小存储单元），大小有可能是32字节、64字节，具体看CPU是哪家的CPU。</p>\n</blockquote>\n<p>Q3：无效之后，是否会继续重新去内存中 读数据？</p>\n<blockquote>\n<p>A：这个不一定，是通过你的程序段来控制的。比如unsafe(魔术类)，或者while循环等，需要一个触发机制。</p>\n</blockquote>\n<p>JMM（java内存模型）其实就是CPU多级缓存架构的一个抽象，是一组规范，并不是真实存在的东西，规范的来源就是JVM本身就是用来屏蔽底层硬件资源的不同（不同的操作系统）。</p>\n<p>Q4：什么时候缓存一致性协议会失效？</p>\n<blockquote>\n<p>如果说X的存储长度 &gt; 一个缓存行，比如横跨了两个缓存行，这样是没有办法加锁的，这时缓存一致性协议会失效，就会去加总线锁。<br>再一个就是CPU本身不支持缓存一致性协议（奔腾系列）。</p>\n</blockquote>\n","categories":["并发编程专题"],"tags":[]},{"title":"redis 集群原理分析","url":"http://ilovenorth.cn/2019/03/13/redis-集群原理分析/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"redis-集群原理分析\"><a href=\"#redis-集群原理分析\" class=\"headerlink\" title=\"redis 集群原理分析\"></a>redis 集群原理分析</h1><h2 id=\"原理分析\"><a href=\"#原理分析\" class=\"headerlink\" title=\"原理分析\"></a>原理分析</h2><p>Redis Cluster 将所有数据划分为 16384 的 slots(槽位)，每个节点负责其中一部分槽位。槽位的信息存储于每个节点中。只有master节点才有槽位。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">192.168.187.200:8001&gt; cluster nodes</span><br><span class=\"line\">9c4b4fe726ff6bc380b65c8716e65cdac8f9e2b6 192.168.187.201:8005@18005 slave b79e767ee587656222e24b0e2605213345a91c9c 0 1551146483000 5 connected</span><br><span class=\"line\">3f60a2638aacb3a6a51dad4536e0062005b80d66 192.168.187.202:8006@18006 master - 0 1551146484100 7 connected 0-5460</span><br><span class=\"line\">b79e767ee587656222e24b0e2605213345a91c9c 192.168.187.202:8003@18003 master - 0 1551146483595 3 connected 10923-16383</span><br><span class=\"line\">b61e5639764a954054d5d5690f72dca33f83b7cf 192.168.187.200:8001@18001 myself,slave 3f60a2638aacb3a6a51dad4536e0062005b80d66 0 1551146484000 1 connected</span><br><span class=\"line\">3f3a3707957b23b9c1b0ffb28ec2a2d57845a130 192.168.187.201:8002@18002 master - 0 1551146483595 11 connected 5461-10922</span><br><span class=\"line\">4641fe0918cb54a280b5f4d63e22cc672d6919d0 192.168.187.200:8004@18004 slave 3f3a3707957b23b9c1b0ffb28ec2a2d57845a130 0 1551146484608 11 connected</span><br></pre></td></tr></table></figure>\n<ul>\n<li>0-5460</li>\n<li>5461-10922</li>\n<li>10923-16383</li>\n</ul>\n<p>这些槽位是在逻辑上的，最多redis支持16384个槽位，也就是16384个机器，在没有设置槽位分配时，默认是平均分配的。</p>\n<p>当 Redis Cluster 的客户端来连接集群时，它也会得到一份集群的槽位配置信息，<strong>并将其缓存在客户端本地</strong>。这样当客户端要查找某个 key 时，可以直接定位到目标节点。同时因为槽位的信息可能会存在客户端与服务器不一致的情况，还需要纠正机制来实现槽位信息的校验调整。</p>\n<h2 id=\"槽位定位算法\"><a href=\"#槽位定位算法\" class=\"headerlink\" title=\"槽位定位算法\"></a>槽位定位算法</h2><p>Cluster 默认会对 key 值使用 crc16 算法进行 hash 得到一个整数值，然后用这个整数值对 16384 进行取模来得到具体槽位。</p>\n<font color=\"red\">HASH_SLOT = CRC16(key) mod 16384</font>\n\n<h2 id=\"跳转重定位\"><a href=\"#跳转重定位\" class=\"headerlink\" title=\"跳转重定位\"></a>跳转重定位</h2><p><strong>注意：redis-cli是没有定位算法的，jedis是有定位算法的</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">192.168.187.200:8001&gt; get name</span><br><span class=\"line\">-&gt; Redirected to slot [5798] located at 192.168.187.201:8002</span><br><span class=\"line\">&quot;fzz&quot;</span><br><span class=\"line\">192.168.187.201:8002&gt;</span><br></pre></td></tr></table></figure>\n<p>我们刚才通过redis-cli连接上了8001这台机器，我们执行一下get命令，看着日志就会很清晰的明白：我们在8001机器上执行get命令，通过redis发现name这个key的槽位是5798，根据一开始打印的集群节点信息 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">192.168.187.201:8002@18002 master - 0 1551146483595 11 connected 5461-10922</span><br></pre></td></tr></table></figure>\n<p>我们发现5798在5461-10922之间，所以redis集群帮我们重定向到8002这台机器，并输出了key的value值：fzz。</p>\n<p>当客户端向一个错误的节点发出了指令，该节点会发现指令的 key 所在的槽位并不归自己管理，这时它会向客户端发送一个特殊的跳转指令携带目标操作的节点地址，告诉客户端去连这个节点去获取数据。客户端收到指令后除了跳转到正确的节点上去操作，还会同步更新纠正本地的槽位映射表缓存，后续所有 key 将使用新的槽位映射表。</p>\n<h2 id=\"水平扩展\"><a href=\"#水平扩展\" class=\"headerlink\" title=\"水平扩展\"></a>水平扩展</h2><p>Redis3.0以后的版本虽然有了集群功能，提供了比之前版本的哨兵模式更高的性能与可用性，但是集群的水平扩展却比较麻烦，今天就来带大家看看redis高可用集群如何做水平扩展，<font color=\"red\">原始集群(见下图)由6个节点组成，6个节点分布在三台机器上，采用三主三从的模式</font></p>\n<p><img src=\"https://ws3.sinaimg.cn/large/006tKfTcly1g118vvemroj30bj063tib.jpg\" alt=\"\"></p>\n<h3 id=\"1-启动集群\"><a href=\"#1-启动集群\" class=\"headerlink\" title=\"1.启动集群\"></a>1.启动集群</h3><ul>\n<li>启动整个集群</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">/usr/local/redis-5.0.2/src/redis-server /usr/local/redis-cluster/8001/redis.conf</span><br><span class=\"line\"> /usr/local/redis-5.0.2/src/redis-server /usr/local/redis-cluster/8002/redis.conf</span><br><span class=\"line\">/usr/local/redis-5.0.2/src/redis-server /usr/local/redis-cluster/8003/redis.conf</span><br><span class=\"line\"> /usr/local/redis-5.0.2/src/redis-server /usr/local/redis-cluster/8004/redis.conf</span><br><span class=\"line\"> /usr/local/redis-5.0.2/src/redis-server /usr/local/redis-cluster/8005/redis.conf</span><br><span class=\"line\"> /usr/local/redis-5.0.2/src/redis-server /usr/local/redis-cluster/8006/redis.conf</span><br></pre></td></tr></table></figure>\n<ul>\n<li>客户端连接8001端口的redis实例</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">/usr/local/redis-5.0.2/src/redis-cli -a fzz -c -h 192.168.0.61 -p 8001</span><br></pre></td></tr></table></figure>\n<ul>\n<li>查看集群状态</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">192.168.0.61:8001&gt; cluster  nodes</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://ws4.sinaimg.cn/large/006tKfTcly1g118xw7ib4j30bj05bdo6.jpg\" alt=\"\"></p>\n<p> 从上图可以看出，整个集群运行正常，三个master节点和三个slave节点，8001端口的实例节点存储0-5460这些hash槽，8002端口的实例节点存储5461-10922这些hash槽，8003端口的实例节点存储10923-16383这些hash槽，这三个master节点存储的所有hash槽组成redis集群的存储槽位，slave点是每个主节点的备份从节点，不显示存储槽位 </p>\n<h3 id=\"2-集群操作\"><a href=\"#2-集群操作\" class=\"headerlink\" title=\"2.集群操作\"></a>2.集群操作</h3><p>我们在原始集群基础上再增加一主(8007)一从(8008)，增加节点后的集群参见下图，新增节点用虚线框表示</p>\n<p><img src=\"https://ws2.sinaimg.cn/large/006tKfTcly1g118yplbeaj30bj06a7e7.jpg\" alt=\"\"></p>\n<ul>\n<li><p><font color=\"green\">增加redis实例</font><br>方式在上一遍已经介绍完了，大家按以前自行配置就好。</p>\n</li>\n<li><font color=\"green\">查看redis集群的命令帮助</font>\n\n</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">cd /usr/local/redis-5.0.2</span><br><span class=\"line\">src/redis-cli --cluster help</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://ws2.sinaimg.cn/large/006tKfTcly1g1190wwagrj30bj0a27kc.jpg\" alt=\"\"></p>\n<ol>\n<li>create：创建一个集群环境host1:port1 … hostN:portN</li>\n<li>call：可以执行redis命令</li>\n<li>add-node：将一个节点添加到集群里，第一个参数为新节点的ip:port，第二个参数为集群中任意一个已经存在的节点的ip:port </li>\n<li>del-node：移除一个节点</li>\n<li>reshard：重新分片</li>\n<li>check：检查集群状态 </li>\n</ol>\n<ul>\n<li><font color=\"green\">配置8007为集群主节点</font>    \n\n</li>\n</ul>\n<p>使用add-node命令新增一个主节点8007(master)，绿色为新增节点，红色为已知存在节点，看到日志最后有”[OK] New node added correctly”提示代表新节点加入成功</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">src/redis-cli --cluster add-node 192.168.0.64:8007 192.168.0.61:8001</span><br></pre></td></tr></table></figure>\n<p>查看集群状态</p>\n<p><img src=\"https://ws4.sinaimg.cn/large/006tKfTcly1g1193s43s5j30bj02vdk7.jpg\" alt=\"\"></p>\n<font color=\"red\">注意：当添加节点成功以后，新增的节点不会有任何数据，因为它还没有分配任何的slot(hash槽)，我们需要为新节点手工分配hash槽</font>    \n\n<p>使用redis-cli命令为8007分配hash槽，找到集群中的任意一个主节点(红色位置表示集群中的任意一个主节点)，对其进行重新分片工作。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">/usr/local/redis-5.0.2/src/redis-cli --cluster reshard 192.168.0.61:8001</span><br><span class=\"line\">输出如下：</span><br><span class=\"line\">... ...</span><br><span class=\"line\">How many slots do you want to move (from 1 to 16384)? 600</span><br><span class=\"line\">(ps:需要多少个槽移动到新的节点上，自己设置，比如600个hash槽)</span><br><span class=\"line\">What is the receiving node ID? eb57a5700ee6f9ff099b3ce0d03b1a50ff247c3c</span><br><span class=\"line\">(ps:把这600个hash槽移动到哪个节点上去，需要指定节点id)</span><br><span class=\"line\">Please enter all the source node IDs.</span><br><span class=\"line\">  Type 'all' to use all the nodes as source nodes for the hash slots.</span><br><span class=\"line\">  Type 'done' once you entered all the source nodes IDs.</span><br><span class=\"line\">Source node 1:all</span><br><span class=\"line\">(ps:输入all为从所有主节点(8001,8002,8003)中分别抽取相应的槽数指定到新节点中，抽取的总槽数为600个)</span><br><span class=\"line\"> ... ...</span><br><span class=\"line\">Do you want to proceed with the proposed reshard plan (yes/no)? yes</span><br><span class=\"line\">(ps:输入yes确认开始执行分片任务)</span><br><span class=\"line\">... ...</span><br></pre></td></tr></table></figure>\n<p>查看下最新的集群状态    </p>\n<p><img src=\"https://ws4.sinaimg.cn/large/006tKfTcly1g11954jbzwj30bj033dkk.jpg\" alt=\"\"></p>\n<font color=\"red\">如上图所示，现在我们的8007已经有hash槽了，也就是说可以在8007上进行读写数据啦！到此为止我们的8007已经加入到集群中，并且是主节点(Master)</font>    \n\n<ul>\n<li><font color=\"green\">配置8008为8007的从节点</font>\n\n</li>\n</ul>\n<p>添加从节点8008到集群中去并查看集群状态    </p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">src/redis-cli --cluster add-node 192.168.0.64:8008 192.168.0.61:8001</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://ws2.sinaimg.cn/large/006tKfTcly1g1196kk0ndj30bj03dn2c.jpg\" alt=\"\"></p>\n<p>如图所示，还是一个master节点，没有被分配任何的hash槽。<br>我们需要执行replicate命令来指定当前节点(从节点)的主节点id为哪个,首先需要连接新加的8008节点的客户端，然后使用集群命令进行操作，把当前的8008(slave)节点指定到一个主节点下(这里使用之前创建的8007主节点，红色表示节点id)</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">src/redis-cli -c -h 192.168.0.64 -p 8008</span><br><span class=\"line\">192.168.0.61:8008&gt; cluster replicate eb57a5700ee6f9ff099b3ce0d03b1a50ff247c3c</span><br></pre></td></tr></table></figure>\n<p>查看集群状态，8008节点已成功添加为8007节点的从节点</p>\n<p><img src=\"https://ws4.sinaimg.cn/large/006tKfTcly1g1197hk77nj30bj03943i.jpg\" alt=\"\"></p>\n<h2 id=\"Redis集群选举原理分析\"><a href=\"#Redis集群选举原理分析\" class=\"headerlink\" title=\"Redis集群选举原理分析\"></a>Redis集群选举原理分析</h2><p>当slave发现自己的master变为FAIL状态时，便尝试进行Failover，以期成为新的master。由于挂掉的master可能会有多个slave，从而存在多个slave竞争成为master节点的过程，其过程如下：</p>\n<ol>\n<li>slave发现自己的master变为FAIL</li>\n<li>将自己记录的集群currentEpoch加1（集群选举周期，cluster info查看），并广播FAILOVER_AUTH_REQUEST 信息</li>\n<li>其他节点收到该信息，只有master响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个从节点发送的epoch信息只发送一次ack</li>\n<li>尝试failover的slave收集FAILOVER_AUTH_ACK</li>\n<li>超过半数后变成新Master</li>\n<li>广播Pong通知其他集群节点。</li>\n</ol>\n<p>假如集群3的master挂了，slave1和slave2分别向其他两个master节点发送FAILOVER_AUTH_REQUEST 信息来竞选master位置，假如master1节点先收到slave1节点的竞选请求信息，它就会给slave节点发送一个FAILOVER_AUTH_ACK验证，证明它投票给了slave1节点，与此同时，master1节点将不再接受slave2节点的请求信息，同理，如果master2节点也先接收到了slave1节点的竞选请求信息，它也会给slave节点发送一个FAILOVER_AUTH_ACK验证，证明它投票给了slave1节点，此时slave1有了两票，超过了当前master节点（2台）的半数，即成为master节点。所以redis集群，必须至少有3个master节点。</p>\n<p><strong>很容易想出一种情况，slave1收到了master1的验证通过信息，slave2收到master2的验证通过信息，2台平票，怎么办？</strong></p>\n<p>从节点并不是在主节点一进入 FAIL 状态就马上尝试发起选举，而是有一定延迟，一定的延迟确保我们等待FAIL状态在集群中传播，slave如果立即尝试选举，其它masters或许尚未意识到FAIL状态，可能会拒绝投票    </p>\n<ul>\n<li>延迟计算公式：    </li>\n</ul>\n<p>DELAY = 500ms + random(0 ~ 500ms) + SLAVE_RANK * 1000ms</p>\n<ul>\n<li>SLAVE_RANK表示此slave已经从master复制数据的总量的rank。Rank越小代表已复制的数据越新。这种方式下，持有最新数据的slave将会首先发起选举（理论上）。</li>\n</ul>\n","categories":["分布式专题"],"tags":[]},{"title":"redis 高可用集群搭建","url":"http://ilovenorth.cn/2019/03/12/redis-高可用集群搭建/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"Redis-高可用集群搭建\"><a href=\"#Redis-高可用集群搭建\" class=\"headerlink\" title=\"Redis 高可用集群搭建\"></a>Redis 高可用集群搭建</h1><h2 id=\"1、Redis集群方案比较\"><a href=\"#1、Redis集群方案比较\" class=\"headerlink\" title=\"1、Redis集群方案比较\"></a>1、Redis集群方案比较</h2><h3 id=\"哨兵模式\"><a href=\"#哨兵模式\" class=\"headerlink\" title=\"哨兵模式\"></a>哨兵模式</h3><p><img src=\"https://ws1.sinaimg.cn/large/006tKfTcly1g0zt79ykysj30bj065487.jpg\" alt=\"\"></p>\n<p>在redis3.0以前的版本要实现集群一般是借助哨兵sentinel工具来监控master节点的状态，如果master节点异常，则会做主从切换，将某一台slave作为master，哨兵的配置略微复杂，并且性能和高可用性等各方面表现一般，<strong>特别是在主从切换的瞬间存在访问瞬断的情况</strong>，<strong>而且哨兵模式只有一个主节点对外提供服务，没法支持很高的并发，且单个主节点内存也不宜设置得过大，否则会导致持久化文件过大，影响数据恢复或主从同步的效率。</strong></p>\n<ul>\n<li>客户端先访问哨兵，拿到主节点ip，然后再去访问master节点。</li>\n<li>哨兵监控主节点，当主节点挂了，哨兵收到通知，然后通过选举策略在从库中选取一个新的master。</li>\n<li>当客户端连接master发现挂了，则会再次访问哨兵，拿到新的masterIP。</li>\n</ul>\n<p>因为单台redis的并发最理想为10W，很难满足大型互联网公司的要求。</p>\n<h3 id=\"高可用集群模式\"><a href=\"#高可用集群模式\" class=\"headerlink\" title=\"高可用集群模式\"></a>高可用集群模式</h3><p><img src=\"https://ws2.sinaimg.cn/large/006tKfTcly1g0zt9uvbljj30bj06d48k.jpg\" alt=\"\"></p>\n<p>redis集群是一个由多个主从节点群组成的分布式服务器群，它具有复制、高可用和分片特性。Redis集群不需要sentinel哨兵也能完成节点移除和故障转移的功能。需要将每个节点设置成集群模式，这种集群模式没有中心节点，可水平扩展，据官方文档称可以线性扩展到上万个节点(官方推荐不超过1000个节点)。redis集群的性能和高可用性均优于之前版本的哨兵模式，且集群配置非常简单。<br>尽管某一个master节点挂了，也只会影响在主从切换时间里这一台机其上的数据的访问。</p>\n<h2 id=\"2-集群搭建\"><a href=\"#2-集群搭建\" class=\"headerlink\" title=\"2.集群搭建\"></a>2.集群搭建</h2><ol>\n<li>准备3个机器，每个机器上配置主从两个节点（设置不同的端口号即可），一共六个节点，三主三从。</li>\n</ol>\n<p>第一步：在第一台机器的/usr/local下创建文件夹redis-cluster，然后在其下面分别创建2个文件夾如下</p>\n<p>（1）mkdir -p /usr/local/redis-cluster</p>\n<p>（2）mkdir 8001、 mkdir 8004</p>\n<p>第二步：把之前的redis.conf配置文件copy到8001下，修改如下内容：</p>\n<p>（1）daemonize yes</p>\n<p>（2）port 8001（分别对每个机器的端口号进行设置）</p>\n<p>（3）dir /usr/local/redis-cluster/8001/（指定数据文件存放位置，必须要指定不同的目录位置，不然会丢失数据）</p>\n<p>（4）cluster-enabled yes（启动集群模式）</p>\n<p>（5）cluster-config-file nodes-8001.conf（会记录集群节点信息的文件，这里800x最好和port对应上）</p>\n<p>（6）cluster-node-timeout 5000<br> (7) # bind 127.0.0.1（去掉bind绑定访问ip信息）<br> (8) protected-mode  no   （关闭保护模式）</p>\n<p>（9）appendonly yes<br>如果要设置密码需要增加如下配置：<br>（10）requirepass fzz         (设置redis访问密码)    </p>\n<p>（11）masterauth fzz      (设置集群节点间访问密码，跟上面一致,配置后集群之间通讯是需要密码的)</p>\n<p>第三步：把修改后的配置文件，copy到8002，修改第2、3、5项里的端口号</p>\n<p>第四步：另外两台机器也需要做上面几步操作，第二台机器用8002和8005，第三台机器用8003和8006</p>\n<p>第五步：分别启动6个redis实例，然后检查是否启动成功</p>\n<p>（1）/usr/local/redis-5.0.2/src/redis-server /usr/local/redis-cluster/800*/redis.conf</p>\n<p>（2）ps -ef | grep redis 查看是否启动成功</p>\n<p>第六步：用redis-cli创建整个redis集群(redis5以前的版本集群是依靠ruby脚本redis-trib.rb实现)<br>-a 为刚才设置的密码<br>（1）/usr/local/redis-5.0.2/src/redis-cli -a fzz –cluster create –cluster-replicas 1 192.168.187.200:8001 192.168.187.201:8002 192.168.187.202:8003 192.168.187.200:8004 192.168.187.201:8005 192.168.187.202:8006 代表为每个创建的主服务器节点创建一个从服务器节点</p>\n<p>第七步：验证集群：</p>\n<p>（1）连接任意一个客户端即可：./redis-cli -c -h -p (-a访问服务端密码，-c表示集群模式，指定ip地址和端口号）如：/usr/local/redis-5.0.2/src/redis-cli -a fzz -c -h 192.168.187.200 -p 800*</p>\n<p>（2）进行验证： cluster info（查看集群信息）、cluster nodes（查看节点列表）</p>\n<p>（3）进行数据操作验证</p>\n<p>（4）关闭集群则需要逐个进行关闭，使用命令：<br>/usr/local/redis/bin/redis-cli -a fzz -c -h 192.168.187.200 -p 800* shutdown</p>\n","categories":["分布式专题"],"tags":[]},{"title":"redis 安装&基础命令&持久化概念","url":"http://ilovenorth.cn/2019/03/07/redis-安装-基础命令-持久化概念/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"redis-安装-amp-基础命令\"><a href=\"#redis-安装-amp-基础命令\" class=\"headerlink\" title=\"redis 安装&amp;基础命令\"></a>redis 安装&amp;基础命令</h1><h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><p>目前，redis官网的最新版本为5.0，在官网下也有着简单的安装命令。</p>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tKfTcly1g0queg5314j31370u0thk.jpg\" alt=\"\"></p>\n<p>下载redis安装包，然后解压编译。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ wget http://download.redis.io/releases/redis-5.0.2.tar.gz</span><br><span class=\"line\">$ tar xzf redis-5.0.2.tar.gz</span><br><span class=\"line\">$ cd redis-5.0.2</span><br><span class=\"line\">$ make</span><br></pre></td></tr></table></figure>\n<h3 id=\"编译异常解决\"><a href=\"#编译异常解决\" class=\"headerlink\" title=\"编译异常解决\"></a>编译异常解决</h3><p>1.执行make之后</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">/bin/sh: cc: command not found</span><br></pre></td></tr></table></figure>\n<p>这是由于系统没有安装gcc环境，因此在进行编译时才会出现上面提示，当安装好gcc后再进行编译时，上面错误提示将消失。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">yum install gcc</span><br></pre></td></tr></table></figure>\n<p>2.make之后</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">zmalloc.h:50:31: error: jemalloc/jemalloc.h: No such file or directory</span><br><span class=\"line\">zmalloc.h:55:2: error: #error &quot;Newer version of jemalloc required&quot;</span><br><span class=\"line\">make[1]: *** [adlist.o] Error 1</span><br><span class=\"line\">make[1]: Leaving directory `/data0/src/redis-2.6.2/src&apos;</span><br><span class=\"line\">make: *** [all] Error 2</span><br></pre></td></tr></table></figure>\n<p>原因是jemalloc重载了Linux下的ANSI C的malloc和free函数。解决办法：make时添加参数。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">make MALLOC=libc</span><br></pre></td></tr></table></figure>\n<p>3.make之后，会出现一句提示</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Hint: To run &apos;make test&apos; is a good idea ;)</span><br></pre></td></tr></table></figure>\n<p>但是不测试，通常是可以使用的。若我们运行make test ，会有如下提示</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[devnote@devnote src]$ make test</span><br><span class=\"line\">You need tcl 8.5 or newer in order to run the Redis test</span><br><span class=\"line\">make: ***[test] Error_1</span><br></pre></td></tr></table></figure>\n<p>解决办法是用yum安装tcl8.5（或去tcl的官方网站<a href=\"http://www.tcl.tk/下载8.5版本，并参考官网介绍进行安装）\" target=\"_blank\" rel=\"noopener\">http://www.tcl.tk/下载8.5版本，并参考官网介绍进行安装）</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">yum install tcl</span><br></pre></td></tr></table></figure>\n<h3 id=\"启动\"><a href=\"#启动\" class=\"headerlink\" title=\"启动\"></a>启动</h3><p>进入src文件夹，执行redis-server即可启动</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> ./src/redis-server</span></span><br></pre></td></tr></table></figure>\n<p>如若后台启动，则修改配置文件，把daemo改为yes。然后在启动的时候指定配置文件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> vi redis.conf</span></span><br><span class=\"line\">daemonize yes</span><br><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> ./src/redis-server redis.conf</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"基础命令\"><a href=\"#基础命令\" class=\"headerlink\" title=\"基础命令\"></a>基础命令</h2><h2 id=\"核心原理\"><a href=\"#核心原理\" class=\"headerlink\" title=\"核心原理\"></a>核心原理</h2><h3 id=\"Redis的单线程与高性能\"><a href=\"#Redis的单线程与高性能\" class=\"headerlink\" title=\"Redis的单线程与高性能\"></a>Redis的单线程与高性能</h3><p><strong>Redis单线程为什么还能这么快？</strong>    </p>\n<p>因为它所有的数据都在内存中，所有的运算都是内存级别的运算，而且单线程避免了多线程的切换性能损耗问题。正因为 Redis 是单线程，所以要小心使用 Redis 指令，对于那些耗时的指令(比如keys)，一定要谨慎使用，一不小心就可能会导致 Redis 卡顿。</p>\n<p>阿里 沈询 ：<strong>“redis 核心就是 如果我的数据全都在内存里，我单线程的去操作 就是效率最高的，为什么呢，因为多线程的本质就是 CPU 模拟出来多个线程的情况，这种模拟出来的情况就有一个代价，就是上下文的切换，对于一个内存的系统来说，它没有上下文的切换就是效率最高的。redis 用 单个CPU 绑定一块内存的数据，然后针对这块内存的数据进行多次读写的时候，都是在一个CPU上完成的，所以它是单线程处理这个事。在内存的情况下，这个方案就是最佳方案”</strong></p>\n<p>所以总结一下：</p>\n<ol>\n<li><p>基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；</p>\n</li>\n<li><p>数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；</p>\n</li>\n<li><p>采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；</p>\n</li>\n<li><p>使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；</p>\n</li>\n<li><p>使用多路I/O复用模型，非阻塞IO；(接下来就简单了解一下IO多路复用)</p>\n</li>\n</ol>\n<p><strong>Redis 单线程如何处理那么多的并发客户端连接？</strong><br>Redis的IO多路复用：redis利用epoll来实现IO多路复用，将连接信息和事件放到队列中，依次放到文件事件分派器，事件分派器将事件分发给事件处理器。<br>Nginx也是采用IO多路复用原理解决C10K问题。<br><img src=\"https://ws3.sinaimg.cn/large/006tKfTcly1g0rovtq9iwj30qc0f60vs.jpg\" alt=\"\"></p>\n<h2 id=\"持久化\"><a href=\"#持久化\" class=\"headerlink\" title=\"持久化\"></a>持久化</h2><h3 id=\"RDB快照（snapshot）\"><a href=\"#RDB快照（snapshot）\" class=\"headerlink\" title=\"RDB快照（snapshot）\"></a>RDB快照（snapshot）</h3><p>在默认情况下， Redis 将内存数据库快照保存在名字为 dump.rdb 的二进制文件中。</p>\n<p>你可以对 Redis 进行设置， 让它在“ N 秒内数据集至少有 M 个改动”这一条件被满足时， 自动保存一次数据集。    </p>\n<p>比如说， 以下设置会让 Redis 在满足“ 60 秒内有至少有 1000 个键被改动”这一条件时， 自动保存一次数据集：    </p>\n<pre><code>save 60 1000\n</code></pre><p>在redis的配置文件redis.conf中也是明确写了，注释写的很清晰，简单翻译一下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">################################ SNAPSHOTTING  ################################</span><br><span class=\"line\">#</span><br><span class=\"line\"># Save the DB on disk: 将数据存储到磁盘</span><br><span class=\"line\">#</span><br><span class=\"line\">#   save &lt;seconds&gt; &lt;changes&gt;</span><br><span class=\"line\">#</span><br><span class=\"line\">#   Will save the DB if both the given number of seconds and the given</span><br><span class=\"line\">#   number of write operations against the DB occurred.</span><br><span class=\"line\">#</span><br><span class=\"line\">#   In the example below the behaviour will be to save:</span><br><span class=\"line\">#   默认是一下三种情况会进行存储</span><br><span class=\"line\">#   1.每900秒内数据集至少有1次变动</span><br><span class=\"line\">#   after 900 sec (15 min) if at least 1 key changed</span><br><span class=\"line\">#   2.每300秒内数据集至少有10次变动</span><br><span class=\"line\">#   after 300 sec (5 min) if at least 10 keys changed</span><br><span class=\"line\">#   3.每60秒内至少有10000次变动</span><br><span class=\"line\">#   after 60 sec if at least 10000 keys changed</span><br><span class=\"line\">#</span><br><span class=\"line\">#   Note: you can disable saving completely by commenting out all &quot;save&quot; lines.</span><br><span class=\"line\">#</span><br><span class=\"line\">#   It is also possible to remove all the previously configured save</span><br><span class=\"line\">#   points by adding a save directive with a single empty string argument</span><br><span class=\"line\">#   like in the following example:</span><br><span class=\"line\">#</span><br><span class=\"line\">#   save &quot;&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">save 900 1</span><br><span class=\"line\">save 300 10</span><br><span class=\"line\">save 60 10000</span><br><span class=\"line\"></span><br><span class=\"line\"># By default Redis will stop accepting writes if RDB snapshots are enabled</span><br><span class=\"line\"># (at least one save point) and the latest background save failed.</span><br><span class=\"line\"># This will make the user aware (in a hard way) that data is not persisting</span><br><span class=\"line\"># on disk properly, otherwise chances are that no one will notice and some</span><br><span class=\"line\"># disaster will happen.</span><br><span class=\"line\">默认情况下，如果启用了RDB快照（至少一个保存点）并且最新的后台保存失败，Redis将停止接受写入。 </span><br><span class=\"line\">这将使用户意识到（以一种困难的方式）数据不能正确地保存在磁盘上，</span><br><span class=\"line\">否则很可能没有人会注意到，并且会发生一些灾难。</span><br><span class=\"line\">#</span><br><span class=\"line\"># If the background saving process will start working again Redis will</span><br><span class=\"line\"># automatically allow writes again.</span><br><span class=\"line\">如果后台保存过程再次开始工作，Redis将自动再次允许写入。</span><br><span class=\"line\">#</span><br><span class=\"line\"># However if you have setup your proper monitoring of the Redis server</span><br><span class=\"line\"># and persistence, you may want to disable this feature so that Redis will</span><br><span class=\"line\"># continue to work as usual even if there are problems with disk,</span><br><span class=\"line\"># permissions, and so forth.</span><br><span class=\"line\">但是，如果您已设置对Redis服务器和持久性的正确监视，则可能需要禁用此功能，以便即使磁盘，</span><br><span class=\"line\">权限等存在问题，Redis也将继续正常工作。</span><br><span class=\"line\"></span><br><span class=\"line\">stop-writes-on-bgsave-error yes</span><br><span class=\"line\"></span><br><span class=\"line\"># Compress string objects using LZF when dump .rdb databases?</span><br><span class=\"line\"># For default that&apos;s set to &apos;yes&apos; as it&apos;s almost always a win.</span><br><span class=\"line\"># If you want to save some CPU in the saving child set it to &apos;no&apos; but</span><br><span class=\"line\"># the dataset will likely be bigger if you have compressible values or keys.</span><br><span class=\"line\">rdbcompression yes</span><br><span class=\"line\"></span><br><span class=\"line\"># Since version 5 of RDB a CRC64 checksum is placed at the end of the file.</span><br><span class=\"line\"># This makes the format more resistant to corruption but there is a performance</span><br><span class=\"line\"># hit to pay (around 10%) when saving and loading RDB files, so you can disable it</span><br><span class=\"line\"># for maximum performances.</span><br><span class=\"line\">从RDB的第5版开始，CRC64校验和被放置在文件的末尾。这使得格式更能抵抗损坏，但是在保存和加载RDB文件时需要支付性能（大约10％），因此你可以禁用它为了最大的性能。</span><br><span class=\"line\">#</span><br><span class=\"line\"># RDB files created with checksum disabled have a checksum of zero that will</span><br><span class=\"line\"># tell the loading code to skip the check.</span><br><span class=\"line\">禁用校验和创建的RDB文件的校验，这意味着将会跳过检查。</span><br><span class=\"line\">rdbchecksum yes</span><br><span class=\"line\"></span><br><span class=\"line\"># The filename where to dump the DB</span><br><span class=\"line\">转储数据库的文件名</span><br><span class=\"line\">dbfilename dump.rdb</span><br><span class=\"line\"></span><br><span class=\"line\"># The working directory.</span><br><span class=\"line\">#</span><br><span class=\"line\"># The DB will be written inside this directory, with the filename specified</span><br><span class=\"line\"># above using the &apos;dbfilename&apos; configuration directive.</span><br><span class=\"line\">#</span><br><span class=\"line\"># The Append Only File will also be created inside this directory.</span><br><span class=\"line\">#</span><br><span class=\"line\"># Note that you must specify a directory here, not a file name.</span><br><span class=\"line\">转储数据库的文件地址</span><br><span class=\"line\">dir ./</span><br></pre></td></tr></table></figure>\n<h3 id=\"RDB快照原理\"><a href=\"#RDB快照原理\" class=\"headerlink\" title=\"RDB快照原理\"></a>RDB快照原理</h3><p>理清Redis实现快照的过程对我们了解快照文件的特性有很大的帮助。Redis会默认将快照文件存储在Redis当前进程的工作目录中的dump.rdb文件中。<br>快照过程如下：</p>\n<ol>\n<li>Redis使用fork函数复制一份当前进程（父进程）的副本（子进程）。</li>\n<li>父进程继续接受并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件。</li>\n<li>当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此一次快照操作完成。</li>\n</ol>\n<p>通过上述过程可以发现Redis在进行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的文件替换成新的，也就是说任何时候RDB文件都是完整的。这使得我们可以通过定时备份RDB文件来实现Redis数据库备份。RDB文件时经过压缩（可以配置rdbcompression参数以及禁用压缩节省CPU占用）的二进制格式，所以占用的空间会小于内存中的数据大小，更加利于传输。</p>\n<p><img src=\"https://ws3.sinaimg.cn/large/006tKfTcly1g0u9zsb4elj31ce0powhx.jpg\" alt=\"\"></p>\n<p>通过RDB的方式实现持久化，一旦Redis异常退出，就会丢失最后一次快照以后更改的所有数据（如上图所示）。如果对于数据会丢失最近的几十个键没有影响，可以这样使用，但是如果数据相对重要，则可以使用AOF方式进行持久化。</p>\n<h3 id=\"AOF持久化\"><a href=\"#AOF持久化\" class=\"headerlink\" title=\"AOF持久化\"></a>AOF持久化</h3><p>AOF（append-only file）<br>快照功能并不是非常耐久（durable）： 如果 Redis 因为某些原因而造成故障停机， 那么服务器将丢失最近写入、且仍未保存到快照中的那些数据。从 1.1 版本开始， Redis 增加了一种完全耐久的持久化方式： AOF 持久化，将修改的每一条指令记录进文件，也就是我们所说的AOF。    </p>\n<p>你可以通过修改配置文件来打开 AOF 功能：</p>\n<pre><code># appendonly yes\n</code></pre><p>从现在开始， 每当 Redis 执行一个改变数据集的命令时（比如 SET）， 这个命令就会被追加到 AOF 文件的末尾。    </p>\n<p>这样的话， 当 Redis 重新启时， 程序就可以通过重新执行 AOF 文件中的命令来达到重建数据集的目的。<br>你可以配置 Redis 多久才将数据 fsync 到磁盘一次。</p>\n<p>有三个选项：</p>\n<ol>\n<li>每次有新命令追加到 AOF 文件时就执行一次 fsync ：非常慢，也非常安全。</li>\n<li>每秒 fsync 一次：足够快（和使用 RDB 持久化差不多），并且在故障时只会丢失 1 秒钟的数据。</li>\n<li>从不 fsync ：将数据交给操作系统来处理。更快，也更不安全的选择。</li>\n</ol>\n<p>推荐（并且也是默认）的措施为每秒 fsync 一次， 这种 fsync 策略可以兼顾速度和安全性。</p>\n<p>我们可以查看appendonly.aof文件，就会发现里面记录的就是我们执行的命令。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@murasakiseifu redis-5.0.3]# more appendonly.aof </span><br><span class=\"line\">*2</span><br><span class=\"line\">$6</span><br><span class=\"line\">SELECT</span><br><span class=\"line\">$1</span><br><span class=\"line\">0</span><br><span class=\"line\">*3</span><br><span class=\"line\">$3</span><br><span class=\"line\">set</span><br><span class=\"line\">$4</span><br><span class=\"line\">name</span><br><span class=\"line\">$4</span><br><span class=\"line\">6666</span><br><span class=\"line\">*3</span><br><span class=\"line\">$3</span><br><span class=\"line\">set</span><br><span class=\"line\">$4</span><br><span class=\"line\">name</span><br><span class=\"line\">$6</span><br><span class=\"line\">777777</span><br><span class=\"line\">*3</span><br><span class=\"line\">$3</span><br><span class=\"line\">set</span><br><span class=\"line\">$4</span><br><span class=\"line\">name</span><br><span class=\"line\">$5</span><br><span class=\"line\">88888</span><br></pre></td></tr></table></figure>\n<h3 id=\"RDB-和-AOF-，我应该用哪一个？\"><a href=\"#RDB-和-AOF-，我应该用哪一个？\" class=\"headerlink\" title=\"RDB 和 AOF ，我应该用哪一个？\"></a>RDB 和 AOF ，我应该用哪一个？</h3><p>如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化。<br>有很多用户都只使用 AOF 持久化， 但我们并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快。</p>\n<h3 id=\"Redis-4-0-混合持久化\"><a href=\"#Redis-4-0-混合持久化\" class=\"headerlink\" title=\"Redis 4.0 混合持久化\"></a>Redis 4.0 混合持久化</h3><p>重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。 Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——<strong>混合持久化</strong>。<br><strong>再说混合持久化之前，要先说一下AOF重写特性。</strong></p>\n<p>我们做一下自增操作，做10次。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">127.0.0.1:6379&gt; incr age</span><br><span class=\"line\">(integer) 1</span><br><span class=\"line\">127.0.0.1:6379&gt; incr age</span><br><span class=\"line\">(integer) 2</span><br><span class=\"line\">127.0.0.1:6379&gt; incr age</span><br><span class=\"line\">(integer) 3</span><br><span class=\"line\">127.0.0.1:6379&gt; incr age</span><br><span class=\"line\">(integer) 4</span><br><span class=\"line\">127.0.0.1:6379&gt; incr age</span><br><span class=\"line\">(integer) 5</span><br><span class=\"line\">127.0.0.1:6379&gt; incr age</span><br><span class=\"line\">(integer) 6</span><br><span class=\"line\">127.0.0.1:6379&gt; incr age</span><br><span class=\"line\">(integer) 7</span><br><span class=\"line\">127.0.0.1:6379&gt; incr age</span><br><span class=\"line\">(integer) 8</span><br><span class=\"line\">127.0.0.1:6379&gt; incr age</span><br><span class=\"line\">(integer) 9</span><br><span class=\"line\">127.0.0.1:6379&gt; incr age</span><br><span class=\"line\">(integer) 10</span><br></pre></td></tr></table></figure>\n<p>然后我们查看一下appendonly.aof 文件，会发现有很多重复的命令。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">age</span><br><span class=\"line\">*2</span><br><span class=\"line\">$4</span><br><span class=\"line\">incr</span><br><span class=\"line\">$3</span><br><span class=\"line\">age</span><br><span class=\"line\">*2</span><br><span class=\"line\">$4</span><br><span class=\"line\">incr</span><br><span class=\"line\">$3</span><br><span class=\"line\">age</span><br><span class=\"line\">*2</span><br><span class=\"line\">$4</span><br><span class=\"line\">incr</span><br><span class=\"line\">$3</span><br><span class=\"line\">age</span><br><span class=\"line\">*2</span><br><span class=\"line\">$4</span><br><span class=\"line\">incr</span><br><span class=\"line\">$3</span><br><span class=\"line\">age</span><br><span class=\"line\">*2</span><br><span class=\"line\">$4</span><br><span class=\"line\">incr</span><br><span class=\"line\">$3</span><br><span class=\"line\">age</span><br><span class=\"line\">*2</span><br><span class=\"line\">$4</span><br><span class=\"line\">incr</span><br><span class=\"line\">$3</span><br><span class=\"line\">age</span><br><span class=\"line\">*2</span><br><span class=\"line\">$4</span><br><span class=\"line\">incr</span><br><span class=\"line\">$3</span><br><span class=\"line\">age</span><br><span class=\"line\">*2</span><br><span class=\"line\">$4</span><br><span class=\"line\">incr</span><br><span class=\"line\">$3</span><br><span class=\"line\">age</span><br></pre></td></tr></table></figure>\n<p>当我们重启redis服务时，会根据aof文件来恢复我们的内存数据，假如我们自增了几十万次，然后恢复时就要执行几十万次的命令，这样性能非常低而且很愚蠢。    </p>\n<p>因此AOF重写功能就诞生了。有两种方式，一种是后台起进程自动执行，一种是我们在客户端手动触发。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">127.0.0.1:6379&gt; bgrewriteaof</span><br><span class=\"line\">Background append only file rewriting started</span><br><span class=\"line\">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure>\n<p>然后我们再看一下 appendonly.aof 文件，重写之后，10次自增就变成一个set age 10的命令了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">set</span><br><span class=\"line\">$10</span><br><span class=\"line\">age</span><br><span class=\"line\">*2</span><br><span class=\"line\">$10</span><br></pre></td></tr></table></figure>\n<p>同样我们可以在配置文件里开启。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># Automatic rewrite of the append only file.</span><br><span class=\"line\"># Redis is able to automatically rewrite the log file implicitly calling</span><br><span class=\"line\"># BGREWRITEAOF when the AOF log size grows by the specified percentage.</span><br><span class=\"line\">#</span><br><span class=\"line\"># This is how it works: Redis remembers the size of the AOF file after the</span><br><span class=\"line\"># latest rewrite (if no rewrite has happened since the restart, the size of</span><br><span class=\"line\"># the AOF at startup is used).</span><br><span class=\"line\">#</span><br><span class=\"line\"># This base size is compared to the current size. If the current size is</span><br><span class=\"line\"># bigger than the specified percentage, the rewrite is triggered. Also</span><br><span class=\"line\"># you need to specify a minimal size for the AOF file to be rewritten, this</span><br><span class=\"line\"># is useful to avoid rewriting the AOF file even if the percentage increase</span><br><span class=\"line\"># is reached but it is still pretty small.</span><br><span class=\"line\">#</span><br><span class=\"line\"># Specify a percentage of zero in order to disable the automatic AOF</span><br><span class=\"line\"># rewrite feature.</span><br><span class=\"line\"></span><br><span class=\"line\">当aof文件只要容量翻倍就会进行重写</span><br><span class=\"line\">auto-aof-rewrite-percentage 100</span><br><span class=\"line\">当aof文件超过64M才会执行上面的配置</span><br><span class=\"line\">auto-aof-rewrite-min-size 64mb</span><br></pre></td></tr></table></figure>\n<p><strong>AOF在重写(aof文件里可能有太多没用指令，所以aof会定期根据内存的最新数据生成aof文件)时将重写这一刻之前的内存rdb快照文件的内容和增量的 AOF修改内存数据的命令日志文件存在一起，都写入新的aof文件，新的文件一开始不叫appendonly.aof，等到重写完新的AOF文件才会进行改名，原子的覆盖原有的AOF文件，完成新旧两个AOF文件的替换</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">开启混合持久化：</span><br><span class=\"line\"># aof-use-rdb-preamble yes</span><br></pre></td></tr></table></figure>\n<p>混合持久化aof文件结构</p>\n<p><img src=\"https://ws4.sinaimg.cn/large/006tKfTcly1g0ub6ljp1sj30bj073dr2.jpg\" alt=\"\"></p>\n<p>结合之前的RDB快照流程，我们知道在子进程写入文件的时候，父进程依然在接受命令，所以这段时间内依然是有新的数据产生但是没有写到RDB文件里。开启混合持久化，在子进程进行RDB快照文件写入的时间里，会进行AOF重写，把这期间内的数据存放在新的AOF文件，重写完新的AOF文件才会进行改名，原子的覆盖原有的AOF文件，完成新旧两个AOF文件的替换。</p>\n","categories":["分布式专题"],"tags":[]},{"title":"zookeeper java-api 介绍","url":"http://ilovenorth.cn/2019/03/04/zookeeper-java-api-介绍/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"zookeeper-java-api-介绍\"><a href=\"#zookeeper-java-api-介绍\" class=\"headerlink\" title=\"zookeeper java-api 介绍\"></a>zookeeper java-api 介绍</h1><h2 id=\"原生\"><a href=\"#原生\" class=\"headerlink\" title=\"原生\"></a>原生</h2><h3 id=\"引包\"><a href=\"#引包\" class=\"headerlink\" title=\"引包\"></a>引包</h3><p>首先我们引入gradle。</p>\n<figure class=\"highlight gradle\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">compile</span> <span class=\"string\">'org.apache.zookeeper:zookeeper:3.4.10'</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"创建我们的连接\"><a href=\"#创建我们的连接\" class=\"headerlink\" title=\"创建我们的连接\"></a>创建我们的连接</h3><ol>\n<li><p>我们先创建一个类，类名：ZookeeperCrud，然后创建一个构造函数。</p>\n <figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@author</span>: murasakiseifu</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@date</span>: 2019-02-27 15:26&#125;</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@version</span>: V1.0</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@review</span>: murasakiseifu/2019-02-27 15:26&#125;</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ZookeeperCrud</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">ZookeeperCrud</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        ZooKeeper zooKeeper = <span class=\"keyword\">new</span> ZooKeeper(...);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<ol start=\"2\">\n<li><p>我们会发现，创建zookeeper连接，需要三个参数，我们进到ZooKeeper.java类中，看一看这三个参数是什么。</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher)</span><br><span class=\"line\">       throws IOException</span><br><span class=\"line\">   &#123;</span><br><span class=\"line\">       this(connectString, sessionTimeout, watcher, false);</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<p> 在源码上有对这三个参数的详解，在这里简单说一下前两个，watcher我们一会再说。</p>\n<p> <strong>String connectString：</strong><br> 创建Zookeeper客户端对象，应用程序需要传递一个String connectString，其中包含逗号分隔的host：port为一对的列表，每一对对应一个zookeeper服务器。<br> <strong>int sessionTimeout：</strong><br> session会话的超时时间，默认单位为毫秒。</p>\n</li>\n<li><p>最终连接zookeeper服务的代码。</p>\n</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">public class ZookeeperCrud &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    String connectString = &quot;192.168.187.200:2181,192.168.187.201:2181,192.168.187.202:2181&quot;;</span><br><span class=\"line\"></span><br><span class=\"line\">    public ZookeeperCrud() &#123;</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            ZooKeeper zooKeeper = new ZooKeeper(connectString, 5000, null);</span><br><span class=\"line\">        &#125; catch (IOException e) &#123;</span><br><span class=\"line\">            e.printStackTrace();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    public static void main(String[] args) &#123;</span><br><span class=\"line\">        ZookeeperCrud zookeeperCrud = new ZookeeperCrud();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>   成功连接的日志</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[2019-02-27 15:58:24] [INFO] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT</span><br><span class=\"line\">  [2019-02-27 15:58:24] [INFO] Client environment:host.name=192.168.187.1</span><br><span class=\"line\">  [2019-02-27 15:58:24] [INFO] Client environment:java.version=1.8.0_144</span><br><span class=\"line\">  [2019-02-27 15:58:24] [INFO] Client environment:java.vendor=Oracle Corporation</span><br><span class=\"line\">  [2019-02-27 15:58:24] [INFO] Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_144.jdk/Contents/Home/jre</span><br><span class=\"line\">  [2019-02-27 15:58:24] [INFO] Client environment:java.class.path=......</span><br><span class=\"line\">  [2019-02-27 15:58:24] [INFO] Client environment:java.library.path=/Users/murasakiseifu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.</span><br><span class=\"line\">  [2019-02-27 15:58:24] [INFO] Client environment:java.io.tmpdir=/var/folders/60/s3wc1nqj74xfjb63z688j6k40000gn/T/</span><br><span class=\"line\">  [2019-02-27 15:58:24] [INFO] Client environment:java.compiler=&lt;NA&gt;</span><br><span class=\"line\">  [2019-02-27 15:58:24] [INFO] Client environment:os.name=Mac OS X</span><br><span class=\"line\">  [2019-02-27 15:58:24] [INFO] Client environment:os.arch=x86_64</span><br><span class=\"line\">  [2019-02-27 15:58:24] [INFO] Client environment:os.version=10.14</span><br><span class=\"line\">  [2019-02-27 15:58:24] [INFO] Client environment:user.name=murasakiseifu</span><br><span class=\"line\">  [2019-02-27 15:58:24] [INFO] Client environment:user.home=/Users/murasakiseifu</span><br><span class=\"line\">  [2019-02-27 15:58:24] [INFO] Client environment:user.dir=/Users/murasakiseifu/my-project/zookeeper-java-api</span><br><span class=\"line\">  [2019-02-27 15:58:24] [INFO] Initiating client connection, connectString=192.168.187.200:2181,192.168.187.201:2181,192.168.187.202:2181 sessionTimeout=5000 watcher=null</span><br></pre></td></tr></table></figure>\n<h3 id=\"流程分析\"><a href=\"#流程分析\" class=\"headerlink\" title=\"流程分析\"></a>流程分析</h3><p><strong>使用工具很简单，重要的是为什么这个工具可以这么用。</strong><br>为什么上述代码能连接zk，我们带着这个问题去查一下zookeeper的源码。其实很简单。</p>\n<ol>\n<li><p>我们实现了通过java客户端连接zookeeper客户端。我们想要看懂是如何连接，可以点到源码里一点一点的找，但是这样很麻烦，而且效率低。看源码要带着问题去看，我们思考，java连接zookeeper客户端肯定是封装了一层，那么什么方式是直接就能连接zookeeper服务器的呢？<font color=\"red\">Zookeeper自己的客户端啊</font>，我们直接查看zkCli.sh的脚本，看看里面有什么。</p>\n <figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@murasakiseifu bin]# vim zkCli.sh</span><br><span class=\"line\">ZOOBIN=\"$&#123;BASH_SOURCE-$0&#125;\"</span><br><span class=\"line\">ZOOBIN=\"$(dirname \"$&#123;ZOOBIN&#125;\")\"</span><br><span class=\"line\">ZOOBINDIR=\"$(cd \"$&#123;ZOOBIN&#125;\"; pwd)\"</span><br><span class=\"line\"></span><br><span class=\"line\">if [ -e \"$ZOOBIN/../libexec/zkEnv.sh\" ]; then</span><br><span class=\"line\">  . \"$ZOOBINDIR\"/../libexec/zkEnv.sh</span><br><span class=\"line\">else</span><br><span class=\"line\">  . \"$ZOOBINDIR\"/zkEnv.sh</span><br><span class=\"line\">fi</span><br><span class=\"line\"></span><br><span class=\"line\">\"$JAVA\" \"-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;\" \"-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;\" \\</span><br><span class=\"line\">     -cp \"$CLASSPATH\" $CLIENT_JVMFLAGS $JVMFLAGS \\</span><br><span class=\"line\">     org.apache.zookeeper.ZooKeeperMain \"$@\"</span><br><span class=\"line\">~</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>除去注释，我们看到这个脚本里有一个我们熟悉的：org.apache.zookeeper.ZooKeeperMain，我们可以找到这个类，去看看有什么.（类里的代码很多，我们挑选几个常见的）</p>\n <figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ZooKeeperMain</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">protected</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> Map&lt;String,String&gt; commandMap = <span class=\"keyword\">new</span> HashMap&lt;String,String&gt;( );</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">protected</span> MyCommandOptions cl = <span class=\"keyword\">new</span> MyCommandOptions();</span><br><span class=\"line\">    <span class=\"keyword\">protected</span> HashMap&lt;Integer,String&gt; history = <span class=\"keyword\">new</span> HashMap&lt;Integer,String&gt;( );</span><br><span class=\"line\">    <span class=\"keyword\">protected</span> <span class=\"keyword\">int</span> commandCount = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">protected</span> <span class=\"keyword\">boolean</span> printWatches = <span class=\"keyword\">true</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">protected</span> ZooKeeper zk;</span><br><span class=\"line\">    <span class=\"keyword\">protected</span> String host = <span class=\"string\">\"\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">boolean</span> <span class=\"title\">getPrintWatches</span><span class=\"params\">( )</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> printWatches;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">static</span> &#123;</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"connect\"</span>, <span class=\"string\">\"host:port\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"close\"</span>,<span class=\"string\">\"\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"create\"</span>, <span class=\"string\">\"[-s] [-e] path data acl\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"delete\"</span>,<span class=\"string\">\"path [version]\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"rmr\"</span>,<span class=\"string\">\"path\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"set\"</span>,<span class=\"string\">\"path data [version]\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"get\"</span>,<span class=\"string\">\"path [watch]\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"ls\"</span>,<span class=\"string\">\"path [watch]\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"ls2\"</span>,<span class=\"string\">\"path [watch]\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"getAcl\"</span>,<span class=\"string\">\"path\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"setAcl\"</span>,<span class=\"string\">\"path acl\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"stat\"</span>,<span class=\"string\">\"path [watch]\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"sync\"</span>,<span class=\"string\">\"path\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"setquota\"</span>,<span class=\"string\">\"-n|-b val path\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"listquota\"</span>,<span class=\"string\">\"path\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"delquota\"</span>,<span class=\"string\">\"[-n|-b] path\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"history\"</span>,<span class=\"string\">\"\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"redo\"</span>,<span class=\"string\">\"cmdno\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"printwatches\"</span>, <span class=\"string\">\"on|off\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"quit\"</span>,<span class=\"string\">\"\"</span>);</span><br><span class=\"line\">        commandMap.put(<span class=\"string\">\"addauth\"</span>, <span class=\"string\">\"scheme auth\"</span>);</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>static静态代码块里的，就是在zkClient执行help命令的信息。</p>\n<pre><code><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">\t[zk: localhost:2181(CONNECTED) 0] help</span><br><span class=\"line\">\tZooKeeper -server host:port cmd args</span><br><span class=\"line\">\t        stat path [watch]</span><br><span class=\"line\">\t        set path data [version]</span><br><span class=\"line\">\t        ls path [watch]</span><br><span class=\"line\">\t        delquota [-n|-b] path</span><br><span class=\"line\">\t        ls2 path [watch]</span><br><span class=\"line\">\t        setAcl path acl</span><br><span class=\"line\">\t        setquota -n|-b val path</span><br><span class=\"line\">\t        history </span><br><span class=\"line\">\t        redo cmdno</span><br><span class=\"line\">\t        printwatches on|off</span><br><span class=\"line\">\t        delete path [version]</span><br><span class=\"line\">\t        sync path</span><br><span class=\"line\">\t        listquota path</span><br><span class=\"line\">\t        rmr path</span><br><span class=\"line\">\t        get path [watch]</span><br><span class=\"line\">\t        create [-s] [-e] path data acl</span><br><span class=\"line\">\t        addauth scheme auth</span><br><span class=\"line\">\t        quit </span><br><span class=\"line\">\t        getAcl path</span><br><span class=\"line\">\t        close </span><br><span class=\"line\">\t        connect host:port</span><br><span class=\"line\">```\t</span><br><span class=\"line\"></span><br><span class=\"line\">再比如这个。</span><br><span class=\"line\"></span><br><span class=\"line\">```java</span><br><span class=\"line\">private static void printStat(Stat stat) &#123;</span><br><span class=\"line\">       System.err.println(&quot;cZxid = 0x&quot; + Long.toHexString(stat.getCzxid()));</span><br><span class=\"line\">       System.err.println(&quot;ctime = &quot; + new Date(stat.getCtime()).toString());</span><br><span class=\"line\">       System.err.println(&quot;mZxid = 0x&quot; + Long.toHexString(stat.getMzxid()));</span><br><span class=\"line\">       System.err.println(&quot;mtime = &quot; + new Date(stat.getMtime()).toString());</span><br><span class=\"line\">       System.err.println(&quot;pZxid = 0x&quot; + Long.toHexString(stat.getPzxid()));</span><br><span class=\"line\">       System.err.println(&quot;cversion = &quot; + stat.getCversion());</span><br><span class=\"line\">       System.err.println(&quot;dataVersion = &quot; + stat.getVersion());</span><br><span class=\"line\">       System.err.println(&quot;aclVersion = &quot; + stat.getAversion());</span><br><span class=\"line\">       System.err.println(&quot;ephemeralOwner = 0x&quot;</span><br><span class=\"line\">       \t\t+ Long.toHexString(stat.getEphemeralOwner()));</span><br><span class=\"line\">       System.err.println(&quot;dataLength = &quot; + stat.getDataLength());</span><br><span class=\"line\">       System.err.println(&quot;numChildren = &quot; + stat.getNumChildren());</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n对应的就是节点的stat状态信息。\n\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[zk: localhost:2181(CONNECTED) 1] get /murasaki</span><br><span class=\"line\">666</span><br><span class=\"line\">cZxid = 0x400000002</span><br><span class=\"line\">ctime = Thu Feb 21 10:53:25 CST 2019</span><br><span class=\"line\">mZxid = 0x800000003</span><br><span class=\"line\">mtime = Fri Feb 22 00:59:05 CST 2019</span><br><span class=\"line\">pZxid = 0x400000003</span><br><span class=\"line\">cversion = 1</span><br><span class=\"line\">dataVersion = 1</span><br><span class=\"line\">aclVersion = 0</span><br><span class=\"line\">ephemeralOwner = 0x0</span><br><span class=\"line\">dataLength = 3</span><br><span class=\"line\">numChildren = 1</span><br></pre></td></tr></table></figure>\n</code></pre><ol start=\"3\">\n<li><p>ZooKeeperMain 类就是我们要找的核心类，在这个类里面有一个main方法。</p>\n <figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String args[])</span></span></span><br><span class=\"line\"><span class=\"function\">       <span class=\"keyword\">throws</span> KeeperException, IOException, InterruptedException</span></span><br><span class=\"line\"><span class=\"function\">   </span>&#123;</span><br><span class=\"line\">       ZooKeeperMain main = <span class=\"keyword\">new</span> ZooKeeperMain(args);</span><br><span class=\"line\">       main.run();</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>这个main方法里创建了一个ZooKeeperMain对象，我们依然点进去。</p>\n <figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">ZooKeeperMain</span><span class=\"params\">(String args[])</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">        cl.parseOptions(args);</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"Connecting to \"</span> + cl.getOption(<span class=\"string\">\"server\"</span>));</span><br><span class=\"line\">        connectToZK(cl.getOption(<span class=\"string\">\"server\"</span>));</span><br><span class=\"line\">        <span class=\"comment\">//zk = new ZooKeeper(cl.getOption(\"server\"),</span></span><br><span class=\"line\"><span class=\"comment\">//                Integer.parseInt(cl.getOption(\"timeout\")), new MyWatcher());</span></span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<pre><code>看有标志性的代码，connectToZK(cl.getOption(&quot;server&quot;));连接zk，这正是我们想要找的，所以我们接着点进去。\n\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">connectToZK</span><span class=\"params\">(String newHost)</span> <span class=\"keyword\">throws</span> InterruptedException, IOException </span>&#123;</span><br><span class=\"line\">       <span class=\"keyword\">if</span> (zk != <span class=\"keyword\">null</span> &amp;&amp; zk.getState().isAlive()) &#123;</span><br><span class=\"line\">           zk.close();</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       host = newHost;</span><br><span class=\"line\">       <span class=\"keyword\">boolean</span> readOnly = cl.getOption(<span class=\"string\">\"readonly\"</span>) != <span class=\"keyword\">null</span>;</span><br><span class=\"line\">       zk = <span class=\"keyword\">new</span> ZooKeeper(host,</span><br><span class=\"line\">                Integer.parseInt(cl.getOption(<span class=\"string\">\"timeout\"</span>)),</span><br><span class=\"line\">                <span class=\"keyword\">new</span> MyWatcher(), readOnly);</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n\n\n看，我们找到了最终的连接zk = new ZooKeeper(...);\n</code></pre><p><strong>我们既然要执行api的crud，我们就再找一下create方法</strong>    </p>\n<ol>\n<li><p>首先我们全局搜索create关键字，我们会发现有很多方法，这里有一个技巧，看带有返回值的方法。</p>\n <figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"> <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">boolean</span> <span class=\"title\">createQuota</span><span class=\"params\">(ZooKeeper zk, String path,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">           <span class=\"keyword\">long</span> bytes, <span class=\"keyword\">int</span> numNodes)</span></span></span><br><span class=\"line\"><span class=\"function\">       <span class=\"keyword\">throws</span> KeeperException, IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">```\t</span><br><span class=\"line\"></span><br><span class=\"line\">里面代码很多，我们就不一一列举了，查看源码我们会发现有一段代码：</span><br><span class=\"line\"></span><br><span class=\"line\">```java</span><br><span class=\"line\"><span class=\"keyword\">if</span> (zk.exists(quotaPath, <span class=\"keyword\">false</span>) == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">       <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">           zk.create(Quotas.procZookeeper, <span class=\"keyword\">null</span>, Ids.OPEN_ACL_UNSAFE,</span><br><span class=\"line\">                   CreateMode.PERSISTENT);</span><br><span class=\"line\">           zk.create(Quotas.quotaZookeeper, <span class=\"keyword\">null</span>, Ids.OPEN_ACL_UNSAFE,</span><br><span class=\"line\">                   CreateMode.PERSISTENT);</span><br><span class=\"line\">       &#125; <span class=\"keyword\">catch</span>(KeeperException.NodeExistsException ne) &#123;</span><br><span class=\"line\">           <span class=\"comment\">// do nothing</span></span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<ol start=\"2\">\n<li><p>里面的zk.create很像我们要找的代码，点进去会发现这就是创建节点的方法，需要我们提供四个参数：路径、数据、权限集合、创建的节点类型。</p>\n <figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">create</span><span class=\"params\">(<span class=\"keyword\">final</span> String path, <span class=\"keyword\">byte</span> data[], List&lt;ACL&gt; acl,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">           CreateMode createMode)</span></span></span><br><span class=\"line\"><span class=\"function\">       <span class=\"keyword\">throws</span> KeeperException, InterruptedException</span></span><br><span class=\"line\"><span class=\"function\">   </span>&#123;</span><br><span class=\"line\">   </span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>我们不一一列举zookeeper其他方法了，大家按照这个方法就都能找到，而且在寻找的过程中，也能知道一些zookeeper java方法的一些使用方式。</p>\n<p><strong>创建持久节点</strong>    </p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">\t<span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 创建持久节点</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@author</span> MurasakiSeiFu</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@date</span> 2019-02-28 10:16</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span>: [path, data]</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span>: java.lang.String</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">createPersistent</span><span class=\"params\">(String path, String data)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> zookeeper.create(path, data.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (KeeperException e) &#123;</span><br><span class=\"line\">            e.printStackTrace();</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (InterruptedException e) &#123;</span><br><span class=\"line\">            e.printStackTrace();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">```\t</span><br><span class=\"line\">\t</span><br><span class=\"line\">ZooDefs.Ids.OPEN_ACL_UNSAFE 为权限设置。\t</span><br><span class=\"line\"></span><br><span class=\"line\">CreateMode.PERSISTENT 为节点类型设置，如果我们要建立临时节点，就把它设置为CreateMode.EPHEMERAL 就可以了。</span><br><span class=\"line\">\t</span><br><span class=\"line\">**获取信息**</span><br><span class=\"line\"></span><br><span class=\"line\">```java</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获取信息</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@author</span> MurasakiSeiFu</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@date</span> 2019-02-28 10:46</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span>: [path]</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span>: java.lang.String</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">getData</span><span class=\"params\">(String path)</span> <span class=\"keyword\">throws</span> KeeperException, InterruptedException </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">byte</span> data[] = zookeeper.getData(path, <span class=\"keyword\">false</span>, <span class=\"keyword\">null</span>);</span><br><span class=\"line\">        data = (data == <span class=\"keyword\">null</span>) ? <span class=\"string\">\"null\"</span>.getBytes() : data;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> String(data);</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n<p><strong>更新信息</strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">   * 更新信息</span></span><br><span class=\"line\"><span class=\"comment\">   *</span></span><br><span class=\"line\"><span class=\"comment\">   * <span class=\"doctag\">@author</span> FuZizheng</span></span><br><span class=\"line\"><span class=\"comment\">   * <span class=\"doctag\">@date</span> 2019-02-28 11:01</span></span><br><span class=\"line\"><span class=\"comment\">   * <span class=\"doctag\">@param</span>: [path, data]</span></span><br><span class=\"line\"><span class=\"comment\">   * <span class=\"doctag\">@return</span>: org.apache.zookeeper.data.Stat</span></span><br><span class=\"line\"><span class=\"comment\">   */</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">public</span> Stat <span class=\"title\">setData</span><span class=\"params\">(String path, String data)</span> <span class=\"keyword\">throws</span> KeeperException, InterruptedException </span>&#123;</span><br><span class=\"line\">      <span class=\"keyword\">return</span> zookeeper.setData(path, data.getBytes(), -<span class=\"number\">1</span>);</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n<p><strong>删除节点</strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * 删除节点</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@author</span> MurasakiSeiFu</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@date</span> 2019-02-28 11:03</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@param</span>: [path]</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@return</span>: void</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">deleteData</span><span class=\"params\">(String path)</span> <span class=\"keyword\">throws</span> KeeperException, InterruptedException </span>&#123;</span><br><span class=\"line\">    zookeeper.delete(path, -<span class=\"number\">1</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>递归删除节点</strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 递归删除节点</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@author</span> FuZizheng</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@date</span> 2019-02-28 11:05</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span>: [path]</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span>: void</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">deleteRecursive</span><span class=\"params\">(String path)</span> <span class=\"keyword\">throws</span> KeeperException, InterruptedException </span>&#123;</span><br><span class=\"line\">        ZKUtil.deleteRecursive(zookeeper, path);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">```\t</span><br><span class=\"line\">\t</span><br><span class=\"line\">### watch事件</span><br><span class=\"line\"></span><br><span class=\"line\">上述是最简单的api，现在我们要讲一下watch事件。\t基本和上述的代码差不多。</span><br><span class=\"line\"></span><br><span class=\"line\">**实现 Watcher接口**</span><br><span class=\"line\"></span><br><span class=\"line\">```java</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ZookeeperWatchCrud</span> <span class=\"keyword\">implements</span> <span class=\"title\">Watcher</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">process</span><span class=\"params\">(WatchedEvent event)</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>基础准备和之前一样，提供集群信息。稍加修改和完善，如下所示：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ZookeeperWatchCrud</span> <span class=\"keyword\">implements</span> <span class=\"title\">Watcher</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> String connectString = <span class=\"string\">\"192.168.187.200:2181,192.168.187.201:2181,192.168.187.202:2181\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> ZooKeeper zookeeper;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">ZookeeperWatchCrud</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            zookeeper = <span class=\"keyword\">new</span> ZooKeeper(connectString, <span class=\"number\">5000</span>, <span class=\"keyword\">this</span>);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</span><br><span class=\"line\">            e.printStackTrace();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">process</span><span class=\"params\">(WatchedEvent event)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 连接状态</span></span><br><span class=\"line\">        Event.KeeperState keeperState = event.getState();</span><br><span class=\"line\">        <span class=\"comment\">// 事件类型</span></span><br><span class=\"line\">        Event.EventType eventType = event.getType();</span><br><span class=\"line\">        <span class=\"comment\">// 受影响的path</span></span><br><span class=\"line\">        String path = event.getPath();</span><br><span class=\"line\"></span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"连接状态:\"</span> + keeperState + <span class=\"string\">\",事件类型：\"</span> + eventType + <span class=\"string\">\",受影响的path:\"</span> + path);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        ZookeeperWatchCrud zookeeperWatchCrud = <span class=\"keyword\">new</span> ZookeeperWatchCrud();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>和之前不同，这次控制台没有报错。watcher=watch.ZookeeperWatchCrud@42110406</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[2019-02-28 11:29:25] [INFO] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT</span><br><span class=\"line\"> [2019-02-28 11:29:25] [INFO] Client environment:host.name=172.16.191.1</span><br><span class=\"line\"> [2019-02-28 11:29:25] [INFO] Client environment:java.version=1.8.0_144</span><br><span class=\"line\"> [2019-02-28 11:29:25] [INFO] Client environment:java.vendor=Oracle Corporation</span><br><span class=\"line\"> [2019-02-28 11:29:25] [INFO] Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_144.jdk/Contents/Home/jre</span><br><span class=\"line\"> [2019-02-28 11:29:25] [INFO] Client environment:java.class.path=...</span><br><span class=\"line\"> [2019-02-28 11:29:25] [INFO] Client environment:java.library.path=/Users/murasakiseifu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.</span><br><span class=\"line\"> [2019-02-28 11:29:25] [INFO] Client environment:java.io.tmpdir=/var/folders/60/s3wc1nqj74xfjb63z688j6k40000gn/T/</span><br><span class=\"line\"> [2019-02-28 11:29:25] [INFO] Client environment:java.compiler=&lt;NA&gt;</span><br><span class=\"line\"> [2019-02-28 11:29:25] [INFO] Client environment:os.name=Mac OS X</span><br><span class=\"line\"> [2019-02-28 11:29:25] [INFO] Client environment:os.arch=x86_64</span><br><span class=\"line\"> [2019-02-28 11:29:25] [INFO] Client environment:os.version=10.14</span><br><span class=\"line\"> [2019-02-28 11:29:25] [INFO] Client environment:user.name=murasakiseifu</span><br><span class=\"line\"> [2019-02-28 11:29:25] [INFO] Client environment:user.home=/Users/murasakiseifu</span><br><span class=\"line\"> [2019-02-28 11:29:25] [INFO] Client environment:user.dir=/Users/murasakiseifu/my-project/zookeeper-java-api</span><br><span class=\"line\"> [2019-02-28 11:29:25] [INFO] Initiating client connection, connectString=192.168.187.200:2181,192.168.187.201:2181,192.168.187.202:2181 sessionTimeout=5000 watcher=watch.ZookeeperWatchCrud@42110406</span><br><span class=\"line\"> </span><br><span class=\"line\">Process finished with exit code 0</span><br></pre></td></tr></table></figure>\n<p>其余代码相同，只在getData和exits两个方法，加上watcher。</p>\n<p><strong>获取信息</strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获取信息</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> path</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> KeeperException</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> InterruptedException</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">getData</span><span class=\"params\">(String path, <span class=\"keyword\">boolean</span> watcher)</span> <span class=\"keyword\">throws</span> KeeperException, InterruptedException </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">byte</span> data[] = zookeeper.getData(path, watcher, <span class=\"keyword\">null</span>);</span><br><span class=\"line\">        data = (data == <span class=\"keyword\">null</span>) ? <span class=\"string\">\"null\"</span>.getBytes() : data;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> String(data);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">```\t</span><br><span class=\"line\"></span><br><span class=\"line\">**是否存在**</span><br><span class=\"line\">\t</span><br><span class=\"line\">```java</span><br><span class=\"line\">\t<span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 是否存在</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> path</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> KeeperException</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> InterruptedException</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Stat <span class=\"title\">exists</span><span class=\"params\">(String path, <span class=\"keyword\">boolean</span> watcher)</span> <span class=\"keyword\">throws</span> KeeperException, InterruptedException </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> zookeeper.exists(path, watcher);</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n<p>加上监听之后，我们修改一下proccess方法，以方便我们做监听。一会测试类中新建的节点路径为/watcher,在process方法把这个路径写死了，方便测试 -。-</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\">   <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">process</span><span class=\"params\">(WatchedEvent event)</span> </span>&#123;</span><br><span class=\"line\">       <span class=\"comment\">// 连接状态</span></span><br><span class=\"line\">       Event.KeeperState keeperState = event.getState();</span><br><span class=\"line\">       <span class=\"comment\">// 事件类型</span></span><br><span class=\"line\">       Event.EventType eventType = event.getType();</span><br><span class=\"line\">       <span class=\"comment\">// 受影响的path</span></span><br><span class=\"line\">       String path = event.getPath();</span><br><span class=\"line\"></span><br><span class=\"line\">       System.out.println(<span class=\"string\">\"连接状态:\"</span> + keeperState + <span class=\"string\">\",事件类型：\"</span> + eventType + <span class=\"string\">\",受影响的path:\"</span> + path);</span><br><span class=\"line\"></span><br><span class=\"line\">       <span class=\"comment\">//step:2</span></span><br><span class=\"line\">       <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">           <span class=\"keyword\">if</span> (<span class=\"keyword\">null</span> != <span class=\"keyword\">this</span>.exists(<span class=\"string\">\"/watcher\"</span>, <span class=\"keyword\">true</span>)) &#123;</span><br><span class=\"line\">               System.out.println(<span class=\"string\">\"内容:\"</span> + <span class=\"keyword\">this</span>.getData(<span class=\"string\">\"/watcher\"</span>, <span class=\"keyword\">true</span>));</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">       &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">           e.printStackTrace();</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       System.out.println(<span class=\"string\">\"--------------------\"</span>);</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<p>我们写一个测试类试一下效果。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> <span class=\"keyword\">throws</span> KeeperException, InterruptedException </span>&#123;</span><br><span class=\"line\">    ZookeeperWatchCrud zookeeperWatchCrud = <span class=\"keyword\">new</span> ZookeeperWatchCrud();</span><br><span class=\"line\">    <span class=\"comment\">//创建节点</span></span><br><span class=\"line\">    zookeeperWatchCrud.createPersistent(<span class=\"string\">\"/watcher\"</span>,<span class=\"string\">\"watcher test\"</span>);</span><br><span class=\"line\">    <span class=\"comment\">//为watcher节点注册监听，并且输出当前内容</span></span><br><span class=\"line\">    System.out.println(zookeeperWatchCrud.getData(<span class=\"string\">\"/watcher\"</span>, <span class=\"keyword\">true</span>));</span><br><span class=\"line\">    <span class=\"comment\">//修改watcher节点数据</span></span><br><span class=\"line\">    zookeeperWatchCrud.setData(<span class=\"string\">\"/watcher\"</span>,<span class=\"string\">\"change data\"</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>控制台输出</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">连接状态:SyncConnected,事件类型：None,受影响的path:null</span><br><span class=\"line\">watcher test</span><br><span class=\"line\">内容:change data</span><br><span class=\"line\">--------------------</span><br><span class=\"line\">连接状态:SyncConnected,事件类型：NodeDataChanged,受影响的path:/watcher</span><br></pre></td></tr></table></figure>\n","categories":["分布式专题"],"tags":[]},{"title":"zookeeper客户端详解","url":"http://ilovenorth.cn/2019/02/27/zookeeper客户端详解/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"zookeeper客户端详解\"><a href=\"#zookeeper客户端详解\" class=\"headerlink\" title=\"zookeeper客户端详解\"></a>zookeeper客户端详解</h1><h2 id=\"1-zookeeper核心概念\"><a href=\"#1-zookeeper核心概念\" class=\"headerlink\" title=\"1. zookeeper核心概念\"></a>1. zookeeper核心概念</h2><p>Zookeeper提供一个多层级的节点命名空间（节点称为znode）。与文件系统不同的是，这些节点都可以设置关联的数据，而文件系统中只有文件节点可以存放数据，而目录节点不行。    </p>\n<p>Zookeeper为了保证高吞吐和低延迟，在内存中维护了这个树状的目录结构，<strong>这种特性使得Zookeeper不能用于存放大量的数据，每个节点的存放数据上限为1M。</strong></p>\n<p>说白了，可以理解zookeeper为一个存储功能，在其节点上存放数据，比如分布式配置中心就是一个典型的例子。    </p>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tKfTcly1g0f24w4olxj31d00n0778.jpg\" alt=\"\"></p>\n<h2 id=\"2-znode\"><a href=\"#2-znode\" class=\"headerlink\" title=\"2. znode\"></a>2. znode</h2><p><img src=\"https://ws3.sinaimg.cn/large/006tKfTcly1g0f5k911z0j306303i418.jpg\" alt=\"\"></p>\n<p>ZooKeeper操作和维护的为一个个数据节点，称为 znode，采用类似文件系统的层级树状结构进行管理。如果 znode 节点包含数据则存储为字节数组（byte array）。</p>\n<h3 id=\"znode类型\"><a href=\"#znode类型\" class=\"headerlink\" title=\"znode类型\"></a>znode类型</h3><p><strong>PERSISTENT-持久节点</strong></p>\n<ul>\n<li>除非手动删除，否则节点一直存在于Zookeeper上</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[zk: localhost:2181(CONNECTED) 1] create /murasaki hello</span><br><span class=\"line\">Created /murasaki</span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 2] create /murasaki/sei hello</span><br><span class=\"line\">Created /murasaki/sei</span><br></pre></td></tr></table></figure>\n<p><strong>EPHEMERAL-临时节点</strong></p>\n<ul>\n<li>临时节点的生命周期与客户端会话绑定，一旦客户端会话失效（客户端与zookeeper连接断开不一定会话失效），那么这个客户端创建的所有临时节点都会被移除。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[zk: localhost:2181(CONNECTED) 1] create -e /linshi hello</span><br><span class=\"line\">Created /linshi</span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 2] ls /</span><br><span class=\"line\">[zookeeper, murasaki, linshi]</span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 3] quit</span><br><span class=\"line\"></span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 0] ls /</span><br><span class=\"line\">[zookeeper, murasaki]</span><br></pre></td></tr></table></figure>\n<p><strong>PERSISTENT_SEQUENTIAL-持久顺序节点</strong></p>\n<ul>\n<li>基本特性同持久节点，只是增加了顺序属性，节点名后边会追加一个由父节点维护的自增整型数字。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[zk: localhost:2181(CONNECTED) 0] ls /</span><br><span class=\"line\">[zookeeper, murasaki]</span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 1] create -s /youxu hello</span><br><span class=\"line\">Created /youxu0000000002</span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 2] ls /</span><br><span class=\"line\">[youxu0000000002, zookeeper, murasaki]</span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 3] create -s /youxu2 hello</span><br><span class=\"line\">Created /youxu20000000003</span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 4] ls /</span><br><span class=\"line\">[youxu20000000003, youxu0000000002, zookeeper, murasaki]</span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 5]</span><br></pre></td></tr></table></figure>\n<p><strong>EPHEMERAL_SEQUENTIAL-临时顺序节点</strong></p>\n<ul>\n<li>基本特性同临时节点，增加了顺序属性，节点名后边会追加一个由父节点维护的自增整型数字。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[zk: localhost:2181(CONNECTED) 6] ls /</span><br><span class=\"line\">[youxu20000000003, youxu0000000002, zookeeper, murasaki]</span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 7] create -s -e /linshiyouxu hello</span><br><span class=\"line\">Created /linshiyouxu0000000004</span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 8] ls /</span><br><span class=\"line\">[youxu20000000003, youxu0000000002, zookeeper, murasaki, linshiyouxu0000000004]</span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 9] quit</span><br><span class=\"line\"></span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 0] ls /</span><br><span class=\"line\">[youxu20000000003, youxu0000000002, zookeeper, murasaki]</span><br></pre></td></tr></table></figure>\n<p><strong>思考：</strong></p>\n<ul>\n<li>Q：一个zookeeper集群有三台机器A、B、C，A机器创建临时节点后A断开，问B机器还有会临时节点吗？</li>\n<li>A：因为是A机器创建的节点，所以当A机器的zkClient断开连接时，节点会被删除，B机器同样也看不到临时节点了。</li>\n</ul>\n<ul>\n<li>Q：一个zookeeper集群有三台机器A、B、C，A机器创建临时节点后B断开，问临时节点还在吗？</li>\n<li>A：还在，因为是A机器创建的临时节点，只要A机器的zkClient依然保持连接，临时节点就不会删除。</li>\n</ul>\n<h3 id=\"Stat-数据结构\"><a href=\"#Stat-数据结构\" class=\"headerlink\" title=\"Stat 数据结构\"></a>Stat 数据结构</h3><p>Stat中记录了这个 ZNode 的三个数据版本，分别是version（当前ZNode的版本）、cversion（当前ZNode子节点的版本）和 cversion（当前ZNode的ACL版本）。<br>Stat：状态信息、版本、权限相关</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[zk: localhost:2181(CONNECTED) 1] get /murasaki</span><br><span class=\"line\">hello</span><br><span class=\"line\">cZxid = 0x400000002</span><br><span class=\"line\">ctime = Thu Feb 21 10:53:25 CST 2019</span><br><span class=\"line\">mZxid = 0x400000002</span><br><span class=\"line\">mtime = Thu Feb 21 10:53:25 CST 2019</span><br><span class=\"line\">pZxid = 0x400000003</span><br><span class=\"line\">cversion = 1</span><br><span class=\"line\">dataVersion = 0</span><br><span class=\"line\">aclVersion = 0</span><br><span class=\"line\">ephemeralOwner = 0x0</span><br><span class=\"line\">dataLength = 5</span><br><span class=\"line\">numChildren = 1</span><br></pre></td></tr></table></figure>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">状态属性</th>\n<th style=\"text-align:left\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">czxid</td>\n<td style=\"text-align:left\">节点创建时的zxid</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">mzxid</td>\n<td style=\"text-align:left\">节点最新一次更新发生时的zxid</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">ctime</td>\n<td style=\"text-align:left\">节点创建时的时间戳</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">mtime</td>\n<td style=\"text-align:left\">节点最新一次更新发生时的时间戳</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">dataVersion</td>\n<td style=\"text-align:left\">节点数据的更新次数</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">cversion</td>\n<td style=\"text-align:left\">其子节点的更新次数</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">aclVersion</td>\n<td style=\"text-align:left\">节点ACL（授权信息）的更新次数</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">ephemeralOwner</td>\n<td style=\"text-align:left\">如果该节点为ephemeral（临时）节点, ephemeralOwner值表示与该节点绑定的session id. 如果该节点不是ephemeral节点, ephemeralOwner值为0.</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">dataLength</td>\n<td style=\"text-align:left\">节点数据的字节数</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">numChildren</td>\n<td style=\"text-align:left\">子节点个数</td>\n</tr>\n</tbody>\n</table>\n<p>Session会话：<br>客户端来创建一个和zk服务端连接的句柄。<br>连接状态：CONNECTING\\CONNECTED\\CLOSED</p>\n<h2 id=\"3-watcher\"><a href=\"#3-watcher\" class=\"headerlink\" title=\"3.watcher\"></a>3.watcher</h2><h3 id=\"什么是watcher\"><a href=\"#什么是watcher\" class=\"headerlink\" title=\"什么是watcher\"></a>什么是watcher</h3><p>Watcher（事件监听器），是zookeeper中的一个很重要的特性。zookeeper允许用户在指定节点（znode）上注册一些Watcher，并且在一些特定事件触发的时候，zookeeper服务端会将事件通知到感兴趣的客户端上去，该机制zookeeper实现分布式协调服务的<font color=\"red\">重要特性。</font></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">1.首先我们在集群1机器上执行以下命令</span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 2] get /murasaki watcher</span><br><span class=\"line\">hello</span><br><span class=\"line\">cZxid = 0x400000002</span><br><span class=\"line\">ctime = Thu Feb 21 10:53:25 CST 2019</span><br><span class=\"line\">mZxid = 0x400000002</span><br><span class=\"line\">mtime = Thu Feb 21 10:53:25 CST 2019</span><br><span class=\"line\">pZxid = 0x400000003</span><br><span class=\"line\">cversion = 1</span><br><span class=\"line\">dataVersion = 0</span><br><span class=\"line\">aclVersion = 0</span><br><span class=\"line\">ephemeralOwner = 0x0</span><br><span class=\"line\">dataLength = 5</span><br><span class=\"line\">numChildren = 1</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">2.然后我们在集群2机器上修改/murasaki节点，并把值设为666</span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 2] set /murasaki 666</span><br><span class=\"line\">cZxid = 0x400000002</span><br><span class=\"line\">ctime = Thu Feb 21 10:53:25 CST 2019</span><br><span class=\"line\">mZxid = 0x800000003</span><br><span class=\"line\">mtime = Fri Feb 22 00:59:05 CST 2019</span><br><span class=\"line\">pZxid = 0x400000003</span><br><span class=\"line\">cversion = 1</span><br><span class=\"line\">dataVersion = 1</span><br><span class=\"line\">aclVersion = 0</span><br><span class=\"line\">ephemeralOwner = 0x0</span><br><span class=\"line\">dataLength = 3</span><br><span class=\"line\">numChildren = 1</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">3.回到集群1机器，会触发watcher时间</span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 3] </span><br><span class=\"line\">WATCHER::</span><br><span class=\"line\"></span><br><span class=\"line\">WatchedEvent state:SyncConnected type:NodeDataChanged path:/murasaki</span><br></pre></td></tr></table></figure>\n<p>根据上面的客户端代码，我们可以看到三个重要的属性：state、type、Path<br>下面重点说明一下state、type两个属性的主要意义。</p>\n<p><strong>SyncConnected</strong></p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">KeeperState</th>\n<th style=\"text-align:left\">EventType</th>\n<th style=\"text-align:left\">触发条件</th>\n<th style=\"text-align:left\">说明</th>\n<th style=\"text-align:left\">操作</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">SyncConnected</td>\n<td style=\"text-align:left\">None</td>\n<td style=\"text-align:left\">客户端与服务端成功建立连接</td>\n<td style=\"text-align:left\">此时客户端和服务器处于连接状态</td>\n<td style=\"text-align:left\"></td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">NodeCreated</td>\n<td style=\"text-align:left\">Watcher监听的对应数据节点被创建</td>\n<td style=\"text-align:left\">此时客户端和服务器处于连接状态</td>\n<td style=\"text-align:left\">Create</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">NodeDeleted</td>\n<td style=\"text-align:left\">Watcher监听的对应数据节点被删除</td>\n<td style=\"text-align:left\">此时客户端和服务器处于连接状态</td>\n<td style=\"text-align:left\">Delete/znode</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">NodeDataChanged</td>\n<td style=\"text-align:left\">Watcher监听的对应数据节点的数据内容发生改变</td>\n<td style=\"text-align:left\">此时客户端和服务器处于连接状态</td>\n<td style=\"text-align:left\">setDate/znode</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">NodeChildChanged</td>\n<td style=\"text-align:left\">Watcher监听的对应数据节点的子节点列表发生变更</td>\n<td style=\"text-align:left\">此时客户端和服务器处于连接状态</td>\n<td style=\"text-align:left\">Create/child</td>\n</tr>\n</tbody>\n</table>\n<p><strong>Disconnected</strong></p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">KeeperState</th>\n<th style=\"text-align:left\">EventType</th>\n<th style=\"text-align:left\">触发条件</th>\n<th style=\"text-align:left\">说明</th>\n<th style=\"text-align:left\">操作</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">Disconnected</td>\n<td style=\"text-align:left\">None</td>\n<td style=\"text-align:left\">客户端与zookeeper服务器断开连接</td>\n<td style=\"text-align:left\">此时客户端和服务器处于断开连接状态</td>\n</tr>\n</tbody>\n</table>\n<p><strong>Expired</strong></p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">KeeperState</th>\n<th style=\"text-align:left\">EventType</th>\n<th style=\"text-align:left\">触发条件</th>\n<th style=\"text-align:left\">说明</th>\n<th style=\"text-align:left\">操作</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">Expired</td>\n<td style=\"text-align:left\">None</td>\n<td style=\"text-align:left\">会话超时</td>\n<td style=\"text-align:left\">此时客户端会话失效，通畅同时也会收到SessionExpiredException异常</td>\n</tr>\n</tbody>\n</table>\n<p><strong>AuthFailed</strong></p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">KeeperState</th>\n<th style=\"text-align:left\">EventType</th>\n<th style=\"text-align:left\">触发条件</th>\n<th style=\"text-align:left\">说明</th>\n<th style=\"text-align:left\">操作</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">AuthFailed</td>\n<td style=\"text-align:left\">None</td>\n<td style=\"text-align:left\">通常有两种情况，1：使用错误的schema进行权限检查 2：SASL权限检查失败</td>\n<td style=\"text-align:left\">通常同时也会收到AuthFailedException异常</td>\n</tr>\n</tbody>\n</table>\n<p>通过这个监听机制，我们就可以监听节点状态，以及节点何时发生了改变。</p>\n<p><img src=\"https://ws2.sinaimg.cn/large/006tKfTcly1g0k1c1vokmj31ds0sstbh.jpg\" alt=\"\"></p>\n<p>比如分布式任务调度中心，有三个交易的任务，每一个都与Job调度中心建立连接，假如此时我们只让B机器执行交易任务，当有一天B机器挂了，通过watcher机制，我们就可以知道B机器的会话状态为Disconnected，因此我们就可以做相应的处理。</p>\n<h2 id=\"4-ACL\"><a href=\"#4-ACL\" class=\"headerlink\" title=\"4.ACL\"></a>4.ACL</h2><h3 id=\"什么是ACL\"><a href=\"#什么是ACL\" class=\"headerlink\" title=\"什么是ACL\"></a>什么是ACL</h3><p>ACL全称：Access Control List，字面理解就是访问控制集合。<br>其中包含了内置的ACl Scheemes：</p>\n<ul>\n<li>world：默认方式，相当于全世界都能访问。</li>\n<li>auth：代表已经认证通过的用户（客户端中可以通过addauth digest user:pwd 来添加当前的上下文中的授权用户）</li>\n<li>digest：即用户名：密码 这种认证方式进行认证，这也是业务系统中最常用的。</li>\n<li>ip：使用IP地址认证。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[zk: localhost:2181(CONNECTED) 0] ls /</span><br><span class=\"line\">[youxu20000000003, youxu0000000002, zookeeper, murasaki, ceshi0000000005]</span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 1] getAcl /murasaki</span><br><span class=\"line\">&apos;world,&apos;anyone</span><br><span class=\"line\">: cdrwa</span><br></pre></td></tr></table></figure>\n<p>根据上述代码我们可以知道，world 就是说明 murasaki 这个节点是所有用户都可以访问的。<br>那么这个 cdrwa 是什么呢？</p>\n<p>cdrwa 指的就是ACL所支持的权限。    </p>\n<ul>\n<li><font color=\"red\">C</font>REATE：能创建子节点。</li>\n<li><font color=\"red\">D</font>ELETE：能删除子节点。</li>\n<li><font color=\"red\">R</font>EAD：能获取节点数据和列出其子节点。</li>\n<li><font color=\"red\">W</font>RITE：能设置节点数据。</li>\n<li><font color=\"red\">A</font>DMIN：能设置权限。</li>\n</ul>\n<p>cdrwa也是这些权限的首字母。</p>\n<p><strong>接下来，我们通过实操来设置一个具有权限认证的节点</strong></p>\n<ol>\n<li><p>首先在我们的集群A机器上执行如下操作,先创建一个用户，账号为murasaki，密码为seifu</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[zk: localhost:2181(CONNECTED) 0] addauth digest murasaki:seifu</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>然后我们创建一个节点，并且现在集群B机器可以访问</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[zk: localhost:2181(CONNECTED) 1] create /quanxian hello</span><br><span class=\"line\">Created /quanxian</span><br><span class=\"line\"></span><br><span class=\"line\">集群B机器：</span><br><span class=\"line\"></span><br><span class=\"line\">WATCHER::</span><br><span class=\"line\"></span><br><span class=\"line\">WatchedEvent state:SyncConnected type:None path:null</span><br><span class=\"line\">[zk: localhost:2181(CONNECTED) 0] get /quanxian</span><br><span class=\"line\">hello</span><br><span class=\"line\">cZxid = 0xb00000006</span><br><span class=\"line\">ctime = Fri Feb 22 12:24:58 CST 2019</span><br><span class=\"line\">mZxid = 0xb00000006</span><br><span class=\"line\">mtime = Fri Feb 22 12:24:58 CST 2019</span><br><span class=\"line\">pZxid = 0xb00000006</span><br><span class=\"line\">cversion = 0</span><br><span class=\"line\">dataVersion = 0</span><br><span class=\"line\">aclVersion = 0</span><br><span class=\"line\">ephemeralOwner = 0x0</span><br><span class=\"line\">dataLength = 5</span><br><span class=\"line\">numChildren = 0</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>然后回到我们的集群A机器，对这个节点进行权限设置</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[zk: localhost:2181(CONNECTED) 2] setAcl /quanxian auth:murasaki:seifu:cdrwa</span><br><span class=\"line\">cZxid = 0xb00000006</span><br><span class=\"line\">ctime = Fri Feb 22 12:24:58 CST 2019</span><br><span class=\"line\">mZxid = 0xb00000006</span><br><span class=\"line\">mtime = Fri Feb 22 12:24:58 CST 2019</span><br><span class=\"line\">pZxid = 0xb00000006</span><br><span class=\"line\">cversion = 0</span><br><span class=\"line\">dataVersion = 0</span><br><span class=\"line\">aclVersion = 1</span><br><span class=\"line\">ephemeralOwner = 0x0</span><br><span class=\"line\">dataLength = 5</span><br><span class=\"line\">numChildren = 0</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>我们在集群A机器获取一下这个节点Acl信息，会发现和以前不一样了，现在这个节点已经带着我们的权限信息了</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[zk: localhost:2181(CONNECTED) 3] getAcl /quanxian</span><br><span class=\"line\">&apos;digest,&apos;murasaki:7Ae+lxj75Wgx4JLEoBSFSRdv218=</span><br><span class=\"line\">: cdrwa</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>但是，这时我们依然在集群A机器上获取一下这个节点数据，发现能获取到，这是为什么？原因就是此时我们的session会话依然是连接，所以依然可以获取到。</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[zk: localhost:2181(CONNECTED) 4] get /quanxian</span><br><span class=\"line\">hello</span><br><span class=\"line\">cZxid = 0xb00000006</span><br><span class=\"line\">ctime = Fri Feb 22 12:24:58 CST 2019</span><br><span class=\"line\">mZxid = 0xb00000006</span><br><span class=\"line\">mtime = Fri Feb 22 12:24:58 CST 2019</span><br><span class=\"line\">pZxid = 0xb00000006</span><br><span class=\"line\">cversion = 0</span><br><span class=\"line\">dataVersion = 0</span><br><span class=\"line\">aclVersion = 1</span><br><span class=\"line\">ephemeralOwner = 0x0</span><br><span class=\"line\">dataLength = 5</span><br><span class=\"line\">numChildren = 0</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>当我们在集群B机器上去获取这个节点时，就获取不到了。</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[zk: localhost:2181(CONNECTED) 1] get /quanxian</span><br><span class=\"line\">Authentication is not valid : /quanxian</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h2 id=\"5-高性能\"><a href=\"#5-高性能\" class=\"headerlink\" title=\"5.高性能\"></a>5.高性能</h2><p>ZooKeeper 是高性能的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。）</p>\n<h2 id=\"6-顺序访问\"><a href=\"#6-顺序访问\" class=\"headerlink\" title=\"6.顺序访问\"></a>6.顺序访问</h2><p>对于来自客户端的每个更新请求，ZooKeeper 都会分配一个全局唯一的递增编号，这个编号反应了所有事务操作的先后顺序，应用程序可以使用 ZooKeeper 这个特性来实现更高层次的同步原语。 这个编号也叫做时间戳——zxid（Zookeeper Transaction Id）</p>\n","categories":["分布式专题"],"tags":[]},{"title":"Zookeeper快速入门&集群部署","url":"http://ilovenorth.cn/2019/02/22/Zookeeper快速入门-集群部署/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"Zookeeper快速入门-amp-集群部署\"><a href=\"#Zookeeper快速入门-amp-集群部署\" class=\"headerlink\" title=\"Zookeeper快速入门&amp;集群部署\"></a>Zookeeper快速入门&amp;集群部署</h1><h2 id=\"单机模式的环境搭建\"><a href=\"#单机模式的环境搭建\" class=\"headerlink\" title=\"单机模式的环境搭建\"></a>单机模式的环境搭建</h2><ol>\n<li>官网下载</li>\n</ol>\n<pre><code>http://mirrors.shu.edu.cn/apache/zookeeper/zookeeper-3.4.10/\n</code></pre><ol start=\"2\">\n<li>上传到服务器</li>\n</ol>\n<pre><code>scp zookeeper-3.4.10.tar.gz 用户名@服务器IP:上传至的目录\n</code></pre><p><strong>eg.</strong> 目标端和源端两台服务器都安装了scp命令之后，才可以通过scp命令互相传输。</p>\n<pre><code>安装scp命令：\nyum -y install openssh-clients\n</code></pre><ol start=\"3\">\n<li>解压压缩包 zookeeper-3.4.10.tar.gz </li>\n</ol>\n<pre><code>tar -zxvf zookeeper-3.4.10.tar.gz\n</code></pre><ol start=\"4\">\n<li>进入 zookeeper-3.4.10 目录下的conf文件夹，重命名zoo_simple.cfg</li>\n</ol>\n<pre><code>mv zoo_sample.cfg zoo.cfg\n</code></pre><ol start=\"5\">\n<li>启动：进入 zookeeper-3.4.10 目录下的bin文件夹</li>\n</ol>\n<pre><code>sh zkServer.sh start\n\n显示如下信息则为启动成功：\nZooKeeper JMX enabled by default\nUsing config: /root/zookeeper-3.4.10/bin/../conf/zoo.cfg\nStarting zookeeper ... STARTED\n</code></pre><ol start=\"6\">\n<li>验证一下，同样是 zookeeper-3.4.10 目录下的conf文件夹</li>\n</ol>\n<pre><code>sh zkServer.sh status\n\n显示如下信息则为启动成功：\nZooKeeper JMX enabled by default\nUsing config: /root/zookeeper-3.4.10/bin/../conf/zoo.cfg\nMode: standalone #单机模式\n</code></pre><ol start=\"7\">\n<li>连接客户端，同样是 zookeeper-3.4.10 目录下的conf文件夹</li>\n</ol>\n<pre><code>sh zkCli.sh\n</code></pre><h2 id=\"集群模式搭建\"><a href=\"#集群模式搭建\" class=\"headerlink\" title=\"集群模式搭建\"></a>集群模式搭建</h2><ol>\n<li>启动3台服务器，修改zoo.cfg配置文件</li>\n</ol>\n<pre><code>在配置文档的末尾加上：\nserver.1=192.168.187.200:2188:2888\nserver.2=192.168.187.201:2188:2888\nserver.3=192.168.187.202:2188:2888\n</code></pre><p><strong>zoo.cfg 参数</strong>    </p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">参数</th>\n<th style=\"text-align:left\">意义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">tickTime</td>\n<td style=\"text-align:left\">2000</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">syncLimit</td>\n<td style=\"text-align:left\">Leader和follower之间的通讯时长最长不能超过initLimt * ticktime</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">initLimt</td>\n<td style=\"text-align:left\">接受客户端链接zk初始化的最长等待心跳时长initLimt * ticktime</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">dataDir</td>\n<td style=\"text-align:left\">数据目录</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">dataLogDir</td>\n<td style=\"text-align:left\">日志文件</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">clientPort</td>\n<td style=\"text-align:left\">客户端链接服务端端口号</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Server.A=B:C:D</td>\n<td style=\"text-align:left\">A:第几号服务器<br>B:服务IP<br>C:代表Leader和follower通讯端口<br>D:备用选leader端口</td>\n</tr>\n</tbody>\n</table>\n<ol start=\"2\">\n<li>根据自己配置的dataDir目录，在三台服务器中添加myid文件，这个myid为投票选举的标志id，同时也是告诉zk这是哪台服务器，细节后面再讲。</li>\n</ol>\n<pre><code>echo &quot;1&quot; &gt; /usr/local/zookeeper/myid\necho &quot;2&quot; &gt; /usr/local/zookeeper/myid\necho &quot;3&quot; &gt; /usr/local/zookeeper/myid\n</code></pre><ol start=\"3\">\n<li>然后依次启动就好，控制台会打印出一下信息。</li>\n</ol>\n<pre><code>ZooKeeper JMX enabled by default\nUsing config: /root/zookeeper-3.4.10/bin/../conf/zoo.cfg\nMode: follower\n</code></pre><p><strong>注意：</strong>    </p>\n<ul>\n<li>集群模式，服务器之前互相通讯，所以要关闭防火墙。</li>\n<li>集群模式需要Java环境。</li>\n</ul>\n<pre><code># 关闭防火墙\nservice iptables stop\n\n# 如果提示 iptables unrecognized service，则需要安装：\nyum install -y iptables\n</code></pre><h2 id=\"集群模式介绍\"><a href=\"#集群模式介绍\" class=\"headerlink\" title=\"集群模式介绍\"></a>集群模式介绍</h2><h3 id=\"角色\"><a href=\"#角色\" class=\"headerlink\" title=\"角色\"></a>角色</h3><hr>\n<p><strong>Leader ：</strong></p>\n<p>   Leader作为整个ZooKeeper集群的主节点，负责响应所有对ZooKeeper状态变更的请求。它会将每个状态更新请求进行排序和编号，<font color=\"red\">以便保证整个集群内部消息处理的FIFO（先进先出），写操作都走leader，zk里面leader只有一个。</font></p>\n<p><strong>Follower ：</strong></p>\n<p>   Follower的逻辑就比较简单了。除了响应本服务器上的读请求外，follower还要处理leader的提议，并在leader提交该提议时在本地也进行提交。<br>   另外需要注意的是，leader和follower构成ZooKeeper集群的法定人数，也就是说，只有他们才参与新leader的选举、响应leader的提议。<font color=\"red\">帮助leader处理读请求，投票权。</font>    </p>\n<p><strong>Observer ：</strong>    </p>\n<p>   如果ZooKeeper集群的读取负载很高，或者客户端多到跨机房，可以设置一些observer服务器，以提高读取的吞吐量。Observer和Follower比较相似，只有一些小区别：首先observer不属于法定人数，即不参加选举也不响应提议；其次是observer不需要将事务持久化到磁盘，一旦observer被重启，需要从leader重新同步整个名字空间。 <font color=\"red\">没有投票权利，可以处理读请求。</font></p>\n<h3 id=\"zookeeper命令介绍\"><a href=\"#zookeeper命令介绍\" class=\"headerlink\" title=\"zookeeper命令介绍\"></a>zookeeper命令介绍</h3><hr>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">命令</th>\n<th style=\"text-align:left\">意义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">ls</td>\n<td style=\"text-align:left\">ls 命令来查看某个目录包含的所有文件</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">ls2</td>\n<td style=\"text-align:left\">ls2 命令来查看某个目录包含的所有文件，与ls不同的是它查看到time、version等信息</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">create</td>\n<td style=\"text-align:left\">创建znode，并设置初始内容</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">get</td>\n<td style=\"text-align:left\">获取znode的数据</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">set</td>\n<td style=\"text-align:left\">修改znode内容</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">delete</td>\n<td style=\"text-align:left\">删除znode</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">quit</td>\n<td style=\"text-align:left\">退出客户端</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">help</td>\n<td style=\"text-align:left\">帮助命令</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">rmr</td>\n<td style=\"text-align:left\">递归删除 可以删除包含有子节点的</td>\n</tr>\n</tbody>\n</table>\n","categories":["分布式专题"],"tags":[]},{"title":"HashMap源码分析","url":"http://ilovenorth.cn/2019/01/22/HashMap源码分析-md/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"Map-源码分析\"><a href=\"#Map-源码分析\" class=\"headerlink\" title=\"Map 源码分析\"></a>Map 源码分析</h1><h2 id=\"HashMap-amp-HashTable-amp-ConcurrentHashMap\"><a href=\"#HashMap-amp-HashTable-amp-ConcurrentHashMap\" class=\"headerlink\" title=\"HashMap&amp;HashTable&amp;ConcurrentHashMap\"></a>HashMap&amp;HashTable&amp;ConcurrentHashMap</h2><h2 id=\"HashMap\"><a href=\"#HashMap\" class=\"headerlink\" title=\"HashMap\"></a>HashMap</h2><p><strong>首先我们看一下HashMap类的静态属性。</strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">HashMap</span>&lt;<span class=\"title\">K</span>,<span class=\"title\">V</span>&gt; <span class=\"keyword\">extends</span> <span class=\"title\">AbstractMap</span>&lt;<span class=\"title\">K</span>,<span class=\"title\">V</span>&gt;</span></span><br><span class=\"line\"><span class=\"class\">    <span class=\"keyword\">implements</span> <span class=\"title\">Map</span>&lt;<span class=\"title\">K</span>,<span class=\"title\">V</span>&gt;, <span class=\"title\">Cloneable</span>, <span class=\"title\">Serializable</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> serialVersionUID = <span class=\"number\">362498820763181265L</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 默认初始容量 - 必须是2的幂。</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> DEFAULT_INITIAL_CAPACITY = <span class=\"number\">1</span> &lt;&lt; <span class=\"number\">4</span>; <span class=\"comment\">// aka 16</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 最大容量为2的30次幂。</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> MAXIMUM_CAPACITY = <span class=\"number\">1</span> &lt;&lt; <span class=\"number\">30</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 如果构造函数中没有指定，则使用该默认的加载因子。</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">float</span> DEFAULT_LOAD_FACTOR = <span class=\"number\">0.75f</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 如果一个桶中的元素个数超过 TREEIFY_THRESHOLD(默认是 8 )，就使用红黑树来替换链表</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> TREEIFY_THRESHOLD = <span class=\"number\">8</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 一个树的链表还原阈值，当扩容时，桶中元素个数小于这个值,就会把树形的桶元素还原（切分）为链表结构</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> UNTREEIFY_THRESHOLD = <span class=\"number\">6</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 哈希表的最小树形化容量</span></span><br><span class=\"line\"><span class=\"comment\">\t * 当哈希表中的容量大于这个值时，表中的桶才能进行树形化</span></span><br><span class=\"line\"><span class=\"comment\">\t * 否则桶内元素太多时会扩容，而不是树形化</span></span><br><span class=\"line\"><span class=\"comment\">\t * 为了避免进行扩容、树形化选择的冲突，这个值不能小于 4 * TREEIFY_THRESHOLD</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> MIN_TREEIFY_CAPACITY = <span class=\"number\">64</span>;</span><br></pre></td></tr></table></figure>\n<p>通过属性，我们就可以得知HashMap的基础信息：</p>\n<ul>\n<li>初始化默认大小为16.</li>\n<li>最大容量为2的30次幂。</li>\n<li>默认的扩容复制因子为0.75.</li>\n<li>JDK1.8中，当一个bucket的链表容量大于8时，将链表转换为红黑树结构。</li>\n<li>当一个bucket的红黑树结构容量小于6时，将红黑树结构转换为链表结构。</li>\n</ul>\n<p><strong>再让我们看看HashMap类的字段。</strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* ---------------- Fields -------------- */</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 该表在首次使用时初始化，并根据需要调整大小。分配时，长度始终为2的幂。</span></span><br><span class=\"line\"><span class=\"comment\">     * 保存Node&lt;K,V&gt;节点的数组</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">transient</span> Node&lt;K,V&gt;[] table;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 由　hashMap 中 Node&lt;K,V&gt;　节点构成的 set</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">transient</span> Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 记录 hashMap 当前存储的元素的数量</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">transient</span> <span class=\"keyword\">int</span> size;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 记录　hashMap 发生结构性变化的次数（注意　value 的覆盖不属于结构性变化）</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">transient</span> <span class=\"keyword\">int</span> modCount;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * threshold的值应等于 table.length * loadFactor, size超过这个值时进行resize()扩容</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> threshold;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 记录 hashMap 装载因子</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"keyword\">float</span> loadFactor;</span><br></pre></td></tr></table></figure>\n<p><strong>HashMap 结构。</strong></p>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tNc79ly1fz9fvpuiw9j319u0niac9.jpg\" alt=\"\"></p>\n<p>HashMap底层就是一个数组结构，数组中的每一项又是一个链表。当新建一个HashMap的时候，就会初始化一个数组。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Node</span>&lt;<span class=\"title\">K</span>,<span class=\"title\">V</span>&gt; <span class=\"keyword\">implements</span> <span class=\"title\">Map</span>.<span class=\"title\">Entry</span>&lt;<span class=\"title\">K</span>,<span class=\"title\">V</span>&gt; </span>&#123;</span><br><span class=\"line\">       <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> hash; <span class=\"comment\">//hash值</span></span><br><span class=\"line\">       <span class=\"keyword\">final</span> K key;    <span class=\"comment\">//键</span></span><br><span class=\"line\">       V value;        <span class=\"comment\">//值</span></span><br><span class=\"line\">       Node&lt;K,V&gt; next; <span class=\"comment\">//用于指向链表的下一层（产生冲突，用拉链法）</span></span><br><span class=\"line\"></span><br><span class=\"line\">       Node(<span class=\"keyword\">int</span> hash, K key, V value, Node&lt;K,V&gt; next) &#123;</span><br><span class=\"line\">           <span class=\"keyword\">this</span>.hash = hash;</span><br><span class=\"line\">           <span class=\"keyword\">this</span>.key = key;</span><br><span class=\"line\">           <span class=\"keyword\">this</span>.value = value;</span><br><span class=\"line\">           <span class=\"keyword\">this</span>.next = next;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">       <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> K <span class=\"title\">getKey</span><span class=\"params\">()</span>        </span>&#123; <span class=\"keyword\">return</span> key; &#125;</span><br><span class=\"line\">       <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> V <span class=\"title\">getValue</span><span class=\"params\">()</span>      </span>&#123; <span class=\"keyword\">return</span> value; &#125;</span><br><span class=\"line\">       <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> String <span class=\"title\">toString</span><span class=\"params\">()</span> </span>&#123; <span class=\"keyword\">return</span> key + <span class=\"string\">\"=\"</span> + value; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">       <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> <span class=\"title\">hashCode</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">           <span class=\"keyword\">return</span> Objects.hashCode(key) ^ Objects.hashCode(value);</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">       <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> V <span class=\"title\">setValue</span><span class=\"params\">(V newValue)</span> </span>&#123;</span><br><span class=\"line\">           V oldValue = value;</span><br><span class=\"line\">           value = newValue;</span><br><span class=\"line\">           <span class=\"keyword\">return</span> oldValue;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">       <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">boolean</span> <span class=\"title\">equals</span><span class=\"params\">(Object o)</span> </span>&#123;</span><br><span class=\"line\">           <span class=\"keyword\">if</span> (o == <span class=\"keyword\">this</span>)</span><br><span class=\"line\">               <span class=\"keyword\">return</span> <span class=\"keyword\">true</span>;</span><br><span class=\"line\">           <span class=\"keyword\">if</span> (o <span class=\"keyword\">instanceof</span> Map.Entry) &#123;</span><br><span class=\"line\">               Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o;</span><br><span class=\"line\">               <span class=\"keyword\">if</span> (Objects.equals(key, e.getKey()) &amp;&amp;</span><br><span class=\"line\">                   Objects.equals(value, e.getValue()))</span><br><span class=\"line\">                   <span class=\"keyword\">return</span> <span class=\"keyword\">true</span>;</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\">           <span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<p><strong>HashMap 构造函数</strong></p>\n<ul>\n<li>构造函数1：指定初始容量–&gt; initialCapacity 和 装载因子–&gt; loadFactor<ul>\n<li>如果initialCapacity（初始容量）小于0，则会抛出<font color=\"red\">非法参数异常</font>.</li>\n<li>如果initialCapacity（初始容量）大于最大容量，则将initialCapacity赋值为最大容量。</li>\n<li>如果loadFactor（复制因子）小于等于0，或者所表示的值是NaN，则会抛出<font color=\"red\">非法参数异常</font>.</li>\n<li>tableSizeFor(initialCapacity)　方法：返回最接近initialCapacity的2的次幂的值，若指定初始容量为９，则实际 hashMap 容量为16。</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">HashMap</span><span class=\"params\">(<span class=\"keyword\">int</span> initialCapacity, <span class=\"keyword\">float</span> loadFactor)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (initialCapacity &lt; <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalArgumentException(<span class=\"string\">\"Illegal initial capacity: \"</span> +</span><br><span class=\"line\">                                           initialCapacity);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (initialCapacity &gt; MAXIMUM_CAPACITY)</span><br><span class=\"line\">        initialCapacity = MAXIMUM_CAPACITY;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (loadFactor &lt;= <span class=\"number\">0</span> || Float.isNaN(loadFactor))</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalArgumentException(<span class=\"string\">\"Illegal load factor: \"</span> +</span><br><span class=\"line\">                                           loadFactor);</span><br><span class=\"line\">    <span class=\"keyword\">this</span>.loadFactor = loadFactor;</span><br><span class=\"line\">    <span class=\"keyword\">this</span>.threshold = tableSizeFor(initialCapacity);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> <span class=\"title\">tableSizeFor</span><span class=\"params\">(<span class=\"keyword\">int</span> cap)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> n = cap - <span class=\"number\">1</span>;</span><br><span class=\"line\">    n |= n &gt;&gt;&gt; <span class=\"number\">1</span>;<span class=\"comment\">// &gt;&gt;&gt; 无符号右移</span></span><br><span class=\"line\">    n |= n &gt;&gt;&gt; <span class=\"number\">2</span>;</span><br><span class=\"line\">    n |= n &gt;&gt;&gt; <span class=\"number\">4</span>;</span><br><span class=\"line\">    n |= n &gt;&gt;&gt; <span class=\"number\">8</span>;</span><br><span class=\"line\">    n |= n &gt;&gt;&gt; <span class=\"number\">16</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (n &lt; <span class=\"number\">0</span>) ? <span class=\"number\">1</span> : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>构造函数2：仅指定初始容量，装载因子的值为默认的0.75f</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">HashMap</span><span class=\"params\">(<span class=\"keyword\">int</span> initialCapacity)</span> </span>&#123;</span><br><span class=\"line\">       <span class=\"keyword\">this</span>(initialCapacity, DEFAULT_LOAD_FACTOR);</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>构造函数3：所有参数均采用默认值</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">HashMap</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">       <span class=\"keyword\">this</span>.loadFactor = DEFAULT_LOAD_FACTOR; <span class=\"comment\">// all other fields defaulted</span></span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>构造函数4：传入一个map<ul>\n<li>构造一个新的HashMap，其映射与指定的Map相同。HashMap是使用默认加载因子（0.75）创建的，初始容量足以保存指定Map中的映射。</li>\n<li>如果参数Map为null，则会抛出<font color=\"red\">空指针异常</font>。</li>\n<li>指定默认因子为0.75f    </li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">HashMap</span><span class=\"params\">(Map&lt;? extends K, ? extends V&gt; m)</span> </span>&#123;</span><br><span class=\"line\">       <span class=\"keyword\">this</span>.loadFactor = DEFAULT_LOAD_FACTOR;</span><br><span class=\"line\">       putMapEntries(m, <span class=\"keyword\">false</span>);</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"function\"><span class=\"keyword\">final</span> <span class=\"keyword\">void</span> <span class=\"title\">putMapEntries</span><span class=\"params\">(Map&lt;? extends K, ? extends V&gt; m, <span class=\"keyword\">boolean</span> evict)</span> </span>&#123;</span><br><span class=\"line\">       <span class=\"keyword\">int</span> s = m.size();</span><br><span class=\"line\">       <span class=\"keyword\">if</span> (s &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">       \t<span class=\"comment\">//如果本地Node&lt;K,V&gt;[] table为null 则根据Map的size进行初始化。</span></span><br><span class=\"line\">           <span class=\"keyword\">if</span> (table == <span class=\"keyword\">null</span>) &#123; <span class=\"comment\">// pre-size</span></span><br><span class=\"line\">               <span class=\"keyword\">float</span> ft = ((<span class=\"keyword\">float</span>)s / loadFactor) + <span class=\"number\">1.0F</span>;</span><br><span class=\"line\">               <span class=\"keyword\">int</span> t = ((ft &lt; (<span class=\"keyword\">float</span>)MAXIMUM_CAPACITY) ?</span><br><span class=\"line\">                        (<span class=\"keyword\">int</span>)ft : MAXIMUM_CAPACITY);</span><br><span class=\"line\">               <span class=\"keyword\">if</span> (t &gt; threshold)</span><br><span class=\"line\">                   threshold = tableSizeFor(t);</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\">           <span class=\"comment\">//如果参数Map的size大于threshold，则进行resize()扩容。</span></span><br><span class=\"line\">           <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (s &gt; threshold)</span><br><span class=\"line\">               resize();</span><br><span class=\"line\">           <span class=\"comment\">//遍历参数Map，将值赋给当前HashMap</span></span><br><span class=\"line\">           <span class=\"keyword\">for</span> (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123;</span><br><span class=\"line\">               K key = e.getKey();</span><br><span class=\"line\">               V value = e.getValue();</span><br><span class=\"line\">               putVal(hash(key), key, value, <span class=\"keyword\">false</span>, evict);</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"红黑树\"><a href=\"#红黑树\" class=\"headerlink\" title=\"红黑树\"></a>红黑树</h3><p>JDK1.8开始，HashMap引进红黑树作为又一存储结构。<br>由于篇幅较多，详情请移步:<a href=\"2019/01/18/红黑树详解/\">红黑树</a></p>\n<h3 id=\"HashMap-工作原理\"><a href=\"#HashMap-工作原理\" class=\"headerlink\" title=\"HashMap 工作原理\"></a>HashMap 工作原理</h3><p>HashMap 是基于hashing的原理。    </p>\n<p>我们使用put(key,value)存储对象到HashMap中，使用get(key)从HashMap中获取对象。当我们给put()方法传递key-value键值对时，我们先对键进行hashCode()方法，计算并返回的hashCode，通过该值找到Map数组的Bucket位置来存储Node对象。</p>\n<h4 id=\"HashMap-put方法分析\"><a href=\"#HashMap-put方法分析\" class=\"headerlink\" title=\"HashMap put方法分析\"></a>HashMap put方法分析</h4><p>在网上找到了这张图，感谢原作者，引用地址已在文末标识。<br>HashMap的put方法执行过程可以通过下图来理解。<br><img src=\"https://ws2.sinaimg.cn/large/006tNc79ly1fzar66rfkej311v0u07cj.jpg\" alt=\"\"></p>\n<p><strong>put源码分析：</strong></p>\n<ol>\n<li>判断Key-Value的节点数组是否为null，如果是就执行resize()扩容</li>\n<li>通过对key就行hash运算，我们得到了hash值，根据hash值通过计算得到插入数组的索引i，如果table[i]==null，就在该索引位置建立新的节点，并转向步骤9，否则执行步骤3</li>\n<li>判断\btable[i]的首个节点是否和key值一样，如果相同直接覆盖value，否则转向步骤4，这里的相同指的是hashCode以及equals</li>\n<li>判断数组table[i]的当前节点是否为红黑树，如果是红黑树，则直接通过putTreeVal()方法在树中插入键值对，否则转向步骤5</li>\n<li>如果不是红黑树，则当前节点下的数据结构为链表</li>\n<li>从JDK1.8开始，链表的插入是尾插法，之前为头插法，<a href=\"http://www.cnblogs.com/andy-zhou/p/5402984.html\" target=\"_blank\" rel=\"noopener\">头插法的缺陷</a>;</li>\n<li>遍历table[i],判断链表的长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中进行插入操作。</li>\n<li>如果不是红黑树，则为链表的插入方法，遍历过程中若发现key已经存在直接覆盖value即可。</li>\n<li>插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。</li>\n</ol>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> V <span class=\"title\">put</span><span class=\"params\">(K key, V value)</span> </span>&#123;</span><br><span class=\"line\">       <span class=\"keyword\">return</span> putVal(hash(key), key, value, <span class=\"keyword\">false</span>, <span class=\"keyword\">true</span>);</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"function\"><span class=\"keyword\">final</span> V <span class=\"title\">putVal</span><span class=\"params\">(<span class=\"keyword\">int</span> hash, K key, V value, <span class=\"keyword\">boolean</span> onlyIfAbsent,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                  <span class=\"keyword\">boolean</span> evict)</span> </span>&#123;</span><br><span class=\"line\">       Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; <span class=\"keyword\">int</span> n, i;</span><br><span class=\"line\">       <span class=\"comment\">// 1.判断tab节点数组是否为空</span></span><br><span class=\"line\">       <span class=\"keyword\">if</span> ((tab = table) == <span class=\"keyword\">null</span> || (n = tab.length) == <span class=\"number\">0</span>)</span><br><span class=\"line\">           n = (tab = resize()).length;</span><br><span class=\"line\">       <span class=\"comment\">// 2.计算index，并对null做处理 </span></span><br><span class=\"line\">       <span class=\"keyword\">if</span> ((p = tab[i = (n - <span class=\"number\">1</span>) &amp; hash]) == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">           tab[i] = newNode(hash, key, value, <span class=\"keyword\">null</span>);</span><br><span class=\"line\">       <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">           Node&lt;K,V&gt; e; K k;</span><br><span class=\"line\">           <span class=\"comment\">// 3.判断节点key是否存在，如果存在则覆盖value</span></span><br><span class=\"line\">           <span class=\"keyword\">if</span> (p.hash == hash &amp;&amp;</span><br><span class=\"line\">               ((k = p.key) == key || (key != <span class=\"keyword\">null</span> &amp;&amp; key.equals(k))))</span><br><span class=\"line\">               e = p;</span><br><span class=\"line\">           <span class=\"comment\">// 4.判断该数组下的链表是否为红黑树</span></span><br><span class=\"line\">           <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (p <span class=\"keyword\">instanceof</span> TreeNode)</span><br><span class=\"line\">               e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(<span class=\"keyword\">this</span>, tab, hash, key, value);</span><br><span class=\"line\">           <span class=\"comment\">// 5.判断为链表</span></span><br><span class=\"line\">           <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">               <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> binCount = <span class=\"number\">0</span>; ; ++binCount) &#123;</span><br><span class=\"line\">               \t    <span class=\"comment\">// 6.JDK1.8开始 链表的插入是尾插法</span></span><br><span class=\"line\">                   <span class=\"keyword\">if</span> ((e = p.next) == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                       p.next = newNode(hash, key, value, <span class=\"keyword\">null</span>);</span><br><span class=\"line\">                       <span class=\"comment\">// 7.链表长度如果大于8则转换为红黑树</span></span><br><span class=\"line\">                       <span class=\"keyword\">if</span> (binCount &gt;= TREEIFY_THRESHOLD - <span class=\"number\">1</span>) <span class=\"comment\">// -1 for 1st</span></span><br><span class=\"line\">                           treeifyBin(tab, hash);</span><br><span class=\"line\">                       <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                   &#125;</span><br><span class=\"line\">                   <span class=\"comment\">// 8.key已存在则直接覆盖value</span></span><br><span class=\"line\">                   <span class=\"keyword\">if</span> (e.hash == hash &amp;&amp;</span><br><span class=\"line\">                       ((k = e.key) == key || (key != <span class=\"keyword\">null</span> &amp;&amp; key.equals(k))))</span><br><span class=\"line\">                       <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                   p = e;</span><br><span class=\"line\">               &#125;</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\">           <span class=\"keyword\">if</span> (e != <span class=\"keyword\">null</span>) &#123; <span class=\"comment\">// existing mapping for key</span></span><br><span class=\"line\">               V oldValue = e.value;</span><br><span class=\"line\">               <span class=\"keyword\">if</span> (!onlyIfAbsent || oldValue == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">                   e.value = value;</span><br><span class=\"line\">               afterNodeAccess(e);</span><br><span class=\"line\">               <span class=\"keyword\">return</span> oldValue;</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       ++modCount;</span><br><span class=\"line\">       <span class=\"comment\">// 9.如果现在的超过容量阈值 就扩容</span></span><br><span class=\"line\">       <span class=\"keyword\">if</span> (++size &gt; threshold)</span><br><span class=\"line\">           resize();</span><br><span class=\"line\">       afterNodeInsertion(evict);</span><br><span class=\"line\">       <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"HashMap-get方法分析\"><a href=\"#HashMap-get方法分析\" class=\"headerlink\" title=\"HashMap get方法分析\"></a>HashMap get方法分析</h4><p>当我们调用 get() 方法，HashMap 会使用键对象的 hashcode 找到 bucket 位置，找到 bucket 位置之后，会调用 keys.equals() 方法去找到链表中正确的节点，最终找到要找的值对象。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> V <span class=\"title\">get</span><span class=\"params\">(Object key)</span> </span>&#123;</span><br><span class=\"line\">    Node&lt;K,V&gt; e;</span><br><span class=\"line\">    <span class=\"comment\">// 根据输入节点的hash值和key值利用getNode()方法进行查找</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> (e = getNode(hash(key), key)) == <span class=\"keyword\">null</span> ? <span class=\"keyword\">null</span> : e.value;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">final</span> Node&lt;K,V&gt; <span class=\"title\">getNode</span><span class=\"params\">(<span class=\"keyword\">int</span> hash, Object key)</span> </span>&#123;</span><br><span class=\"line\">    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; <span class=\"keyword\">int</span> n; K k;</span><br><span class=\"line\">    <span class=\"comment\">// 1.判断tab节点数组是否为空，并且tab节点下的链表或红黑树的第一个节点部不为</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((tab = table) != <span class=\"keyword\">null</span> &amp;&amp; (n = tab.length) &gt; <span class=\"number\">0</span> &amp;&amp;</span><br><span class=\"line\">        (first = tab[(n - <span class=\"number\">1</span>) &amp; hash]) != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (first.hash == hash &amp;&amp; <span class=\"comment\">// always check first node</span></span><br><span class=\"line\">            ((k = first.key) == key || (key != <span class=\"keyword\">null</span> &amp;&amp; key.equals(k))))</span><br><span class=\"line\">            <span class=\"keyword\">return</span> first;</span><br><span class=\"line\">        <span class=\"comment\">// 2. 该节点下如果指向下一个节点</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> ((e = first.next) != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">        \t\t<span class=\"comment\">// 3.若定位到的节点是　TreeNode 节点，则在树中进行查找</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (first <span class=\"keyword\">instanceof</span> TreeNode)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);</span><br><span class=\"line\">            <span class=\"keyword\">do</span> &#123;</span><br><span class=\"line\">                <span class=\"comment\">// 4.否则在链表中进行查找，会调用 keys.equals() 方法去找到链表中正确的节点，最终找到要找的值对象</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> (e.hash == hash &amp;&amp;</span><br><span class=\"line\">                    ((k = e.key) == key || (key != <span class=\"keyword\">null</span> &amp;&amp; key.equals(k))))</span><br><span class=\"line\">                    <span class=\"keyword\">return</span> e;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">while</span> ((e = e.next) != <span class=\"keyword\">null</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>树中查找的源码分析：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">final</span> TreeNode&lt;K,V&gt; <span class=\"title\">getTreeNode</span><span class=\"params\">(<span class=\"keyword\">int</span> h, Object k)</span> </span>&#123;</span><br><span class=\"line\">\t <span class=\"comment\">//从根节点开始，调用 find 方法进行查找</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> ((parent != <span class=\"keyword\">null</span>) ? root() : <span class=\"keyword\">this</span>).find(h, k, <span class=\"keyword\">null</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">final</span> TreeNode&lt;K,V&gt; <span class=\"title\">find</span><span class=\"params\">(<span class=\"keyword\">int</span> h, Object k, Class&lt;?&gt; kc)</span> </span>&#123;</span><br><span class=\"line\">    TreeNode&lt;K,V&gt; p = <span class=\"keyword\">this</span>;</span><br><span class=\"line\">    <span class=\"keyword\">do</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> ph, dir; K pk;</span><br><span class=\"line\">        TreeNode&lt;K,V&gt; pl = p.left, pr = p.right, q;</span><br><span class=\"line\">        <span class=\"comment\">// 首先进行hash值大小比较，根据大小把当前节点变为它的左子树或者右子树</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> ((ph = p.hash) &gt; h)</span><br><span class=\"line\">            p = pl;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (ph &lt; h)</span><br><span class=\"line\">            p = pr;</span><br><span class=\"line\">        <span class=\"comment\">// 如果hash值相同，则开始比较key值，如果key值相等就直接返回该节点。</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> ((pk = p.key) == k || (k != <span class=\"keyword\">null</span> &amp;&amp; k.equals(pk)))</span><br><span class=\"line\">            <span class=\"keyword\">return</span> p;</span><br><span class=\"line\">        <span class=\"comment\">// 如果 左子树或者右子树为空 则指向另一侧的子树</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (pl == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">            p = pr;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (pr == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">            p = pl;</span><br><span class=\"line\">        <span class=\"comment\">//执行到这儿，意味着hash 值相同，key 值不同</span></span><br><span class=\"line\">        <span class=\"comment\">//若k 是可比较的并且k.compareTo(pk) 返回结果不为０可进入下面elseif   </span></span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> ((kc != <span class=\"keyword\">null</span> ||</span><br><span class=\"line\">                  (kc = comparableClassFor(k)) != <span class=\"keyword\">null</span>) &amp;&amp;</span><br><span class=\"line\">                 (dir = compareComparables(kc, k, pk)) != <span class=\"number\">0</span>)</span><br><span class=\"line\">            p = (dir &lt; <span class=\"number\">0</span>) ? pl : pr;</span><br><span class=\"line\">        <span class=\"comment\">//若 k 是不可比较的　或者　k.compareTo(pk) 返回结果为０则在整棵树中进行查找，先找右子树，右子树没有再找左子树</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> ((q = pr.find(h, k, kc)) != <span class=\"keyword\">null</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> q;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            p = pl;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">while</span> (p != <span class=\"keyword\">null</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"减少hash碰撞\"><a href=\"#减少hash碰撞\" class=\"headerlink\" title=\"减少hash碰撞\"></a>减少hash碰撞</h4><p>扰动函数可以减少碰撞</p>\n<p>原理是如果两个不相等的对象返回不同的 hashcode 的话，那么碰撞的几率就会小些。这就意味着存链表结构减小，这样取值的话就不会频繁调用 equal 方法，从而提高 HashMap 的性能（扰动即 Hash 方法内部的算法实现，目的是让不同对象返回不同 hashcode）。</p>\n<p>使用不可变的、声明作 final 对象，并且采用合适的 equals() 和 hashCode() 方法，将会减少碰撞的发生</p>\n<p>不可变性使得能够缓存不同键的 hashcode，这将提高整个获取对象的速度，使用 String、Integer 这样的 wrapper 类作为键是非常好的选择。</p>\n<p>因为 String 是 final，而且已经重写了 equals() 和 hashCode() 方法了。不可变性是必要的，因为为了要计算 hashCode()，就要防止键值改变，如果键值在放入时和获取时返回不同的 hashcode 的话，那么就不能从 HashMap 中找到你想要的对象。</p>\n<h4 id=\"HashMap扩容方法-resize\"><a href=\"#HashMap扩容方法-resize\" class=\"headerlink\" title=\"HashMap扩容方法 resize()\"></a>HashMap扩容方法 resize()</h4><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">final</span> Node&lt;K,V&gt;[] resize() &#123;</span><br><span class=\"line\">       Node&lt;K,V&gt;[] oldTab = table;</span><br><span class=\"line\">       <span class=\"comment\">// 旧数组的大小</span></span><br><span class=\"line\">       <span class=\"keyword\">int</span> oldCap = (oldTab == <span class=\"keyword\">null</span>) ? <span class=\"number\">0</span> : oldTab.length;</span><br><span class=\"line\">       <span class=\"comment\">// 旧数组的扩容阈值</span></span><br><span class=\"line\">       <span class=\"keyword\">int</span> oldThr = threshold;</span><br><span class=\"line\">       <span class=\"keyword\">int</span> newCap, newThr = <span class=\"number\">0</span>;</span><br><span class=\"line\">       <span class=\"keyword\">if</span> (oldCap &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">           <span class=\"comment\">// 如果旧数组的大小大于0，并且其大小已经等于最大的数组容量</span></span><br><span class=\"line\">           <span class=\"keyword\">if</span> (oldCap &gt;= MAXIMUM_CAPACITY) &#123;</span><br><span class=\"line\">           \t   <span class=\"comment\">// 则扩容阈值设为Integer的最大值,并直接返回旧数组不再扩容</span></span><br><span class=\"line\">               threshold = Integer.MAX_VALUE;</span><br><span class=\"line\">               <span class=\"keyword\">return</span> oldTab;</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\">           <span class=\"comment\">// 如果旧数组二倍的容量小于最大容量 并且旧表数组容量大于默认值16 </span></span><br><span class=\"line\">           <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> ((newCap = oldCap &lt;&lt; <span class=\"number\">1</span>) &lt; MAXIMUM_CAPACITY &amp;&amp;</span><br><span class=\"line\">                    oldCap &gt;= DEFAULT_INITIAL_CAPACITY)</span><br><span class=\"line\">               <span class=\"comment\">// 则新数组的扩容阈值为旧数组的二倍</span></span><br><span class=\"line\">               newThr = oldThr &lt;&lt; <span class=\"number\">1</span>; <span class=\"comment\">// double threshold</span></span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (oldThr &gt; <span class=\"number\">0</span>) <span class=\"comment\">// initial capacity was placed in threshold</span></span><br><span class=\"line\">           newCap = oldThr;</span><br><span class=\"line\">       <span class=\"keyword\">else</span> &#123;               <span class=\"comment\">// zero initial threshold signifies using defaults</span></span><br><span class=\"line\">           <span class=\"comment\">//阀值和容量使用默认值</span></span><br><span class=\"line\">           newCap = DEFAULT_INITIAL_CAPACITY;</span><br><span class=\"line\">           newThr = (<span class=\"keyword\">int</span>)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       <span class=\"keyword\">if</span> (newThr == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">           <span class=\"comment\">// 计算新的阈值</span></span><br><span class=\"line\">           <span class=\"keyword\">float</span> ft = (<span class=\"keyword\">float</span>)newCap * loadFactor;</span><br><span class=\"line\">           <span class=\"comment\">// 阀值没有超过最大阀值，设置新的阀值</span></span><br><span class=\"line\">           newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (<span class=\"keyword\">float</span>)MAXIMUM_CAPACITY ?</span><br><span class=\"line\">                     (<span class=\"keyword\">int</span>)ft : Integer.MAX_VALUE);</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       threshold = newThr;</span><br><span class=\"line\">       <span class=\"meta\">@SuppressWarnings</span>(&#123;<span class=\"string\">\"rawtypes\"</span>,<span class=\"string\">\"unchecked\"</span>&#125;)</span><br><span class=\"line\">           <span class=\"comment\">// 创建新的Hash表</span></span><br><span class=\"line\">           Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])<span class=\"keyword\">new</span> Node[newCap];</span><br><span class=\"line\">       table = newTab;</span><br><span class=\"line\">       <span class=\"comment\">// 遍历旧的Hash表</span></span><br><span class=\"line\">       <span class=\"keyword\">if</span> (oldTab != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">           <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> j = <span class=\"number\">0</span>; j &lt; oldCap; ++j) &#123;</span><br><span class=\"line\">               Node&lt;K,V&gt; e;</span><br><span class=\"line\">               <span class=\"keyword\">if</span> ((e = oldTab[j]) != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                   <span class=\"comment\">// 释放空间</span></span><br><span class=\"line\">                   oldTab[j] = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">                   <span class=\"comment\">//当前节点不是以链表的形式存在</span></span><br><span class=\"line\">                   <span class=\"keyword\">if</span> (e.next == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">                       newTab[e.hash &amp; (newCap - <span class=\"number\">1</span>)] = e;</span><br><span class=\"line\">                   <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (e <span class=\"keyword\">instanceof</span> TreeNode)</span><br><span class=\"line\">                       <span class=\"comment\">// 则为红黑树</span></span><br><span class=\"line\">                       ((TreeNode&lt;K,V&gt;)e).split(<span class=\"keyword\">this</span>, newTab, j, oldCap);</span><br><span class=\"line\">                   <span class=\"keyword\">else</span> &#123; <span class=\"comment\">// preserve order</span></span><br><span class=\"line\">                       <span class=\"comment\">//以链表形式存在的节点；</span></span><br><span class=\"line\">                       Node&lt;K,V&gt; loHead = <span class=\"keyword\">null</span>, loTail = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">                       Node&lt;K,V&gt; hiHead = <span class=\"keyword\">null</span>, hiTail = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">                       Node&lt;K,V&gt; next;</span><br><span class=\"line\">                       <span class=\"keyword\">do</span> &#123;</span><br><span class=\"line\">                           next = e.next;</span><br><span class=\"line\">                           <span class=\"keyword\">if</span> ((e.hash &amp; oldCap) == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                               <span class=\"keyword\">if</span> (loTail == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">                                   loHead = e;</span><br><span class=\"line\">                               <span class=\"keyword\">else</span></span><br><span class=\"line\">                                   loTail.next = e;</span><br><span class=\"line\">                               loTail = e;</span><br><span class=\"line\">                           &#125;</span><br><span class=\"line\">                           <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                               <span class=\"keyword\">if</span> (hiTail == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">                                   hiHead = e;</span><br><span class=\"line\">                               <span class=\"keyword\">else</span></span><br><span class=\"line\">                                   hiTail.next = e;</span><br><span class=\"line\">                               hiTail = e;</span><br><span class=\"line\">                           &#125;</span><br><span class=\"line\">                       &#125; <span class=\"keyword\">while</span> ((e = next) != <span class=\"keyword\">null</span>);</span><br><span class=\"line\">                       <span class=\"keyword\">if</span> (loTail != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                           loTail.next = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">                           newTab[j] = loHead;</span><br><span class=\"line\">                       &#125;</span><br><span class=\"line\">                       <span class=\"keyword\">if</span> (hiTail != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">                           hiTail.next = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">                           newTab[j + oldCap] = hiHead;</span><br><span class=\"line\">                       &#125;</span><br><span class=\"line\">                   &#125;</span><br><span class=\"line\">               &#125;</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       <span class=\"keyword\">return</span> newTab;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<p>resize()方法中比较重要的是链表和红黑树的rehash()操作，先来说下rehash()的实现原理：</p>\n<p>在扩容的时候，一般是把长度扩为原来2倍，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。这段代码就是关于位置转换的。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">do</span> &#123;</span><br><span class=\"line\">    next = e.next;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((e.hash &amp; oldCap) == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (loTail == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">            loHead = e;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            loTail.next = e;</span><br><span class=\"line\">        loTail = e;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (hiTail == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">            hiHead = e;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            hiTail.next = e;</span><br><span class=\"line\">        hiTail = e;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125; <span class=\"keyword\">while</span> ((e = next) != <span class=\"keyword\">null</span>);</span><br><span class=\"line\"><span class=\"keyword\">if</span> (loTail != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">    loTail.next = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    newTab[j] = loHead;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">if</span> (hiTail != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">    hiTail.next = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    newTab[j + oldCap] = hiHead;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>假如我们有四个数为5，21，37，53。并且oldTab的初始容量为16。即4个数的二进制如下：</p>\n<ul>\n<li>5 ：00000101</li>\n<li>21：00010101</li>\n<li>37：00100101</li>\n<li>53：00110101    </li>\n</ul>\n<p>在oldTab中，四个数会与（16-1）做与运算，也就是与1111做与运算，运算之后结果如下：</p>\n<ul>\n<li>5 ：00000101</li>\n<li>21：00010101</li>\n<li>37：00100101</li>\n<li>53：00110101</li>\n</ul>\n<p>四个数与（16-1）相与后都是0101，即原始链为：5—&gt;21—&gt;37—&gt;53—-&gt;null。<br>然后进入do-while循环，对链表节点进行遍历，通过运算来判断是在原来位置还是去扩容后的新链表：<br><strong>lo就是扩容后仍然在原地的元素链表</strong><br><strong>hi就是扩容后下标为【 原位置+原容量 】的元素链表，从而不需要重新计算hash。</strong><br>因为扩容后计算存储位置就是hash&amp;（32 - 1）【取后5位】，但是并不需要再计算一次位置，</p>\n<p>此处只需要判断左边新增的那一位（右数第5位）是否为1即可判断此节点是留在原地lo还是移动去高位hi：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">(e.hash &amp; oldCap) == <span class=\"number\">0</span></span><br></pre></td></tr></table></figure>\n<p>在这里，我们与16进行也就是10000，做与运算。</p>\n<ul>\n<li>5 ：00000101——————》0留在原地  lo链表</li>\n<li>21：00010101——————》1移向高位  hi链表</li>\n<li>37：00100101——————》0留在原地  lo链表</li>\n<li>53：00110101——————》1移向高位  hi链表    </li>\n</ul>\n<p>退出循环后只需要判断lo，hi是否为空，然后把各自链表头结点直接放到对应位置上即可完成整个链表的移动。</p>\n<p>原理是：利用了尾指针Tail，完成了尾部插入，不会造成逆序，所以也不会产生并发死锁的问题。</p>\n<p>这种方法对比1.7中算法的优点是：</p>\n<p>1、不管怎么样都不需要重新再计算hash；</p>\n<p>2、放过去的链表内元素的相对顺序不会改变；</p>\n<p>3、不会在并发扩容中发生死锁。</p>\n<h4 id=\"HashMap-hash函数实现\"><a href=\"#HashMap-hash函数实现\" class=\"headerlink\" title=\"HashMap hash函数实现\"></a>HashMap hash函数实现</h4><p>我们可以看到，在 HashMap 中要找到某个元素，需要根据 key 的 hash 值来求得对应数组中的位置。如何计算这个位置就是 hash 算法。</p>\n<p>前面说过，HashMap 的数据结构是数组和链表的结合，所以我们当然希望这个 HashMap 里面的元素位置尽量的分布均匀些，尽量使得每个位置上的元素数量只有一个。那么当我们用 hash 算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，而不用再去遍历链表。 所以，我们首先想到的就是把 hashcode 对数组长度取模运算。这样一来，元素的分布相对来说是比较均匀的。</p>\n<p>但是“模”运算的消耗还是比较大的，能不能找一种更快速、消耗更小的方式？我们来看看 JDK1.8 源码是怎么做的</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> <span class=\"title\">hash</span><span class=\"params\">(Object key)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (key == <span class=\"keyword\">null</span>)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> h;</span><br><span class=\"line\">    h = key.hashCode()；返回散列值也就是hashcode</span><br><span class=\"line\">    <span class=\"comment\">// ^ ：按位异或</span></span><br><span class=\"line\">    <span class=\"comment\">// &gt;&gt;&gt;:无符号右移，忽略符号位，空位都以0补齐</span></span><br><span class=\"line\">    <span class=\"comment\">//其中n是数组的长度，即Map的数组部分初始化长度</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> (n-<span class=\"number\">1</span>)&amp;(h ^ (h &gt;&gt;&gt; <span class=\"number\">16</span>));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tNc79ly1fzfbg2rw5sj311m0iqgul.jpg\" alt=\"\"></p>\n<p>简单来说就是：</p>\n<p>高16 bit 不变，低16 bit 和高16 bit 做了一个异或（得到的 hashcode 转化为32位二进制，前16位和后16位低16 bit 和高16 bit 做了一个异或）</p>\n<p>(n·1) &amp; hash = -&gt; 得到下标</p>\n<p>参考：<a href=\"https://www.cnblogs.com/JohnsonZilch/p/6554547.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/JohnsonZilch/p/6554547.html</a><br>      <a href=\"https://www.cnblogs.com/Xieyang-blog/p/8886921.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/Xieyang-blog/p/8886921.html</a></p>\n","categories":["源码分析"],"tags":[]},{"title":"红黑树详解","url":"http://ilovenorth.cn/2019/01/18/红黑树详解/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h2 id=\"红黑树\"><a href=\"#红黑树\" class=\"headerlink\" title=\"红黑树\"></a>红黑树</h2><p>JDK1.8开始，HashMap引进红黑树作为又一存储结构。<br>正好HashMap有红黑树的源码，所以我们借此分析一下红黑树结构。</p>\n<ul>\n<li>TreeNode&lt;K,V&gt; 继承 LinkedHashMap.Entry&lt;K,V&gt;，用来实现红黑树相关的存储结构</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">TreeNode</span>&lt;<span class=\"title\">K</span>,<span class=\"title\">V</span>&gt; <span class=\"keyword\">extends</span> <span class=\"title\">LinkedHashMap</span>.<span class=\"title\">Entry</span>&lt;<span class=\"title\">K</span>,<span class=\"title\">V</span>&gt; </span>&#123;</span><br><span class=\"line\">\tTreeNode&lt;K,V&gt; parent;  <span class=\"comment\">// 存储当前节点的父节点</span></span><br><span class=\"line\">    TreeNode&lt;K,V&gt; left;   <span class=\"comment\">// 存储当前节点的左孩子</span></span><br><span class=\"line\">    TreeNode&lt;K,V&gt; right;  <span class=\"comment\">// 存储当前节点的右孩子</span></span><br><span class=\"line\">    TreeNode&lt;K,V&gt; prev;   <span class=\"comment\">// 存储当前节点的前一个节点</span></span><br><span class=\"line\">    <span class=\"keyword\">boolean</span> red;          <span class=\"comment\">// 存储当前节点的颜色（红、黑）</span></span><br><span class=\"line\">    TreeNode(<span class=\"keyword\">int</span> hash, K key, V val, Node&lt;K,V&gt; next) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(hash, key, val, next);</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>红黑树相关操作</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* ------------------------------------------------------------ */</span></span><br><span class=\"line\">       <span class=\"comment\">// Red-black tree methods, all adapted from CLR</span></span><br><span class=\"line\">       <span class=\"comment\">// 左旋</span></span><br><span class=\"line\">       <span class=\"keyword\">static</span> &lt;K,V&gt; <span class=\"function\">TreeNode&lt;K,V&gt; <span class=\"title\">rotateLeft</span><span class=\"params\">(TreeNode&lt;K,V&gt; root,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                                             TreeNode&lt;K,V&gt; p)</span> </span>&#123;       </span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">\t <span class=\"comment\">// 右旋</span></span><br><span class=\"line\">       <span class=\"keyword\">static</span> &lt;K,V&gt; <span class=\"function\">TreeNode&lt;K,V&gt; <span class=\"title\">rotateRight</span><span class=\"params\">(TreeNode&lt;K,V&gt; root,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                                              TreeNode&lt;K,V&gt; p)</span> </span>&#123;         </span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">\t <span class=\"comment\">// 插入平衡算法</span></span><br><span class=\"line\">       <span class=\"keyword\">static</span> &lt;K,V&gt; <span class=\"function\">TreeNode&lt;K,V&gt; <span class=\"title\">balanceInsertion</span><span class=\"params\">(TreeNode&lt;K,V&gt; root,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                                                   TreeNode&lt;K,V&gt; x)</span> </span>&#123;        </span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">\t<span class=\"comment\">// 删除平衡算法</span></span><br><span class=\"line\">       <span class=\"keyword\">static</span> &lt;K,V&gt; <span class=\"function\">TreeNode&lt;K,V&gt; <span class=\"title\">balanceDeletion</span><span class=\"params\">(TreeNode&lt;K,V&gt; root,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                                                  TreeNode&lt;K,V&gt; x)</span> </span>&#123;           </span><br><span class=\"line\">       &#125;       </span><br><span class=\"line\">\t<span class=\"comment\">// 递归不变检查</span></span><br><span class=\"line\">       <span class=\"keyword\">static</span> &lt;K,V&gt; <span class=\"function\"><span class=\"keyword\">boolean</span> <span class=\"title\">checkInvariants</span><span class=\"params\">(TreeNode&lt;K,V&gt; t)</span> </span>&#123;          </span><br><span class=\"line\">       &#125;</span><br></pre></td></tr></table></figure>\n<p><strong>红黑树特点：</strong><br>红黑树是一种近似平衡的<font color=\"orange\">二叉查找树</font>，它能够确保任何一个节点的左右子树的高度差不会超过二者中较低那个的一倍。<br>具体来说，红黑树是满足如下条件的二叉查找树（binary search tree）：</p>\n<ul>\n<li>每个节点要么是红色，要么是黑色。</li>\n<li>根是黑色的。</li>\n<li>每个叶子节点都是黑色的空节点（NIL节点）</li>\n<li>如果一个节点是红色的，那么它的节点必须是黑色的。</li>\n<li>从一个节点到一个null引用的每一条路径必须包含相同数目的黑色节点。</li>\n</ul>\n<p>在树的结构发生改变时（插入或者删除操作），往往会破坏上述条件3或条件4，需要通过调整使得查找树重新满足红黑树的条件。</p>\n<p><strong>知识准备：</strong></p>\n<h3 id=\"什么是二叉查找树？\"><a href=\"#什么是二叉查找树？\" class=\"headerlink\" title=\"什么是二叉查找树？\"></a>什么是二叉查找树？</h3><p>二叉查找树（BST）具备什么特性呢？</p>\n<ol>\n<li><p>左子树上所有结点的值均小于或等于它的根结点的值。</p>\n</li>\n<li><p>右子树上所有结点的值均大于或等于它的根结点的值。</p>\n</li>\n<li><p>左、右子树也分别为二叉排序树。</p>\n</li>\n</ol>\n<h3 id=\"二叉查找树的好处\"><a href=\"#二叉查找树的好处\" class=\"headerlink\" title=\"二叉查找树的好处\"></a>二叉查找树的好处</h3><p>我们来查找一下10这个节点。</p>\n<ol>\n<li><p>查看根节点 9<br><img src=\"https://ws4.sinaimg.cn/large/006tNc79ly1fzakddsg0ij311u0mwdj1.jpg\" alt=\"\"></p>\n</li>\n<li><p>由于10 &gt; 9，因此查看右孩子13<br><img src=\"https://ws4.sinaimg.cn/large/006tNc79ly1fzakf9so37j31100nqn0h.jpg\" alt=\"\"></p>\n</li>\n<li><p>由于10 &lt; 13，因此查看左孩子11<br><img src=\"https://ws4.sinaimg.cn/large/006tNc79ly1fzakgb781dj31020nen0g.jpg\" alt=\"\"></p>\n</li>\n<li><p>由于10 &lt; 11，因此查看左孩子10，发现10正是要查找的节点<br><img src=\"https://ws1.sinaimg.cn/large/006tNc79ly1fzakh6pobgj310c0mitc0.jpg\" alt=\"\"></p>\n</li>\n</ol>\n<ul>\n<li>这种方式正是二分查找的思想，查找所需的最大次数等同于二叉查找树的高度。</li>\n<li>在插入节点的时候也是利用类似的方法，通过一层一层比较大小，找到新节点适合插入的位置。</li>\n</ul>\n<h3 id=\"二叉查找树的缺陷\"><a href=\"#二叉查找树的缺陷\" class=\"headerlink\" title=\"二叉查找树的缺陷\"></a>二叉查找树的缺陷</h3><p>假设初始的二叉查找树只有三个节点，根节点值为9，左孩子值为5，右孩子值为13。<br><img src=\"https://ws2.sinaimg.cn/large/006tNc79ly1fzakl3awgbj30yc0bet9s.jpg\" alt=\"\"></p>\n<p>接下来我们依次插入如下五个节点：4,3,2,1。<br><img src=\"https://ws1.sinaimg.cn/large/006tNc79ly1fzaknz5iusj312u0oaq5i.jpg\" alt=\"\"></p>\n<p>变成线性了，查找的性能大打折扣。<br>如何解决二叉查找树多次插入新节点而导致的不平衡呢？红黑树就诞生了。</p>\n<h3 id=\"红黑树详解\"><a href=\"#红黑树详解\" class=\"headerlink\" title=\"红黑树详解\"></a>红黑树详解</h3><p><strong>红黑树规则：</strong><br>刚才我们讲述了红黑树的规则，我们在这里重温一遍：</p>\n<ul>\n<li>每个节点要么是红色，要么是黑色。</li>\n<li>根是黑色的。</li>\n<li>每个叶子节点都是黑色的空节点（NIL节点）</li>\n<li>如果一个节点是红色的，那么它的节点必须是黑色的。(从每个叶子到根的所有路径上不能有两个连续的红色节点)</li>\n<li>从一个节点到一个null引用的每一条路径必须包含相同数目的黑色节点。</li>\n</ul>\n<p>下图中这棵树，就是一颗典型的红黑树：<br><img src=\"https://ws4.sinaimg.cn/large/006tNc79ly1fzal9e0pewj31720tuafe.jpg\" alt=\"\"></p>\n<p><strong>当插入或者删除节点的时候，红黑树的规则有可能被打破。这时候就需要做出一些调整，来继续维持我们的规则。什么时候会破坏规则，什么时候不会破坏呢？举一个简单的例子。</strong></p>\n<ol>\n<li><p>向原红黑树插入值为14的新节点<br><img src=\"https://ws4.sinaimg.cn/large/006tNc79ly1fzalc62ivdj316q0twwkf.jpg\" alt=\"\"><br>我们会发现，新增14节点后，该红黑树依然满足红黑树的规则，并没有破坏。</p>\n</li>\n<li><p>向原红黑树插入值为21的新节点<br><img src=\"https://ws4.sinaimg.cn/large/006tNc79ly1fzalfg7vufj310a0u044v.jpg\" alt=\"\"><br>由于父节点22是红色节点，因此这种情况打破了红黑树的规则4（每个红色节点的两个子节点都是黑色），必须进行调整，使之重新符合红黑树的规则。    </p>\n</li>\n</ol>\n<p><strong>如何调整？调整有两种方法：「变色」和「旋转」</strong></p>\n<p><strong>旋转又分为：「左旋」和「右旋」</strong></p>\n<h3 id=\"变色\"><a href=\"#变色\" class=\"headerlink\" title=\"变色\"></a>变色</h3><p>为了重新符合红黑树的规则，尝试把红色节点变为黑色，或者把黑色节点变为红色。</p>\n<p>下图所表示的是红黑树的一部分，需要注意节点25并非根节点。因为节点21和节点22连续出现了红色，不符合规则4，所以把节点22从红色变成黑色：</p>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tNc79ly1fzap95yaf2j316g0lctaz.jpg\" alt=\"\"></p>\n<p>但这样并不算完，因为凭空多出的黑色节点打破了规则5，所以发生连锁反应，需要继续把节点25从黑色变成红色：</p>\n<p><img src=\"https://ws3.sinaimg.cn/large/006tNc79ly1fzapaadtdcj316g0m60v7.jpg\" alt=\"\"></p>\n<p>此时仍然没有结束，因为节点25和节点27又形成了两个连续的红色节点，需要继续把节点27从红色变成黑色：</p>\n<p><img src=\"https://ws2.sinaimg.cn/large/006tNc79ly1fzapbagiztj316m0lowgu.jpg\" alt=\"\"></p>\n<p>变色我们先演示到这，接下来我们看一下旋转。</p>\n<h3 id=\"左旋\"><a href=\"#左旋\" class=\"headerlink\" title=\"左旋\"></a>左旋</h3><p>左旋的过程是将x的右子树绕x<font color=\"red\">逆时针旋转</font>，使得x的右子树成为x的父亲，同时修改相关节点的引用。旋转之后，二叉查找树的属性仍然满足。如下图：</p>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tNc79ly1fzaps8c4n1j314e0ok41r.jpg\" alt=\"\"></p>\n<p>JDK1.8，TreeMap红黑树左旋代码。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">void</span> <span class=\"title\">rotateLeft</span><span class=\"params\">(Entry&lt;K,V&gt; p)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (p != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">        Entry&lt;K,V&gt; r = p.right;</span><br><span class=\"line\">        p.right = r.left;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (r.left != <span class=\"keyword\">null</span>)</span><br><span class=\"line\">            r.left.parent = p;</span><br><span class=\"line\">        r.parent = p.parent;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (p.parent == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">            root = r;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (p.parent.left == p)</span><br><span class=\"line\">            p.parent.left = r;</span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            p.parent.right = r;</span><br><span class=\"line\">        r.left = p;</span><br><span class=\"line\">        p.parent = r;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"右旋\"><a href=\"#右旋\" class=\"headerlink\" title=\"右旋\"></a>右旋</h3><p>右旋的过程是将x的左子树绕x<font color=\"red\">顺时针旋转</font>，使得x的左子树成为x的父亲，同时修改相关节点的引用。旋转之后，二叉查找树的属性仍然满足。</p>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tNc79ly1fzapxvuvioj318y0q6427.jpg\" alt=\"\"></p>\n<p>JDK1.8，TreeMap红黑树右旋代码。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">void</span> <span class=\"title\">rotateRight</span><span class=\"params\">(Entry&lt;K,V&gt; p)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (p != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">        Entry&lt;K,V&gt; l = p.left;</span><br><span class=\"line\">        p.left = l.right;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (l.right != <span class=\"keyword\">null</span>) l.right.parent = p;</span><br><span class=\"line\">        l.parent = p.parent;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (p.parent == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">            root = l;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (p.parent.right == p)</span><br><span class=\"line\">            p.parent.right = l;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> p.parent.left = l;</span><br><span class=\"line\">        l.right = p;</span><br><span class=\"line\">        p.parent = l;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"举例\"><a href=\"#举例\" class=\"headerlink\" title=\"举例\"></a>举例</h3><p>我们以刚才插入节点21的情况为例，根据刚才的变色，目前红黑树结构如下：</p>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tNc79ly1fzaqangrkaj314f0u07b1.jpg\" alt=\"\"></p>\n<p>此时节点17和节点25是连续的两个红色节点，那么把节点17变成黑色节点？恐怕是不行的，因为这样一是打破了规则4，而且根据规则2（根节点是黑色），也不可能把节点13变成红色节点。</p>\n<p>变色已无法解决问题，我们把节点13看做X，把节点17看做Y，像刚才的示意图那样进行左旋转：</p>\n<p><img src=\"https://ws2.sinaimg.cn/large/006tNc79ly1fzaqeyxod8j312b0u044z.jpg\" alt=\"\"></p>\n<p><img src=\"https://ws2.sinaimg.cn/large/006tNc79ly1fzaqhaol4yj313c0u0wku.jpg\" alt=\"\"></p>\n<p>由于根节点必须是黑色节点，所以需要变色，变色结果如下：</p>\n<p><img src=\"https://ws4.sinaimg.cn/large/006tNc79ly1fzaqiyu4qjj314a0u044j.jpg\" alt=\"\"></p>\n<p>这样就结束了吗？并没有。因为其中两条路径(17 -&gt; 8 -&gt; 6 -&gt; NIL)的黑色节点个数是4，其他路径的黑色节点个数是3，不符合规则5。</p>\n<p>这时候我们需要把节点13看做X，节点8看做Y，像刚才的示意图那样进行右旋转：</p>\n<p><img src=\"https://ws2.sinaimg.cn/large/006tNc79ly1fzaqkbez1lj313a0u0dm3.jpg\" alt=\"\"></p>\n<p><img src=\"https://ws4.sinaimg.cn/large/006tNc79ly1fzaqmckbbnj314q0u0wkp.jpg\" alt=\"\"></p>\n<p>最后根据规则来进行变色：</p>\n<p><img src=\"https://ws4.sinaimg.cn/large/006tNc79ly1fzaqo42vwmj313d0u00yy.jpg\" alt=\"\"></p>\n<p>如此一来，我们的红黑树变得重新符合规则。这一个例子的调整过程比较复杂，经历了如下步骤：</p>\n<p>变色 -&gt; 左旋转 -&gt; 变色 -&gt; 右旋转 -&gt; 变色。</p>\n<h3 id=\"PS\"><a href=\"#PS\" class=\"headerlink\" title=\"PS\"></a>PS</h3><p>最后推荐大家一个数据结构网站：<a href=\"https://www.cs.usfca.edu/~galles/visualization/RedBlack.html\" target=\"_blank\" rel=\"noopener\">看了你就知道哦 ;)</a></p>\n","categories":["源码分析"],"tags":[]},{"title":"初始分布式","url":"http://ilovenorth.cn/2018/11/16/初始分布式/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"初识分布式\"><a href=\"#初识分布式\" class=\"headerlink\" title=\"初识分布式\"></a>初识分布式</h1><h2 id=\"单体应用\"><a href=\"#单体应用\" class=\"headerlink\" title=\"单体应用\"></a>单体应用</h2><p><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fx8pwb041fj30k00mowgd.jpg\" alt=\"\"></p>\n<p>最初，我们的应用都是这种单体应用，即浏览器发送请求到我们的应用服务器1，然后应用再与数据库交互。<br><br>这种单体应用存在着问题：</p>\n<ol>\n<li>JVM内部调用</li>\n<li>单点故障</li>\n</ol>\n<p>流量上去就满足不了我们的需求.</p>\n<h2 id=\"集群\"><a href=\"#集群\" class=\"headerlink\" title=\"集群\"></a>集群</h2><p><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fx8q0xay4oj30yq0tqjuw.jpg\" alt=\"\"></p>\n<p>最初的分布式就是增加服务器。1和2两个服务器不是同一个进程。<br>假如服务器1能承受100个并发，如果达到101个并发就会出现问题，所以我们可以引用nginx。达到负载均衡。</p>\n<p>这种只增加服务器的方式同样也存在着问题：</p>\n<h3 id=\"1-分布式session问题\"><a href=\"#1-分布式session问题\" class=\"headerlink\" title=\"1. 分布式session问题\"></a>1. 分布式session问题</h3><p>当用户A第一次登陆后，请求可能会发送到”1”这台服务器，此时”1”服务器存着用户的session数据，这时，如果突然有大量用户的请求进入了”1”服务器，达到了”1”服务器处理能力的峰值，当用户A进行下一次请求操作时，请求会发送到”2”服务器，这时就会报错，因为拿不到用户的session数据。</p>\n<p><font color=\"orange\">方案一：Session Sticky</font><br><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fx8qatgzc0j30r00oediy.jpg\" alt=\"\"></p>\n<p>由图可知，通过ip_hash算法，我们可以让用户aaa登录后，永久的将session存到左面的服务器中，用户bbb登陆后，永久的将session存到右侧的服务器中。解决了，上述的问题，用户登录后操作都会是在同一个服务器上运行。<br><br>Session Sticky 问题:<br></p>\n<ul>\n<li>单点故障问题：如果右面的服务器停电了，那么用户bbb将永远都不能登录了。</li>\n<li>ip_hash问题：采用ip_hash算法，意味着同一个路由器下面的所有ip都是一样的，它获取的不是用户的ip。</li>\n</ul>\n<p><font color=\"orange\">方案二：Session Relication</font><br><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fx8qmp0hjqj30mq0qigou.jpg\" alt=\"\"></p>\n<p>利用Tomcat特性，用户aaa登录之后，将abc通知到其他服务器，叫做session复制。</p>\n<p>Session Relication 问题<br></p>\n<ul>\n<li>服务器数量问题：如果我有100台服务器，就需要复制到100个服务器上。</li>\n<li>流量占用问题：通过TCP协议复制，占用流量。</li>\n<li>存储问题：每个服务器需要存储所有用户的session数据。</li>\n</ul>\n<p><font color=\"orange\">方案三：Cookie Base</font><br><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fx8r1w0km3j30l00q0tbq.jpg\" alt=\"\"></p>\n<p>cookie存session加密，每次都去解密来判断。也就是常说的token方式。服务端拿到session做check验证。</p>\n<p>Cookie Base 问题<br></p>\n<ul>\n<li>安全：每次都会把session暴露给客户端，通过MD5碰撞可能会被破解。</li>\n</ul>\n<p><font color=\"orange\">方案四：Session Center</font><br><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fx8r68d5hej30l20wygpn.jpg\" alt=\"\"></p>\n<p>用户登录进去之后，客户端和服务端都不保存数据，而是把session数据放到Redis中，这种方式也是普遍互联网公司使用的方案。</p>\n<h3 id=\"2-数据库\"><a href=\"#2-数据库\" class=\"headerlink\" title=\"2.数据库\"></a>2.数据库</h3><p><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fx8q0xay4oj30yq0tqjuw.jpg\" alt=\"\"></p>\n<p>回到我们分布式集群的这张图，通过增加服务器，我们完成了对于单点故障，流量增加的问题，也是老板有钱 -。-，但是这时，数据库就会出现问题了，服务器太多，mysql就承受不住了，因此，也需要把数据库改为分布式的。</p>\n<p><strong>分布式环境下，数据库优化：</strong></p>\n<ol>\n<li>读写分离<br><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fx8ro3f9tfj312k0t6n0y.jpg\" alt=\"\"><br>我们通过增加一个数据库，来完成数据库的读写分离，所有添加删除修改操作都走主库，读取操作走从库。符合互联网公司读多写少的业务场景，并且要完成主从同步。<br><br>读写分离的目的就是为降低主库的查询压力。参考订单业务。<ul>\n<li>Proxy: mycat、altas、mysql-proxy</li>\n<li>Jdbc: tddl、sharding-jdbc</li>\n</ul>\n</li>\n<li>换数据库<br>不推荐 -。- 没钱 -。-</li>\n<li>分库分表<br>“不要把鸡蛋放在一个篮子里”。对于技术来说就是热点数据的问题，尽管我们读写分离了，但是我们insert语句依然都会走主库，这时我们就会用分库分表。<br><br>分库分表，垂直分、水平分。<ul>\n<li>Proxy: mycat、altas</li>\n<li>Jdbc: tddl、sharding-jdbc</li>\n</ul>\n</li>\n<li>云数据库</li>\n</ol>\n<h3 id=\"3-服务化（微服务）\"><a href=\"#3-服务化（微服务）\" class=\"headerlink\" title=\"3.服务化（微服务）\"></a>3.服务化（微服务）</h3><p>我们一般是周二周四上线，假如周四，商品部门上新功能，会员部门改bug。<br><br>上线的步骤一般是：开发、测试、RC、生产。如果这两个部门的测试人员在测试之后，认为这两个部门的功能没有问题，但是在生产的时候，商品部门的新功能上线失败，会员部门的bug上线成功。<br><br>对于商品部门来说是上线失败了，需要回滚；对于会员部门来说，上线成功了，不需要回滚。<br><br>我们发现现在这个架构师有问题的，我们需要对现在的核心功能或者公共功能抽取出来。<br><br>垂直拆分：按业务拆分，和会员部门有关的功能都放到会员业务里，商品也同理，叫做模块化的方式。<br><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fx8uob7uxhj30y50u0n4p.jpg\" alt=\"\"></p>\n<p>这种架构模式同样也会带来问题：不同模块之间的通讯问题。<br><br>这是我们就要引入：RPC（远程调用）、dubbo（分布式）<br><br>如果我们拆的东西越细，就代表我们拆的应用越多，如果更多的应用就意味着他们之间的调用更复杂了，排查bug就会很复杂，依赖配置也是问题（多个应用都要连接某一个数据库），一旦某个库改了一些配置，所有的应用都要改，为了解决这个问题，就需要分布式配置中心(disconf、diamond)<br><br>当我们图片多了，普通的NFS挂载也不是长久之计，分布式文件存储也就诞生了(TFS)。<br><br>ELK搜索引擎、风控系统，都是分布式系统不可或缺的东西。<br></p>\n<p>当我们RPC过多时，就需要分布式消息中间件。<br><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fx8zvch23xj316s0sctil.jpg\" alt=\"\"><br>比如上线双十一统计系统，10号上线12号下线，如果使用RPC，肯定就需要改代码了。如果使用分布式消息中间件就可以解决这个问题，分布式消息中间件的主要作用是异步、解耦和消峰（Kafka、rocketmq、activemq、rabbitmq）。</p>\n<h2 id=\"zookeeper\"><a href=\"#zookeeper\" class=\"headerlink\" title=\"zookeeper\"></a>zookeeper</h2><p>zookeeper到底是做什么的？<br><br>我们知道分布式配置中心的作用就是为了统一管理配置，一旦有一天分布式配置中心挂了，那么所有连接该分布式配置中心的微服务就都挂了，为了保证它的高可用，保证配置中心更新之后，其下面的微服务也同时更新，这时就要用到zookeeper了。<br><br><strong>官方：</strong><br>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。</p>\n<h3 id=\"集群角色介绍：\"><a href=\"#集群角色介绍：\" class=\"headerlink\" title=\"集群角色介绍：\"></a>集群角色介绍：</h3><p><strong>Leader：</strong><br><br>    Leader作为整个ZooKeeper集群的主节点，负责响应所有对ZooKeeper状态变更的请求。它会将每个状态更新请求进行排序和编号，以便保证整个集群内部消息处理的FIFO，写操作都走leader，zk里面leader只有一个.<br><br><strong>Follower ：</strong><br><br>    Follower的逻辑就比较简单了。除了响应本服务器上的读请求外，follower还要处理leader的提议，并在leader提交该提议时在本地也进行提交。    另外需要注意的是，leader和follower构成ZooKeeper集群的法定人数，也就是说，只有他们才参与新leader的选举、响应leader的提议。 帮助leader处理读请求，投票权<br><br><strong>Observer ：</strong><br><br>    如果ZooKeeper集群的读取负载很高，或者客户端多到跨机房，可以设置一些observer服务器，以提高读取的吞吐量。Observer和Follower比较相似，只有一些小区别：首先observer不属于法定人数，即不参加选举也不响应提议；其次是observer不需要将事务持久化到磁盘，一旦observer被重启，需要从leader重新同步整个名字空间。 没有投票权利,可以处理读请求</p>\n","categories":["分布式专题"],"tags":[]},{"title":"JVM垃圾回收详解","url":"http://ilovenorth.cn/2018/10/26/JVM垃圾回收详解/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"JVM-垃圾回收详解\"><a href=\"#JVM-垃圾回收详解\" class=\"headerlink\" title=\"JVM 垃圾回收详解\"></a>JVM 垃圾回收详解</h1><h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><pre><code>1.JVM内存分配与回收\n2.如何判断对象可以被回收\n3.垃圾收集算法\n</code></pre><h3 id=\"1-JVM内存分配与回收\"><a href=\"#1-JVM内存分配与回收\" class=\"headerlink\" title=\"1.JVM内存分配与回收\"></a>1.JVM内存分配与回收</h3><h4 id=\"1-1-对象优先在Eden区分配\"><a href=\"#1-1-对象优先在Eden区分配\" class=\"headerlink\" title=\"1.1 对象优先在Eden区分配\"></a>1.1 对象优先在Eden区分配</h4><p>大多数情况下，对象在新生代中 Eden 区分配。当 Eden 区没有足够空间进行分配时，虚拟机将发起一次Minor GC。我们来进行实际测试一下。<br>在测试之前我们先来看看 <strong>Minor Gc和Full GC 有什么不同呢？</strong><br><strong>新生代GC（Minor GC）</strong>:指发生新生代的的垃圾收集动作，Minor GC非常频繁，回收速度一般也比较快。<br><strong>老年代GC（Major GC/Full GC）</strong>:指发生在老年代的GC，出现了Major GC经常会伴随至少一次的Minor GC（并非绝对），Major GC的速度一般会比Minor GC的慢10倍以上。</p>\n<p><strong>测试：</strong><br><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fwki68ia6bj30wg0cktfi.jpg\" alt=\"\"></p>\n<p><strong>通过以下方式运行： 添加的参数： -XX:+PrintGCDetails</strong><br><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fwkia56fdlj31kw0dxtcv.jpg\" alt=\"\"></p>\n<p><strong>运行结果：</strong><br><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fwkibxr7wej31iw09iqg5.jpg\" alt=\"\"></p>\n<p>我们可以看到 YoungGen：新生代 OldGen：老年代 Metaspace：元空间。<br>从上图我们可以看出eden区内存几乎已经被分配完全（即使程序什么也不做，新生代也会使用至少2000多k内存）。<br>from和to区都是0%，老年代也是0%。我们现在再建立一个allocation2，并为它分配内存，看看会出现什么情况？<br><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fwkinopizrj313s0diaiv.jpg\" alt=\"\"><br><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fwkiofio6dj31go09mwrp.jpg\" alt=\"\"></p>\n<p><strong>简单说一下为什么会出现这种情况：</strong> 因为给allocation2分配内存的时候eden区内存几乎已经被分配完了，我们刚刚讲了当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC.GC期间虚拟机又发现allocation1无法存入Survior空间，所以只好通过 分配担保机制 把新生代的对象提前转移到老年代中去，老年代上的空间足够存放allocation1，所以不会出现Full GC。执行Minor GC后，后面分配的对象如果能够存在eden区的话，还是会在eden区分配内存。</p>\n<h4 id=\"1-2-大对象直接进入老年代\"><a href=\"#1-2-大对象直接进入老年代\" class=\"headerlink\" title=\"1.2 大对象直接进入老年代\"></a>1.2 大对象直接进入老年代</h4><p>大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。<br><strong>为什么要这样呢？</strong><br>为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。</p>\n<h4 id=\"1-3-长期存活的对象将进入老年代\"><a href=\"#1-3-长期存活的对象将进入老年代\" class=\"headerlink\" title=\"1.3 长期存活的对象将进入老年代\"></a>1.3 长期存活的对象将进入老年代</h4><p>既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别那些对象应放在新生代，那些对象应放在老年代中。为了做到这一点，虚拟机给每个对象一个对象年龄（Age）计数器。<br>如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为1.对象在 Survivor 中每熬过一次 MinorGC,年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。</p>\n<h3 id=\"2-如何判断对象可以被回收\"><a href=\"#2-如何判断对象可以被回收\" class=\"headerlink\" title=\"2.如何判断对象可以被回收\"></a>2.如何判断对象可以被回收</h3><p>堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断那些对象已经死亡（即不能再被任何途径使用的对象）。</p>\n<h4 id=\"2-1-引用计数法\"><a href=\"#2-1-引用计数法\" class=\"headerlink\" title=\"2.1 引用计数法\"></a>2.1 引用计数法</h4><p>给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加1；当引用失效，计数器就减1；任何时候计数器为0的对象就是不可能再被使用的。<br><strong>这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。</strong><br>所谓对象之间的相互引用问题，如下面代码所示：除了对象objA 和 objB 相互引用着对方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为0，于是引用计数算法无法通知 GC 回收器回收他们。<br><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fwkjhr7zbjj30za0hodr6.jpg\" alt=\"\"><br>我们根据图来解析一下。<br><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fwkjt5hpdbj30zs0m276g.jpg\" alt=\"\"><br>一开始，objA 和 objB互相指着在堆上各自的地址。<br><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fwkjvob1krj30zy0l20ve.jpg\" alt=\"\"><br>objA.instance = objB;objB.instance = objA;<br>我们让objA 和 objB互相指着对方的成员变量instance，我们都知道成员变量是存放在堆上的。<br><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fwkjx0xhkjj30yu0leac2.jpg\" alt=\"\"><br>objA = null;objB = null;<br>尽管我们都不用这两个对象了，但是在堆上，这两个对象的成员变量依然在互相引用着，导致无法对这两个对象进行回收。</p>\n<h4 id=\"2-2-可达性分析算法\"><a href=\"#2-2-可达性分析算法\" class=\"headerlink\" title=\"2.2 可达性分析算法\"></a>2.2 可达性分析算法</h4><p>这个算法的基本思想就是通过一系列的称为 <strong>“GC Roots”</strong> 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。<br><strong>GC Roots根节点：</strong>类加载器、Thread、虚拟机栈的本地变量表、static成员、常量引用、本地方法栈的变量等等<br><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fwkk3h4j56j309p06r47g.jpg\" alt=\"\"></p>\n<h4 id=\"2-3-finalize-方法最终判定对象是否存活\"><a href=\"#2-3-finalize-方法最终判定对象是否存活\" class=\"headerlink\" title=\"2.3 finalize()方法最终判定对象是否存活\"></a>2.3 finalize()方法最终判定对象是否存活</h4><p>即使在可达性分析算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历再次标记过程。<br><strong>标记的前提是对象在进行可达性分析后发现没有与GC Roots相连接的引用链。</strong><br><strong>1. 第一次标记并进行一次筛选。</strong><br>筛选的条件是此对象是否有必要执行finalize()方法。<br>当对象没有覆盖finalize方法，或者finzlize方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”，对象被回收。<br><strong>2. 第二次标记</strong><br>如果这个对象被判定为有必要执行finalize（）方法，那么这个对象将会被放置在一个名为：F-Queue的队列之中，并在稍后由一条虚拟机自动建立的、低优先级的Finalizer线程去执行。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束。这样做的原因是，如果一个对象finalize（）方法中执行缓慢，或者发生死循环（更极端的情况），将很可能会导致F-Queue队列中的其他对象永久处于等待状态，甚至导致整个内存回收系统崩溃。<br>finalize（）方法是对象脱逃死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模标记，如果对象要在finalize（）中成功拯救自己—-只要重新与引用链上的任何的一个对象建立关联即可，譬如把自己赋值给某个类变量或对象的成员变量，那在第二次标记时它将移除出“即将回收”的集合。如果对象这时候还没逃脱，那基本上它就真的被回收了。</p>\n<h4 id=\"2-4-如何判断一个常量是废弃常量\"><a href=\"#2-4-如何判断一个常量是废弃常量\" class=\"headerlink\" title=\"2.4 如何判断一个常量是废弃常量\"></a>2.4 如何判断一个常量是废弃常量</h4><p>运行时常量池主要回收的是废弃的常量。那么，我们如何判断一个常量是废弃常量呢？<br>假如在常量池中存在字符串 “abc”，如果当前没有任何String对象引用该字符串常量的话，就说明常量 “abc” 就是废弃常量，如果这时发生内存回收的话而且有必要的话，”abc” 就会被系统清理出常量池。</p>\n<h4 id=\"2-5-如何判断一个类是无用的类\"><a href=\"#2-5-如何判断一个类是无用的类\" class=\"headerlink\" title=\"2.5 如何判断一个类是无用的类\"></a>2.5 如何判断一个类是无用的类</h4><p>方法区主要回收的是无用的类，那么如何判断一个类是<strong>无用的类</strong>的呢？<br>判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面3个条件才能算是 “无用的类” ：</p>\n<ul>\n<li>该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。</li>\n<li>加载该类的 ClassLoader 已经被回收。</li>\n<li>该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。    </li>\n</ul>\n<p>虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。</p>\n<h3 id=\"3-垃圾收集算法\"><a href=\"#3-垃圾收集算法\" class=\"headerlink\" title=\"3.垃圾收集算法\"></a>3.垃圾收集算法</h3><hr>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fwkkxkbtkdj30bj08wwsn.jpg\" alt=\"\"></p>\n<h4 id=\"3-1-标记-清楚算法\"><a href=\"#3-1-标记-清楚算法\" class=\"headerlink\" title=\"3.1 标记-清楚算法\"></a>3.1 标记-清楚算法</h4><p>算法分为“标记”和“清除”阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。它是最基础的收集算法，效率也很高，但是会带来两个明显的问题：</p>\n<p>1.效率问题：需要遍历才能标记各个对象是否需要回收，回收时依然要遍历。<br>2.空间问题：（标记清除后会产生大量不连续的碎片）比如下面的图，我要存一个需要6个格子的对象，我们会发现根本没有空间，就会又做一次GC。</p>\n<p><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fwkl39lkb8j30bj09iqi3.jpg\" alt=\"\"></p>\n<h4 id=\"3-2-复制算法\"><a href=\"#3-2-复制算法\" class=\"headerlink\" title=\"3.2 复制算法\"></a>3.2 复制算法</h4><p>为了解决效率问题，“复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。非常适合于From和To区的相互转换。<br><img src=\"https://ws2.sinaimg.cn/large/006tNbRwly1fwkl8c2vf1j30bj09iqi3.jpg\" alt=\"\"></p>\n<h4 id=\"3-3-标记-整理算法\"><a href=\"#3-3-标记-整理算法\" class=\"headerlink\" title=\"3.3 标记-整理算法\"></a>3.3 标记-整理算法</h4><p>根据老年代的特点特出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一段移动，然后直接清理掉端边界以外的内存。<br><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fwklqpr12sj30bj065487.jpg\" alt=\"\"></p>\n<h4 id=\"3-4-分代收集算法\"><a href=\"#3-4-分代收集算法\" class=\"headerlink\" title=\"3.4 分代收集算法\"></a>3.4 分代收集算法</h4><p>当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将java堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。<br><strong>比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。</strong></p>\n<h3 id=\"4-垃圾收集器\"><a href=\"#4-垃圾收集器\" class=\"headerlink\" title=\"4.垃圾收集器\"></a>4.垃圾收集器</h3><p><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fwkludx4n3j309o08pk2y.jpg\" alt=\"\"></p>\n<p><strong>如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。</strong><br>虽然我们对各个收集器进行比较，但并非为了挑选出一个最好的收集器。因为直到现在为止还没有最好的垃圾收集器出现，更加没有万能的垃圾收集器，<strong>我们能做的就是根据具体应用场景选择适合自己的垃圾收集器。</strong>试想一下：如果有一种四海之内、任何场景下都适用的完美收集器存在，那么我们的HotSpot虚拟机就不会实现那么多不同的垃圾收集器了。</p>\n<h4 id=\"4-1-Serial收集器\"><a href=\"#4-1-Serial收集器\" class=\"headerlink\" title=\"4.1 Serial收集器\"></a>4.1 Serial收集器</h4><p>Serial（串行）收集器收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 <strong>“单线程”</strong> 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（<strong>“Stop The World”</strong>），直到它收集结束。<br><strong>新生代采用复制算法，老年代采用标记-整理算法。</strong></p>\n<p><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fwle0oc18dj307k04c78m.jpg\" alt=\"\"></p>\n<p>虚拟机的设计者们当然知道Stop The World带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。<br>但是Serial收集器有没有优于其他垃圾收集器的地方呢？当然有，它<strong>简单而高效（与其他收集器的单线程相比）</strong>。Serial收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。</p>\n<h4 id=\"4-2-ParNew收集器\"><a href=\"#4-2-ParNew收集器\" class=\"headerlink\" title=\"4.2 ParNew收集器\"></a>4.2 ParNew收集器</h4><p><strong>ParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和Serial收集器完全一样。</strong><br><strong>新生代采用复制算法，老年代采用标记-整理算法。</strong></p>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fwle38p4fjj308y05g7av.jpg\" alt=\"\"></p>\n<p>它是许多运行在Server模式下的虚拟机的首要选择，除了Serial收集器外，只有它能与CMS收集器（真正意义上的并发收集器，后面会介绍到）配合工作。    </p>\n<p><strong>并行和并发概念补充：</strong><br><strong>并行（Parallel） ：</strong>指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。适合科学计算、后台处理等弱交互场景。<br><strong>并发（Concurrent）：</strong>指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个CPU上。适合Web应用。</p>\n<h4 id=\"4-3-Parallel-Scavenge收集器\"><a href=\"#4-3-Parallel-Scavenge收集器\" class=\"headerlink\" title=\"4.3 Parallel Scavenge收集器\"></a>4.3 Parallel Scavenge收集器</h4><p>Parallel Scavenge 收集器类似于ParNew 收集器，是Server 模式（内存大于2G，2个cpu）下的默认收集器，<strong>那么它有什么特别之处呢？</strong>    </p>\n<p><strong>Parallel Scavenge收集器关注点是吞吐量（高效率的利用CPU）。CMS等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是CPU中用于运行用户代码的时间与CPU总消耗时间的比值。</strong> Parallel Scavenge收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。<br><strong>新生代采用复制算法，老年代采用标记-整理算法。</strong></p>\n<p><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fwlec3ndf3j308y05g7av.jpg\" alt=\"\"></p>\n<h4 id=\"4-4-Serial-Old收集器\"><a href=\"#4-4-Serial-Old收集器\" class=\"headerlink\" title=\"4.4.Serial Old收集器\"></a>4.4.Serial Old收集器</h4><p><strong>Serial收集器的老年代版本，</strong>它同样是一个单线程收集器。它主要有两大用途：一种用途是在JDK1.5以及以前的版本中与Parallel Scavenge收集器搭配使用，另一种用途是作为CMS收集器的后备方案。</p>\n<h4 id=\"4-5-Parallel-Old收集器\"><a href=\"#4-5-Parallel-Old收集器\" class=\"headerlink\" title=\"4.5 Parallel Old收集器\"></a>4.5 Parallel Old收集器</h4><p><strong>Parallel Scavenge收集器的老年代版本。</strong>使用多线程和“标记-整理”算法。在注重吞吐量以及CPU资源的场合，都可以优先考虑 Parallel Scavenge收集器和Parallel Old收集器。</p>\n<h4 id=\"4-6-CMS收集器-XX-UseConcMarkSweepGC-主要是old区使用\"><a href=\"#4-6-CMS收集器-XX-UseConcMarkSweepGC-主要是old区使用\" class=\"headerlink\" title=\"4.6 CMS收集器(-XX:+UseConcMarkSweepGC(主要是old区使用))\"></a>4.6 CMS收集器(-XX:+UseConcMarkSweepGC(主要是old区使用))</h4><p><strong>CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它而非常符合在注重用户体验的应用上使用，它是HotSpot虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。</strong>    </p>\n<p>从名字中的<strong>Mark Sweep</strong>这两个词可以看出，CMS收集器是一种<strong>“标记-清除”</strong>算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤：<br><strong>初始标记： </strong>暂停所有的其他线程(STW)，并记录下直接与root相连的对象，速度很快 ；    </p>\n<p><strong>并发标记： </strong>同时开启GC和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以GC线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。    </p>\n<p><strong>重新标记： </strong>重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短。    </p>\n<p><strong>并发清除： </strong>开启用户线程，同时GC线程开始对未标记的区域做清扫。</p>\n<p><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fwllf0fe7rj30bj05ggu6.jpg\" alt=\"\"></p>\n<p>从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：<strong>并发收集、低停顿。</strong><br>但是它有下面三个明显的缺点：<br><strong>对CPU资源敏感（会和服务抢资源）；<br>无法处理浮动垃圾(在java业务程序线程与垃圾收集线程并发执行过程中又产生的垃圾，这种浮动垃圾只能等到下一次gc再清理了)；<br>它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。</strong>    </p>\n<p>CMS的相关参数<br>-XX:+UseConcMarkSweepGC 启用cms<br>-XX:ConcGCThreads:并发的GC线程数（并非STW时间，而是和服务一起执行的线程数）<br>-XX:+UseCMSCompactAtFullCollection:FullGC之后做压缩（减少碎片）<br>-XX:CMSFullGCsBeforeCompaction:多少次FullGC之后压缩一次（因压缩非常的消耗时间，所以不能每次FullGC都做）<br>-XX:CMSInitiatingOccupancyFraction:触发FulGC条件（默认是92）<br>-XX:+UseCMSInitiatingOccupancyOnly:是否动态调节<br>-XX:+CMSScavengeBeforeRemark:FullGC之前先做YGC（一般这个参数是打开的）<br>-XX:+CMSClassUnloadingEnabled:启用回收Perm区（jdk1.7及以前）    </p>\n<h4 id=\"4-7-G1收集器-XX-UseG1GC\"><a href=\"#4-7-G1收集器-XX-UseG1GC\" class=\"headerlink\" title=\"4.7 G1收集器(-XX:+UseG1GC)\"></a>4.7 G1收集器(-XX:+UseG1GC)</h4><p><strong>G1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征.</strong></p>\n<p><img src=\"https://ws2.sinaimg.cn/large/006tNbRwly1fwllh2wdvvj30a806b47b.jpg\" alt=\"\"></p>\n<p><img src=\"https://ws2.sinaimg.cn/large/006tNbRwly1fwllh8r1k8j30bj042agd.jpg\" alt=\"\"></p>\n<p>G1将Java堆划分为多个大小相等的独立区域（Region），虽保留新生代和老年代的概念，但不再是物理隔阂了，它们都是（可以不连续）Region的集合。<br>分配大对象（直接进Humongous区，专门存放短期巨型对象，不用直接进老年代，避免Full GC的大量开销）不会因为无法找到连续空间而提前触发下一次GC。<br>被视为JDK1.7中HotSpot虚拟机的一个重要进化特征。它具备以下特点：</p>\n<p><strong>并行与并发：</strong>G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿时间。部分其他收集器原本需要停顿Java线程来执行GC动作，G1收集器仍然可以通过并发的方式让java程序继续执行。    </p>\n<p><strong>分代收集：</strong>虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但是还是保留了分代的概念。    </p>\n<p><strong>空间整合：</strong>与CMS的“标记–清理”算法不同，G1从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。    </p>\n<p><strong>可预测的停顿：</strong>这是G1相对于CMS的另一个大优势，降低停顿时间是G1 和 CMS 共同的关注点，但G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内完成垃圾收集。    </p>\n<p>G1收集器的运作大致分为以下几个步骤：</p>\n<p><strong>初始标记（initial mark，STW）：</strong>在此阶段，G1 GC 对根进行标记。该阶段与常规的 (STW) 年轻代垃圾回收密切相关。    </p>\n<p><strong>并发标记（Concurrent Marking）：</strong>G1 GC 在整个堆中查找可访问的（存活的）对象。</p>\n<p><strong>最终标记（Remark，STW）：</strong>该阶段是 STW 回收，帮助完成标记周期。</p>\n<p><strong>筛选回收（Cleanup，STW）：</strong>筛选回收阶段首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。<br><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fwlljwh6fcj30ds03ftf2.jpg\" alt=\"\"></p>\n<p><strong>G1收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的Region(这也就是它的名字Garbage-First的由来)。</strong>这种使用Region划分内存空间以及有优先级的区域回收方式，保证了GF收集器在有限时间内可以尽可能高的收集效率。</p>\n","categories":["虚拟机专题"],"tags":[]},{"title":"类加载机制","url":"http://ilovenorth.cn/2018/10/24/类加载机制/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"类加载机制\"><a href=\"#类加载机制\" class=\"headerlink\" title=\"类加载机制\"></a>类加载机制</h1><hr>\n<p>Java运行时编译源码(.java)成字节码，由jre运行。jre由Java虚拟机(jvm)实现。Jvm分析字节码，后解释并执行。<br>简单看看就行 -。-<br><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fwhxxi4thuj30zk0a80va.jpg\" alt=\"\"></p>\n<h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><pre><code>1.类加载过程\n2.类加载器种类\n3.类加载机制\n</code></pre><hr>\n<h3 id=\"类加载过程\"><a href=\"#类加载过程\" class=\"headerlink\" title=\"类加载过程\"></a>类加载过程</h3><p><img src=\"https://ws2.sinaimg.cn/large/006tNbRwly1fwhxzsbd4ej30zk04qab0.jpg\" alt=\"\"></p>\n<p>类加载：类加载器将class文件加载到虚拟机的内存    </p>\n<ul>\n<li><p>加载：在硬盘上查找并通过IO读入字节码文件。    </p>\n</li>\n<li><p>连接：执行校验、准备、解析（可选）步骤。    </p>\n</li>\n<li><p>校验：校验字节码文件的正确性。    </p>\n</li>\n<li><p>准备：给类的静态变量分配内存，并赋予默认值，我们都知道静态变量是归属于类的，而不是类的对象，只在类的第一次加载的时候会给静态变量分配内存，然后赋予默认值。    </p>\n</li>\n<li><p>解析：类装载器装入类所引用的其他所有类。    </p>\n</li>\n<li><p>初始化：对类的静态变量初始化为指定的值，执行静态代码块,和准备步骤的区别:假如我们 static int a = 5，在准备的那步是把int类型的变量a赋予默认值为0，然后在初始化这步把a初始化为5。</p>\n</li>\n</ul>\n<h3 id=\"类加载器种类\"><a href=\"#类加载器种类\" class=\"headerlink\" title=\"类加载器种类\"></a>类加载器种类</h3><p>从现在开始就是重点内容了！</p>\n<p>类加载器有以下几个种类：    </p>\n<ul>\n<li><p>启动类加载器：负责加载JRE的核心类库，如jre目标下的rt.jar,charsets.jar等    </p>\n</li>\n<li><p>扩展类加载器：负责加载JRE扩展目录ext中JAR类包    </p>\n</li>\n<li><p>系统类加载器：负责加载ClassPath路径下的类包    </p>\n</li>\n<li><p>用户自定义加载器：负责加载用户自定义路径下的类包</p>\n</li>\n</ul>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fwhyj98u6aj30j80fwjt9.jpg\" alt=\"\"></p>\n<p>这些定义是很难直接理解的，我们还是根据代码来分析。</p>\n<p><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fwhyo8ndzjj31hq0eik4c.jpg\" alt=\"\"><br>执行一下，我们先来看看这四个类是用什么类加载器加载的。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">null</span><br><span class=\"line\">sun.misc.Launcher$ExtClassLoader</span><br><span class=\"line\">sun.misc.Launcher$AppClassLoader</span><br><span class=\"line\">sun.misc.Launcher$AppClassLoader</span><br></pre></td></tr></table></figure>\n<p>我们先不看String类，我们直接看第二行的 DESKeyFactory 类，这是一个加解密的类，我们发现，它的类加载器是ExtClassLoader，根据上面的层级图我们可以知道，ExtClassLoader也就是拓展类加载器。拓展类加载器负责加载JRE扩展目录ext中JAR类包，我们找一下这个类所在的位置，在我的电脑里是/Library/Java/JavaVirtualMachines/jdk1.8.0_144.jdk/Contents/Home/<font color=\"orange\">jre/lib/ext/sunjce_provider.jar!</font>/com/sun/crypto/provider/DESKeyFactory.class ，果然！</p>\n<p>我们再看第二行，第二行我们要看是我们这个测试类本身，它的类加载器是AppClassLoader，AppClassLoader也就是系统类加载器：负责加载ClassPath路径下的类包，在我的电脑里/Users/murasakiseifu/Downloads/SDKTest/src/main/java/com/oss/SDKTest/TestJDKClassLoader.java，只要是在我们类路径下的类，就都会用AppClassLoader。</p>\n<p>我们再回到第一行String类，我们先看一下String类的位置：/Library/Java/JavaVirtualMachines/jdk1.8.0_144.jdk/Contents/Home/jre/lib/rt.jar!/java/lang/String.class，我们可以看到String.class是在JDK核心jar包之一的rt.jar下的，和ext扩展类文件夹同级的这些包，都属于JDK的核心jar包。<br><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fwhz97rco1j31kw0mmgvc.jpg\" alt=\"\"><br>但是为什么显示为null？因为这些jar包都是c语言写的，JDK并不知道名字。</p>\n<p>最后一行是打印了一下我们系统类加载器的名字。</p>\n<hr>\n<h3 id=\"类加载机制-1\"><a href=\"#类加载机制-1\" class=\"headerlink\" title=\"类加载机制\"></a>类加载机制</h3><hr>\n<p>1.全盘负责委托机制<br>2.双亲委派机制</p>\n<p><strong>全盘负责委托机制</strong>    </p>\n<p>当一个ClassLoader加载一个类时，除非显示的使用另一个ClassLoader，该类所依赖和引用的类也由这个ClassLoader载入。<br>当我们类A引用类B引用C时，类A用的是什么类加载器，那么类B类C用的就是什么加载器，一般我们也会不改这个，了解一下就好。</p>\n<p><strong>双亲委派机制</strong>    </p>\n<p>指先委托父类加载器寻找目标类，在找不到的情况下在自己的路径中查找并载入目标类。<br>这个是我们要了解的重点！我们再来看一下这个图。<br><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fwhyj98u6aj30j80fwjt9.jpg\" alt=\"\"></p>\n<p>在介绍之前，我们要明白一个概念：<font color=\"red\">这些ClassLoader之间并不是继承的关系！并不是继承的关系！并不是继承的关系！</font>重要的事情说三遍，准确点说应该是父级的类加载器，这里是为了大家更好的理解。</p>\n<p>比如我们加载我们这个Test类，如果我们没有自定义类加载器，那么一开始就是从系统类加载器开始—-&gt;它去请求他的上一级类加载器：拓展类加载器—-&gt;拓展类加载器再去请求他的上级：启动类加载器——&gt;然后启动类加载器开始检测能否加载这个类，因为启动类加载器只加载JRE的核心类库，所有他加载不了，他就交由他的子级加载器：拓展类加载器—-&gt;拓展类加载器开始检测能否加载这个类，因为拓展列加载器负责加载JRE扩展目录ext中JAR类包，他也加载不了，他也交由给他的子级加载器：系统类加载器。</p>\n<p>这么玩的原因是什么？</p>\n<p><strong>双亲委派模式的沙箱安全机制</strong>：自己写的String.class类不会被加载，这样便可以防止核心API库被随意篡改.</p>\n<p>假如有一个王八蛋自己写了一个String.class，而且完完全全模拟了JDK中String类的包路径，如果没有双亲委派机制，那后果可就不堪设想了。假如黑客模拟写了一个java.lang.string类，当类加载器进行加载的时候，类加载器根据双亲委派机制，当启动类加载器看到这个路径的java.lang.string类，他也是会去加载JRE的核心类库里的String类，确保了<br>核心API库不会被随意篡改.</p>\n<p><strong>避免类的重复加载</strong>：当父亲已经加载了该类时，就没有必要ClassLoader再加载一次。</p>\n<p>一个常见的问题：JVM加载jar包是否会将包里的所有类全部加载进内存？<br>JVM对class文件是按需加载(运行期间动态加载)，非一次性加载。</p>\n","categories":["源码分析"],"tags":[]},{"title":"JVM指令集","url":"http://ilovenorth.cn/2018/10/23/JVM指令集/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<p>跳转到class文件目录，使用 </p>\n<p>javap -c StringTest.class -&gt; p.txt</p>\n<p>1 </p>\n<p>命令将编译后的文件输出到p.txt文件</p>\n<p>栈和局部变量操作</p>\n<p>将常量压入栈的指令</p>\n<p>aconst_null 将null对象引用压入栈</p>\n<p>iconst_m1 将int类型常量-1压入栈</p>\n<p>iconst_0 将int类型常量0压入栈</p>\n<p>iconst_1 将int类型常量1压入栈</p>\n<p>iconst_2 将int类型常量2压入栈</p>\n<p>iconst_3 将int类型常量3压入栈</p>\n<p>iconst_4 将int类型常量4压入栈</p>\n<p>iconst_5 将int类型常量5压入栈</p>\n<p>lconst_0 将long类型常量0压入栈</p>\n<p>lconst_1 将long类型常量1压入栈</p>\n<p>fconst_0 将float类型常量0压入栈</p>\n<p>fconst_1 将float类型常量1压入栈</p>\n<p>dconst_0 将double类型常量0压入栈</p>\n<p>dconst_1 将double类型常量1压入栈</p>\n<p>bipush 将一个8位带符号整数压入栈</p>\n<p>sipush 将16位带符号整数压入栈</p>\n<p>ldc 把常量池中的项压入栈</p>\n<p>ldc_w 把常量池中的项压入栈（使用宽索引）</p>\n<p>ldc2_w 把常量池中long类型或者double类型的项压入栈（使用宽索引）</p>\n<p>从栈中的局部变量中装载值的指令</p>\n<p>iload 从局部变量中装载int类型值</p>\n<p>lload 从局部变量中装载long类型值</p>\n<p>fload 从局部变量中装载float类型值</p>\n<p>dload 从局部变量中装载double类型值</p>\n<p>aload 从局部变量中装载引用类型值（refernce）</p>\n<p>iload_0 从局部变量0中装载int类型值</p>\n<p>iload_1 从局部变量1中装载int类型值</p>\n<p>iload_2 从局部变量2中装载int类型值</p>\n<p>iload_3 从局部变量3中装载int类型值</p>\n<p>lload_0 从局部变量0中装载long类型值</p>\n<p>lload_1 从局部变量1中装载long类型值</p>\n<p>lload_2 从局部变量2中装载long类型值</p>\n<p>lload_3 从局部变量3中装载long类型值</p>\n<p>fload_0 从局部变量0中装载float类型值</p>\n<p>fload_1 从局部变量1中装载float类型值</p>\n<p>fload_2 从局部变量2中装载float类型值</p>\n<p>fload_3 从局部变量3中装载float类型值</p>\n<p>dload_0 从局部变量0中装载double类型值</p>\n<p>dload_1 从局部变量1中装载double类型值</p>\n<p>dload_2 从局部变量2中装载double类型值</p>\n<p>dload_3 从局部变量3中装载double类型值</p>\n<p>aload_0 从局部变量0中装载引用类型值</p>\n<p>aload_1 从局部变量1中装载引用类型值</p>\n<p>aload_2 从局部变量2中装载引用类型值</p>\n<p>aload_3 从局部变量3中装载引用类型值</p>\n<p>iaload 从数组中装载int类型值</p>\n<p>laload 从数组中装载long类型值</p>\n<p>faload 从数组中装载float类型值</p>\n<p>daload 从数组中装载double类型值</p>\n<p>aaload 从数组中装载引用类型值</p>\n<p>baload 从数组中装载byte类型或boolean类型值</p>\n<p>caload 从数组中装载char类型值</p>\n<p>saload 从数组中装载short类型值</p>\n<p>将栈中的值存入局部变量的指令</p>\n<p>istore 将int类型值存入局部变量</p>\n<p>lstore 将long类型值存入局部变量</p>\n<p>fstore 将float类型值存入局部变量</p>\n<p>dstore 将double类型值存入局部变量</p>\n<p>astore 将将引用类型或returnAddress类型值存入局部变量</p>\n<p>istore_0 将int类型值存入局部变量0</p>\n<p>istore_1 将int类型值存入局部变量1</p>\n<p>istore_2 将int类型值存入局部变量2</p>\n<p>istore_3 将int类型值存入局部变量3</p>\n<p>lstore_0 将long类型值存入局部变量0</p>\n<p>lstore_1 将long类型值存入局部变量1</p>\n<p>lstore_2 将long类型值存入局部变量2</p>\n<p>lstore_3 将long类型值存入局部变量3</p>\n<p>fstore_0 将float类型值存入局部变量0</p>\n<p>fstore_1 将float类型值存入局部变量1</p>\n<p>fstore_2 将float类型值存入局部变量2</p>\n<p>fstore_3 将float类型值存入局部变量3</p>\n<p>dstore_0 将double类型值存入局部变量0</p>\n<p>dstore_1 将double类型值存入局部变量1</p>\n<p>dstore_2 将double类型值存入局部变量2</p>\n<p>dstore_3 将double类型值存入局部变量3</p>\n<p>astore_0 将引用类型或returnAddress类型值存入局部变量0</p>\n<p>astore_1 将引用类型或returnAddress类型值存入局部变量1</p>\n<p>astore_2 将引用类型或returnAddress类型值存入局部变量2</p>\n<p>astore_3 将引用类型或returnAddress类型值存入局部变量3</p>\n<p>iastore 将int类型值存入数组中</p>\n<p>lastore 将long类型值存入数组中</p>\n<p>fastore 将float类型值存入数组中</p>\n<p>dastore 将double类型值存入数组中</p>\n<p>aastore 将引用类型值存入数组中</p>\n<p>bastore 将byte类型或者boolean类型值存入数组中</p>\n<p>castore 将char类型值存入数组中</p>\n<p>sastore 将short类型值存入数组中</p>\n<p>wide指令</p>\n<p>wide 使用附加字节扩展局部变量索引</p>\n<p>通用(无类型）栈操作</p>\n<p>nop 不做任何操作</p>\n<p>pop 弹出栈顶端一个字长的内容</p>\n<p>pop2 弹出栈顶端两个字长的内容</p>\n<p>dup 复制栈顶部一个字长内容</p>\n<p>dup_x1 复制栈顶部一个字长的内容，然后将复制内容及原来弹出的两个字长的内容压入栈</p>\n<p>dup_x2 复制栈顶部一个字长的内容，然后将复制内容及原来弹出的三个字长的内容压入栈</p>\n<p>dup2 复制栈顶部两个字长内容</p>\n<p>dup2_x1 复制栈顶部两个字长的内容，然后将复制内容及原来弹出的三个字长的内容压入栈</p>\n<p>dup2_x2 复制栈顶部两个字长的内容，然后将复制内容及原来弹出的四个字长的内容压入栈</p>\n<p>swap 交换栈顶部两个字长内容</p>\n<p>类型转换</p>\n<p>i2l 把int类型的数据转化为long类型</p>\n<p>i2f 把int类型的数据转化为float类型</p>\n<p>i2d 把int类型的数据转化为double类型</p>\n<p>l2i 把long类型的数据转化为int类型</p>\n<p>l2f 把long类型的数据转化为float类型</p>\n<p>l2d 把long类型的数据转化为double类型</p>\n<p>f2i 把float类型的数据转化为int类型</p>\n<p>f2l 把float类型的数据转化为long类型</p>\n<p>f2d 把float类型的数据转化为double类型</p>\n<p>d2i 把double类型的数据转化为int类型</p>\n<p>d2l 把double类型的数据转化为long类型</p>\n<p>d2f 把double类型的数据转化为float类型</p>\n<p>i2b 把int类型的数据转化为byte类型</p>\n<p>i2c 把int类型的数据转化为char类型</p>\n<p>i2s 把int类型的数据转化为short类型</p>\n<p>整数运算</p>\n<p>iadd 执行int类型的加法</p>\n<p>ladd 执行long类型的加法</p>\n<p>isub 执行int类型的减法</p>\n<p>lsub 执行long类型的减法</p>\n<p>imul 执行int类型的乘法</p>\n<p>lmul 执行long类型的乘法</p>\n<p>idiv 执行int类型的除法</p>\n<p>ldiv 执行long类型的除法</p>\n<p>irem 计算int类型除法的余数</p>\n<p>lrem 计算long类型除法的余数</p>\n<p>ineg 对一个int类型值进行取反操作</p>\n<p>lneg 对一个long类型值进行取反操作</p>\n<p>iinc 把一个常量值加到一个int类型的局部变量上</p>\n<p>逻辑运算</p>\n<p>移位操作</p>\n<p>ishl 执行int类型的向左移位操作</p>\n<p>lshl 执行long类型的向左移位操作</p>\n<p>ishr 执行int类型的向右移位操作</p>\n<p>lshr 执行long类型的向右移位操作</p>\n<p>iushr 执行int类型的向右逻辑移位操作</p>\n<p>lushr 执行long类型的向右逻辑移位操作</p>\n<p>按位布尔运算</p>\n<p>iand 对int类型值进行“逻辑与”操作</p>\n<p>land 对long类型值进行“逻辑与”操作</p>\n<p>ior 对int类型值进行“逻辑或”操作</p>\n<p>lor 对long类型值进行“逻辑或”操作</p>\n<p>ixor 对int类型值进行“逻辑异或”操作</p>\n<p>lxor 对long类型值进行“逻辑异或”操作</p>\n<p>浮点运算</p>\n<p>fadd 执行float类型的加法</p>\n<p>dadd 执行double类型的加法</p>\n<p>fsub 执行float类型的减法</p>\n<p>dsub 执行double类型的减法</p>\n<p>fmul 执行float类型的乘法</p>\n<p>dmul 执行double类型的乘法</p>\n<p>fdiv 执行float类型的除法</p>\n<p>ddiv 执行double类型的除法</p>\n<p>frem 计算float类型除法的余数</p>\n<p>drem 计算double类型除法的余数</p>\n<p>fneg 将一个float类型的数值取反</p>\n<p>dneg 将一个double类型的数值取反</p>\n<p>对象和数组</p>\n<p>对象操作指令</p>\n<p>new 创建一个新对象</p>\n<p>checkcast 确定对象为所给定的类型</p>\n<p>getfield 从对象中获取字段</p>\n<p>putfield 设置对象中字段的值</p>\n<p>getstatic 从类中获取静态字段</p>\n<p>putstatic 设置类中静态字段的值</p>\n<p>instanceof 判断对象是否为给定的类型</p>\n<p>数组操作指令</p>\n<p>newarray 分配数据成员类型为基本上数据类型的新数组</p>\n<p>anewarray 分配数据成员类型为引用类型的新数组</p>\n<p>arraylength 获取数组长度</p>\n<p>multianewarray 分配新的多维数组</p>\n<p>控制流</p>\n<p>条件分支指令</p>\n<p>ifeq 如果等于0，则跳转</p>\n<p>ifne 如果不等于0，则跳转</p>\n<p>iflt 如果小于0，则跳转</p>\n<p>ifge 如果大于等于0，则跳转</p>\n<p>ifgt 如果大于0，则跳转</p>\n<p>ifle 如果小于等于0，则跳转</p>\n<p>if_icmpcq 如果两个int值相等，则跳转</p>\n<p>if_icmpne 如果两个int类型值不相等，则跳转</p>\n<p>if_icmplt 如果一个int类型值小于另外一个int类型值，则跳转</p>\n<p>if_icmpge 如果一个int类型值大于或者等于另外一个int类型值，则跳转</p>\n<p>if_icmpgt 如果一个int类型值大于另外一个int类型值，则跳转</p>\n<p>if_icmple 如果一个int类型值小于或者等于另外一个int类型值，则跳转</p>\n<p>ifnull 如果等于null，则跳转</p>\n<p>ifnonnull 如果不等于null，则跳转</p>\n<p>if_acmpeq 如果两个对象引用相等，则跳转</p>\n<p>if_acmpnc 如果两个对象引用不相等，则跳转</p>\n<p>比较指令</p>\n<p>lcmp 比较long类型值</p>\n<p>fcmpl 比较float类型值（当遇到NaN时，返回-1）</p>\n<p>fcmpg 比较float类型值（当遇到NaN时，返回1）</p>\n<p>dcmpl 比较double类型值（当遇到NaN时，返回-1）</p>\n<p>dcmpg 比较double类型值（当遇到NaN时，返回1）</p>\n<p>无条件转移指令</p>\n<p>goto 无条件跳转</p>\n<p>goto_w 无条件跳转（宽索引）</p>\n<p>表跳转指令</p>\n<p>tableswitch 通过索引访问跳转表，并跳转</p>\n<p>lookupswitch 通过键值匹配访问跳转表，并执行跳转操作</p>\n<p>异常</p>\n<p>athrow 抛出异常或错误</p>\n<p>finally子句</p>\n<p>jsr 跳转到子例程</p>\n<p>jsr_w 跳转到子例程（宽索引）</p>\n<p>rct 从子例程返回</p>\n<p>方法调用与返回</p>\n<p>方法调用指令</p>\n<p>invokcvirtual 运行时按照对象的类来调用实例方法</p>\n<p>invokespecial 根据编译时类型来调用实例方法</p>\n<p>invokestatic 调用类（静态）方法</p>\n<p>invokcinterface 调用接口方法</p>\n<p>方法返回指令</p>\n<p>ireturn 从方法中返回int类型的数据</p>\n<p>lreturn 从方法中返回long类型的数据</p>\n<p>freturn 从方法中返回float类型的数据</p>\n<p>dreturn 从方法中返回double类型的数据</p>\n<p>areturn 从方法中返回引用类型的数据</p>\n<p>return 从方法中返回，返回值为void</p>\n<p>线程同步</p>\n<p>montiorenter 进入并获取对象监视器</p>\n<p>monitorexit 释放并退出对象监视器</p>\n<p>JVM指令助记符</p>\n<p>变量到操作数栈：iload,iload_,lload,lload_,fload,fload_,dload,dload_,aload,aload_</p>\n<p>操作数栈到变量：istore,istore_,lstore,lstore_,fstore,fstore_,dstore,dstor_,astore,astore_</p>\n<p>常数到操作数栈：bipush,sipush,ldc,ldc_w,ldc2_w,aconst_null,iconst_ml,iconst_,lconst_,fconst_,dconst_</p>\n<p>加：iadd,ladd,fadd,dadd</p>\n<p>减：isub,lsub,fsub,dsub</p>\n<p>乘：imul,lmul,fmul,dmul</p>\n<p>除：idiv,ldiv,fdiv,ddiv</p>\n<p>余数：irem,lrem,frem,drem</p>\n<p>取负：ineg,lneg,fneg,dneg</p>\n<p>移位：ishl,lshr,iushr,lshl,lshr,lushr</p>\n<p>按位或：ior,lor</p>\n<p>按位与：iand,land</p>\n<p>按位异或：ixor,lxor</p>\n<p>类型转换：i2l,i2f,i2d,l2f,l2d,f2d(放宽数值转换)</p>\n<p>i2b,i2c,i2s,l2i,f2i,f2l,d2i,d2l,d2f(缩窄数值转换)</p>\n<p>创建类实便：new</p>\n<p>创建新数组：newarray,anewarray,multianwarray</p>\n<p>访问类的域和类实例域：getfield,putfield,getstatic,putstatic</p>\n<p>把数据装载到操作数栈：baload,caload,saload,iaload,laload,faload,daload,aaload</p>\n<p>从操作数栈存存储到数组：bastore,castore,sastore,iastore,lastore,fastore,dastore,aastore</p>\n<p>获取数组长度：arraylength</p>\n<p>检相类实例或数组属性：instanceof,checkcast</p>\n<p>操作数栈管理：pop,pop2,dup,dup2,dup_xl,dup2_xl,dup_x2,dup2_x2,swap</p>\n<p>有条件转移：ifeq,iflt,ifle,ifne,ifgt,ifge,ifnull,ifnonnull,if_icmpeq,if_icmpene,</p>\n<p>if_icmplt,if_icmpgt,if_icmple,if_icmpge,if_acmpeq,if_acmpne,lcmp,fcmpl</p>\n<p>fcmpg,dcmpl,dcmpg</p>\n<p>复合条件转移：tableswitch,lookupswitch</p>\n<p>无条件转移：goto,goto_w,jsr,jsr_w,ret</p>\n<p>调度对象的实便方法：invokevirtual</p>\n<p>调用由接口实现的方法：invokeinterface</p>\n<p>调用需要特殊处理的实例方法：invokespecial</p>\n<p>调用命名类中的静态方法：invokestatic</p>\n<p>方法返回：ireturn,lreturn,freturn,dreturn,areturn,return</p>\n<p>异常：athrow</p>\n<p>finally关键字的实现使用：jsr,jsr_w,ret</p>\n","categories":["虚拟机专题"],"tags":[]},{"title":"深入理解Java虚拟机","url":"http://ilovenorth.cn/2018/10/22/深入理解Java虚拟机/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"深入理解Java虚拟机\"><a href=\"#深入理解Java虚拟机\" class=\"headerlink\" title=\"深入理解Java虚拟机\"></a>深入理解Java虚拟机</h1><hr>\n<p>PS : 也是最近对Java虚拟机很着迷，听了图灵学院诸葛老师的课，特此记录一下学习笔记，感谢诸葛老师，研究技术总会忘了时间的。</p>\n<p>JVM ：首先我们介绍一下JVM，虚拟机指以软件的方式模拟具有完整硬件系统功能、运行在一个完全隔离环境中的完整计算机系统 ，是物理机的软件实现。常用的虚拟机有VMWare，Virtual Box，Java Virtual Machine。    </p>\n<p>Java虚拟机阵营：Sun HotSpot VM、BEA JRockit VM、IBM J9 VM、Azul VM、Apache Harmony、Google Dalvik VM、Microsoft JVM… Sun HotSpot VM、BEA JRockit VM合并后退出了JDK8。</p>\n<h2 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a>主要内容</h2><p>JVM由三个主要的子系统构成        </p>\n<pre><code>1. 类加载器子系统    \n\n2. 运行时数据区（内存结构）\n\n3. 执行引擎\n</code></pre><p>今天主要记录一下运行时数据区（内存结构），从这里入手，也是比较容易理解。<br>首先我们先来看一下java类加载的过程。<br><img src=\"https://ws2.sinaimg.cn/large/006tNbRwly1fwgurvt9onj30ki0jsjtk.jpg\" alt=\"\"></p>\n<p>当我们执行一个xxx.java文件时，通过javac命令会把Java文件编译成class字节码文件，然后类装载子系统把字节码文件load到java内存里去，也就是我们运行时数据区。<br>我们知道，当我们执行代码时，其实是启动一个Java进程，然后Java进程执行里面的Java线程，最简单的就是main()方法，对于运行时数据区，分为线程私有和线程共享。</p>\n<ul>\n<li>线程共享 ： 方法区、堆。</li>\n<li>线程私有 ： Java栈、本地方法栈、程序计数器。</li>\n</ul>\n<p>我们这里不解释这5个区的具体意思，网上有很多，我们还是根据代码一点一点的分析，结合理论会更容易理解。</p>\n<h3 id=\"Java栈\"><a href=\"#Java栈\" class=\"headerlink\" title=\"Java栈\"></a>Java栈</h3><hr>\n<p>我们简化一下上面的那张图。</p>\n<p><img src=\"https://ws2.sinaimg.cn/large/006tNbRwly1fwgykbyxskj316u0p8wi6.jpg\" alt=\"\"></p>\n<p>1.实例代码</p>\n<p><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fwgyn0ukj3j30v20j8qeg.jpg\" alt=\"\"></p>\n<p>一个很简单的运算函数，接下来我们演示java栈是如何处理这段代码的。</p>\n<p>每一个线程都存在三个线程私有的模块：Java栈、本地方法栈、程序计数器。这个我们已经知道了，所以当我们执行这个java程序时，线程1就拥有了它私有的Java栈、本地方法栈、程序计数器。<br>如下图所示。</p>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fwgytilsm2j31hi0sq0xj.jpg\" alt=\"\"></p>\n<p>一个线程中每个方法在执行的同时都会创建一个栈帧（用于存储局部变量表，操作数栈，动态链接，方法出口等信息），不存在垃圾回收问题，只要线程一结束该栈就释放，生命周期和线程一致，因为是线程私有的。    </p>\n<p>所以，对于我们上面的实例代码，当我们执行的时候，一共会执行两个方法：main()方法、math()方法。因此会创建两个栈帧，我们都知道栈的数据结构是后入先出，所以当线程1执行程序的时候，java栈的执行过程是这样的。<br><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fwgyzlp1w5j31go0rgtdl.jpg\" alt=\"\"><br><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fwgz0o8xrjj31gk0rmjwk.jpg\" alt=\"\"><br>完善一下这个图，最终是这个样子。<br><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fwgz68yklxj31g40quafq.jpg\" alt=\"\"></p>\n<h3 id=\"class-字节码\"><a href=\"#class-字节码\" class=\"headerlink\" title=\"class 字节码\"></a>class 字节码</h3><hr>\n<p>再去了解java栈里面的知识，就需要去看class的字节码文件了。当我们用javac xxx.java时就会生成字节码文件，实例代码的字节码文件如下所示。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">cafe babe 0000 0034 0025 0a00 0900 1407</span><br><span class=\"line\">0015 0a00 0200 1409 0016 0017 0a00 0200</span><br><span class=\"line\">180a 0019 001a 0800 1b0a 0019 001c 0700</span><br><span class=\"line\">1d01 0006 3c69 6e69 743e 0100 0328 2956</span><br><span class=\"line\">0100 0443 6f64 6501 000f 4c69 6e65 4e75</span><br><span class=\"line\">6d62 6572 5461 626c 6501 0004 6d61 7468</span><br><span class=\"line\">0100 0328 2949 0100 046d 6169 6e01 0016</span><br><span class=\"line\">285b 4c6a 6176 612f 6c61 6e67 2f53 7472</span><br><span class=\"line\">696e 673b 2956 0100 0a53 6f75 7263 6546</span><br><span class=\"line\">696c 6501 0009 4d61 7468 2e6a 6176 610c</span><br><span class=\"line\">000a 000b 0100 1463 6f6d 2f6f 7373 2f53</span><br><span class=\"line\">444b 5465 7374 2f4d 6174 6807 001e 0c00</span><br><span class=\"line\">1f00 200c 000e 000f 0700 210c 0022 0023</span><br><span class=\"line\">0100 0365 6e64 0c00 2200 2401 0010 6a61</span><br><span class=\"line\">7661 2f6c 616e 672f 4f62 6a65 6374 0100</span><br><span class=\"line\">106a 6176 612f 6c61 6e67 2f53 7973 7465</span><br><span class=\"line\">6d01 0003 6f75 7401 0015 4c6a 6176 612f</span><br><span class=\"line\">696f 2f50 7269 6e74 5374 7265 616d 3b01</span><br><span class=\"line\">0013 6a61 7661 2f69 6f2f 5072 696e 7453</span><br><span class=\"line\">7472 6561 6d01 0007 7072 696e 746c 6e01</span><br><span class=\"line\">0004 2849 2956 0100 1528 4c6a 6176 612f</span><br><span class=\"line\">6c61 6e67 2f53 7472 696e 673b 2956 0020</span><br><span class=\"line\">0002 0009 0000 0000 0003 0000 000a 000b</span><br><span class=\"line\">0001 000c 0000 001d 0001 0001 0000 0005</span><br><span class=\"line\">2ab7 0001 b100 0000 0100 0d00 0000 0600</span><br><span class=\"line\">0100 0000 0900 0100 0e00 0f00 0100 0c00</span><br><span class=\"line\">0000 3100 0200 0400 0000 0d04 3c05 3d1b</span><br><span class=\"line\">1c60 100a 683e 1dac 0000 0001 000d 0000</span><br><span class=\"line\">0012 0004 0000 000c 0002 000d 0004 000e</span><br><span class=\"line\">000b 000f 0009 0010 0011 0001 000c 0000</span><br><span class=\"line\">003f 0002 0002 0000 001b bb00 0259 b700</span><br><span class=\"line\">034c b200 042b b600 05b6 0006 b200 0412</span><br><span class=\"line\">07b6 0008 b100 0000 0100 0d00 0000 1200</span><br><span class=\"line\">0400 0000 1300 0800 1400 1200 1500 1a00</span><br><span class=\"line\">1600 0100 1200 0000 0200 13</span><br></pre></td></tr></table></figure>\n<p>每一个4位字节码对应一个指令，我们这么看是肯定看不懂的，所以我们通过javap -c 来反编译一下字节码文件，并把它写到.txt文件中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">javap</span><br><span class=\"line\">用法: javap &lt;options&gt; &lt;classes&gt;</span><br><span class=\"line\">其中, 可能的选项包括:</span><br><span class=\"line\">  -help  --help  -?        输出此用法消息</span><br><span class=\"line\">  -version                 版本信息</span><br><span class=\"line\">  -v  -verbose             输出附加信息</span><br><span class=\"line\">  -l                       输出行号和本地变量表</span><br><span class=\"line\">  -public                  仅显示公共类和成员</span><br><span class=\"line\">  -protected               显示受保护的/公共类和成员</span><br><span class=\"line\">  -package                 显示程序包/受保护的/公共类</span><br><span class=\"line\">                           和成员 (默认)</span><br><span class=\"line\">  -p  -private             显示所有类和成员</span><br><span class=\"line\">  -c                       对代码进行反汇编</span><br><span class=\"line\">  -s                       输出内部类型签名</span><br><span class=\"line\">  -sysinfo                 显示正在处理的类的</span><br><span class=\"line\">                           系统信息 (路径, 大小, 日期, MD5 散列)</span><br><span class=\"line\">  -constants               显示最终常量</span><br><span class=\"line\">  -classpath &lt;path&gt;        指定查找用户类文件的位置</span><br><span class=\"line\">  -cp &lt;path&gt;               指定查找用户类文件的位置</span><br><span class=\"line\"> \t  -bootclasspath &lt;path&gt;    覆盖引导类文件的位置</span><br><span class=\"line\"></span><br><span class=\"line\">javap -c Math.class &gt; math.txt</span><br></pre></td></tr></table></figure>\n<p>反编译生成的.txt如下所示。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Compiled from &quot;Math.java&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">class com.oss.SDKTest.Math &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  com.oss.SDKTest.Math();</span><br><span class=\"line\">    Code:</span><br><span class=\"line\">       0: aload_0</span><br><span class=\"line\">       1: invokespecial #1                  // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V</span><br><span class=\"line\">       4: return</span><br><span class=\"line\"></span><br><span class=\"line\">  public int math();</span><br><span class=\"line\">    Code:</span><br><span class=\"line\">       0: iconst_1</span><br><span class=\"line\">       1: istore_1</span><br><span class=\"line\">       2: iconst_2</span><br><span class=\"line\">       3: istore_2</span><br><span class=\"line\">       4: iload_1</span><br><span class=\"line\">       5: iload_2</span><br><span class=\"line\">       6: iadd</span><br><span class=\"line\">       7: bipush        10</span><br><span class=\"line\">       9: imul</span><br><span class=\"line\">      10: istore_3</span><br><span class=\"line\">      11: iload_3</span><br><span class=\"line\">      12: ireturn</span><br><span class=\"line\"></span><br><span class=\"line\">  public static void main(java.lang.String[]);</span><br><span class=\"line\">    Code:</span><br><span class=\"line\">       0: new           #2                  // class com/oss/SDKTest/Math</span><br><span class=\"line\">       3: dup</span><br><span class=\"line\">       4: invokespecial #3                  // Method &quot;&lt;init&gt;&quot;:()V</span><br><span class=\"line\">       7: astore_1</span><br><span class=\"line\">       8: getstatic     #4                  // Field java/lang/System.out:Ljava/io/PrintStream;</span><br><span class=\"line\">      11: aload_1</span><br><span class=\"line\">      12: invokevirtual #5                  // Method math:()I</span><br><span class=\"line\">      15: invokevirtual #6                  // Method java/io/PrintStream.println:(I)V</span><br><span class=\"line\">      18: getstatic     #4                  // Field java/lang/System.out:Ljava/io/PrintStream;</span><br><span class=\"line\">      21: ldc           #7                  // String end</span><br><span class=\"line\">      23: invokevirtual #8                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V</span><br><span class=\"line\">      26: return</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>我们一点点来看这段代码。这段代码对应的就是我们math()方法，左侧的0~12编号，就是说是按从上到下执行的。我把每一行的意思写到注释里。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">public int math();</span><br><span class=\"line\">\t    Code:</span><br><span class=\"line\">\t       0: iconst_1 //将int类型常量1压入栈--操作数栈(一个临时存放操作数的栈)   程序计数器为1(存的是下一条要执行执行代码的地址，可以理解为指针)</span><br><span class=\"line\">\t       </span><br><span class=\"line\">\t       1: istore_1 //将int类型值存入局部变量1,也就是a = 1 --局部变量表,此时操作数栈的常量1出栈   程序计数器为2</span><br><span class=\"line\">\t       </span><br><span class=\"line\">\t       2: iconst_2 //将int类型常量2压入栈--操作数栈   程序计数器为3</span><br><span class=\"line\">\t       </span><br><span class=\"line\">\t       3: istore_2 //将int类型值存入局部变量2,也就是b = 2,此时此时操作数栈的常量2出栈   程序计数器为4</span><br><span class=\"line\">\t       </span><br><span class=\"line\">\t       4: iload_1  //从局部变量1中装载int类型值,也就是把局部变量表中的a=1整体压入到操作数栈中</span><br><span class=\"line\">\t       </span><br><span class=\"line\">\t       5: iload_2  //从局部变量2中装载int类型值,也就是把局部变量表中的b=2也整体压入到操作数栈中</span><br><span class=\"line\">\t       </span><br><span class=\"line\">\t       6: iadd     //执行int类型的加法--先从操作数栈中弹出栈顶元素2，再探出挨着栈顶元素的第二个元素1，做相加2+1，把运算完的结果3重新压入到操作数栈，此时操作数栈中只有元素3</span><br><span class=\"line\">\t       </span><br><span class=\"line\">\t       7: bipush        10   //将一个8位带符号整数压入栈，也就是把10压入到操作数栈，为什么编号没有8?因为我们的10也占了个地址，0~12并不是真正的编号，而是地址的代称，所以我们的程序计数器存的就是地址。</span><br><span class=\"line\">\t       </span><br><span class=\"line\">\t       9: imul     //执行int类型的乘法--和iadd的操作一样，最后操作数栈中只有元素30</span><br><span class=\"line\">\t       </span><br><span class=\"line\">\t      10: istore_3 //将int类型值存入局部变量3，也就是c = 30\t      </span><br><span class=\"line\">\t      11: iload_3  //从局部变量3中装载int类型值，把c = 30压入到操作数栈</span><br><span class=\"line\">\t      </span><br><span class=\"line\">\t      12: ireturn  //从操作数栈中返回int类型的数据</span><br></pre></td></tr></table></figure>\n<p>最后对应如图。<br><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fwh17qawstj31gm0ssq9m.jpg\" alt=\"\"></p>\n<p>实际上，我们main()方法也是有局部变量表，局部变量就是我们的 math对象。方法出口指向我们main()方法。</p>\n<p><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fwh1hw19kdj31gm0t87cb.jpg\" alt=\"\"></p>\n<p><strong>动态链接</strong></p>\n<p>我们现在对于程序计数器、局部变量表、方法出口有了直观的了解，但是动态链接是做什么用的？</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Map&lt;String, String&gt; map = new HashMap&lt;&gt;();</span><br><span class=\"line\">map.put(&quot;test&quot;, &quot;test&quot;);</span><br></pre></td></tr></table></figure>\n<p>我们声明一个map，我们在定义的时候是一个map接口，我们真正调用的时候实际上是HashMap的put方法，这也是多态的特性，我们HashMap也是在堆里，尽管我们变量的类型是一个map接口，map变量最终要找的是HashMap，但hashmap是另外一个类，所以我们需要一个关联，也就是动态链接。</p>\n<hr>\n<h3 id=\"本地方法栈\"><a href=\"#本地方法栈\" class=\"headerlink\" title=\"本地方法栈\"></a>本地方法栈</h3><hr>\n<p>接下来我们讲一下本地方法栈。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">new Thread().start();</span><br></pre></td></tr></table></figure>\n<p>我们都知道，当我们调用线程start()方法时，线程并不是直接启动的，而是让CPU做一个准备，就绪之后才能执行。下面是start()方法的源码，我们可以看出，先定义个started状态为false，当执行完start0()，started状态为true。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">public synchronized void start() &#123;</span><br><span class=\"line\">       /**</span><br><span class=\"line\">        * This method is not invoked for the main method thread or &quot;system&quot;</span><br><span class=\"line\">        * group threads created/set up by the VM. Any new functionality added</span><br><span class=\"line\">        * to this method in the future may have to also be added to the VM.</span><br><span class=\"line\">        *</span><br><span class=\"line\">        * A zero status value corresponds to state &quot;NEW&quot;.</span><br><span class=\"line\">        */</span><br><span class=\"line\">       if (threadStatus != 0)</span><br><span class=\"line\">           throw new IllegalThreadStateException();</span><br><span class=\"line\"></span><br><span class=\"line\">       /* Notify the group that this thread is about to be started</span><br><span class=\"line\">        * so that it can be added to the group&apos;s list of threads</span><br><span class=\"line\">        * and the group&apos;s unstarted count can be decremented. */</span><br><span class=\"line\">       group.add(this);</span><br><span class=\"line\"></span><br><span class=\"line\">       boolean started = false;</span><br><span class=\"line\">       try &#123;</span><br><span class=\"line\">           start0();</span><br><span class=\"line\">           started = true;</span><br><span class=\"line\">       &#125; finally &#123;</span><br><span class=\"line\">           try &#123;</span><br><span class=\"line\">               if (!started) &#123;</span><br><span class=\"line\">                   group.threadStartFailed(this);</span><br><span class=\"line\">               &#125;</span><br><span class=\"line\">           &#125; catch (Throwable ignore) &#123;</span><br><span class=\"line\">               /* do nothing. If start0 threw a Throwable then</span><br><span class=\"line\">                 it will be passed up the call stack */</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<p>我们再去看看start0()方法做了什么。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">private native void start0();</span><br></pre></td></tr></table></figure>\n<p>这个方法看起来好像是个接口，需要实现?    </p>\n<p>这个实际就是本地方法接口，native修饰，他的底层实现是c语言写的，我们java出现的时候是1995年，之前都是c和c++的天下，所以java刚出现时不可能一下子就全部替换，肯定要和c语言写的接口进行交互，所以java就是用这种方式来和c语言接口进行交互。现在这种本地方法使用已经非常少了。<br>当我们调用这个方法时，这个本地方法就是压入到我们的本地方法栈，我们执行引擎就会去调用c语言库，类似于.dll后缀的文件。</p>\n<hr>\n<h3 id=\"方法区\"><a href=\"#方法区\" class=\"headerlink\" title=\"方法区\"></a>方法区</h3><hr>\n<p>到此，线程私有的区域已经全部介绍完了，现在我们来看一下方法区。</p>\n<p><strong>方法区</strong>    </p>\n<p>类的所有字段和方法<font color=\"orange\">字节码</font>，以及一些特殊方法如构造函数，接口代码也在此定义。简单说，所有定义的方法的信息都保存在该区域，<font color=\"orange\">静态变量+常量+类信息(构造方法/接口定义)+运行时常量池</font>都存在方法区中，虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。</p>\n<p><strong>栈+堆+方法区的交互关系</strong></p>\n<p>我们现在知道Java栈中存放着局部变量，当我们创建一个对象时，比如我们new一个Math对象。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Math math1 = new Math();</span><br><span class=\"line\">Math math2 = new Math();</span><br></pre></td></tr></table></figure>\n<p>我们这个Math对象是根据字节码的模板new出来的，math1和math2用的都是同一个Math类模板，而类模板是存放在方法区里的，也就是说，两个math对象的实例数据，都存放在方法区中。在java堆中存放着两个对象指向类模板信息的指针。</p>\n<p><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fwh2iht1tdj30zk0fg76f.jpg\" alt=\"\"></p>\n<p>对应之前的图，就是这个样子。<br><img src=\"https://ws2.sinaimg.cn/large/006tNbRwly1fwh2n0tgl2j31gk0tewn1.jpg\" alt=\"\"><br>但是在方法区里就不是.class文件了啊，在方法区这些静态常量啊之类的都会被模块化的。</p>\n<hr>\n<h3 id=\"堆\"><a href=\"#堆\" class=\"headerlink\" title=\"堆\"></a>堆</h3><hr>\n<p>最后我们简单介绍一下堆，之后的笔记将会针对堆做一系列的分析。</p>\n<p><strong>堆(线程共享)</strong>    </p>\n<p>虚拟机启动时创建，用于存放对象实例，几乎所有的对象（包含常量池）都在堆上分配内存，当对象无法再该空间申请到内存时将抛出<font color=\"red\">OutOfMemoryError</font>异常。同时也是<strong>垃圾收集器管理的主要区域</strong>。可通过 -Xmx –Xms 参数来分别指定最大堆和最小堆。</p>\n<p>我们知道Java栈、本地方法栈、程序计数器是在Java线程里的，一旦线程结束，相应的这些都会被销毁，意味着这三个模块的内存不会占太多，所以我们的垃圾收集器最照顾的就是堆里的内容，其次就是方法区，因此堆占的内存是最多的。</p>\n<p><strong>堆的结构</strong></p>\n<p><img src=\"https://ws2.sinaimg.cn/large/006tNbRwly1fwh2z2ir5qj30zk0bwwfv.jpg\" alt=\"\"></p>\n<p>通过图片最下面的Heap大括号我们可以看出来，一个有三个区域 : Eden(伊甸区)、Survivor Space、Tenured Space。Eden(伊甸区)、Survivor Space组成了我们的新生代，Tenured Space 是我们的老年代，下面的几分之几就是他们在堆上默认所占用的空间。MetaData是元空间，在JDK8出现的，也就是我们的永久代，之前永久代是在堆里面的，我们可以理解元空间就是我们方法区的实现，方法区是抽象的东西。</p>\n<p>我们知道所有的new出来的对象我们都存放在堆中，一开始就是放在Eden区中，程序在运行时，会有不断new出来的对象，Eden总会放满的时候，一放满就会触发轻GC（GC分为轻GC和full GC，full GC对于性能的影响是很大的，要尽量避免），把无用的对象(没有任何引用的对象，没有被任何指针指向的对象)通过垃圾回收器清掉，把还在用的对象放到Suivivor区的From区，周而复始，From区也会满，满的时候依然做轻GC，把From区中无用的清掉，把还在用的放到To区中，这时候，To和From互换了，To变为From区，From区变为To区，当new的对象又放满Eden区时，轻GC之后，还在用的对象就会放到新的From区中，依次轮询。</p>\n<p>可以对轮询设置次数，假如我们设置的是15次，交替15次之后，如果To区域还有存活的对象，在我们做完轻GC之后，就会把这些存活的对象放到老年代，这是程序还在运行，总有一天老年代也会放满，老年代一放满，就会触发full GC。</p>\n<p>早些年当触发full GC时，会执行STW（Stop the world），停止全部业务线程来专门完成full GC。</p>\n<p>普一些概念。</p>\n<p><strong>新生代</strong></p>\n<p>类诞生、成长、消亡的区域，一个类在这里产生，应用，最后被垃圾回收器收集，结束生命。<br>新生区分为两部分： <strong>伊甸区（Eden space）和幸存者区（Survivor pace）</strong> ，所有的类都是在伊甸区被new出来的。幸存区有两个： 0区（Survivor 0 space）和1区（Survivor 1 space）。当伊甸园的空间用完时，程序又需要创建对象，JVM的垃圾回收器将对伊甸园区进行垃圾回收(Minor GC)，将伊甸园区中的不再被其他对象所引用的对象进行销毁。然后将伊甸园中的剩余对象移动到幸存 0区。若幸存 0区也满了，再对该区进行垃圾回收，然后移动到1区。那如果1区也满了呢？</p>\n<p><strong>老年代</strong></p>\n<p>新生区经过多次GC仍然存活的对象移动到老年区。若老年区也满了，那么这个时候将产生MajorGC（FullGC），进行老年区的内存清理。若老年区执行了Full GC之后发现依然无法进行对象的保存，就会产生OOM异常“OutOfMemoryError”</p>\n<p><strong>元数据区</strong></p>\n<p>元数据区：元数据区取代了永久代(jdk1.8以前)，本质和永久代类似，都是对JVM规范中方法区的实现，区别在于元数据区并不在虚拟机中，而是使用本地物理内存，永久代在虚拟机中，永久代逻辑结构上属于堆，但是物理上不属于堆，堆大小=新生代+老年代。元数据区也有可能发生OutOfMemory异常。</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">JDK版本</th>\n<th style=\"text-align:left\"></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">Jdk1.6及之前</td>\n<td style=\"text-align:left\">有永久代, 常量池在方法区</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Jdk1.7</td>\n<td style=\"text-align:left\">有永久代，但已经逐步“去永久代”，常量池在堆</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Jdk1.8及之后</td>\n<td style=\"text-align:left\">无永久代，常量池在元空间</td>\n</tr>\n</tbody>\n</table>\n<p>元数据区的动态扩展，默认–XX:MetaspaceSize值为21MB的高水位线。一旦触及则Full GC将被触发并卸载没有用的类（类对应的类加载器不再存活），然后高水位线将会重置。新的高水位线的值取决于GC后释放的元空间。如果释放的空间少，这个高水位线则上升。如果释放空间过多，则高水位线下降。    </p>\n<p>为什么jdk1.8用元数据区取代了永久代？    </p>\n<p>官方解释：移除永久代是为融合HotSpot JVM与 JRockit VM而做出的努力，因为JRockit没有永久代，不需要配置永久代</p>\n","categories":["虚拟机专题"],"tags":[]},{"title":"Tomcat 生产环境应用","url":"http://ilovenorth.cn/2018/10/18/Tomcat-生产环境应用/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"Tomcat-生产环境应用\"><a href=\"#Tomcat-生产环境应用\" class=\"headerlink\" title=\"Tomcat 生产环境应用\"></a>Tomcat 生产环境应用</h1><p><strong>概要：</strong></p>\n<ol>\n<li>Tomcat各核心组件认知</li>\n<li>Tomcat server.xml 配置详解</li>\n<li>Tomcat IO模型介绍</li>\n</ol>\n<hr>\n<h2 id=\"一-Tomcat各组件认知\"><a href=\"#一-Tomcat各组件认知\" class=\"headerlink\" title=\"一.Tomcat各组件认知\"></a>一.Tomcat各组件认知</h2><hr>\n<p><strong>主要内容：</strong></p>\n<ol>\n<li>Tomcat架构说明</li>\n<li>Tomcat组件及关系详情介绍</li>\n<li>Tomcat启动参数说明</li>\n</ol>\n<h3 id=\"1-Tomcat架构说明\"><a href=\"#1-Tomcat架构说明\" class=\"headerlink\" title=\"1.Tomcat架构说明\"></a>1.Tomcat架构说明</h3><p>Tomcat是一个基于JAVA的WEB容器，其实现了JAVA EE中的 Servlet 与 jsp 规范，与 Nginx apache 服务器不同在于一般用于动态请求处理。在架构设计上采用面向组件的方式设计。即整体功能是通过组件的方式拼装完成。另外每个组件都可以被替换以保证灵活性。<br><img src=\"https://ws2.sinaimg.cn/large/006tNbRwly1fwcezqz9mtg30kr08pdfo.gif\" alt=\"\"></p>\n<h3 id=\"2-Tomcat-各组件及关系\"><a href=\"#2-Tomcat-各组件及关系\" class=\"headerlink\" title=\"2.Tomcat 各组件及关系\"></a>2.Tomcat 各组件及关系</h3><p>从上面的架构图我们可以看出Tomcat的主要组件，下面我们就介绍一下Tomcat各组件。</p>\n<ul>\n<li>Server 和 Service    <ul>\n<li>Server：指Tomcat的服务器。</li>\n<li>Service：指Tomcat的服务，毕竟服务是对外的，那么对外提供服务的介质就是连接器–Connector。</li>\n</ul>\n</li>\n<li>Connector 连接器：帮我们把客户端的请求连接到Tomcat。<ul>\n<li>一个service可以配置多个连接器，每个连接器可以使用不用的端口号：8080/8009。</li>\n<li>PS : 我们会注意到server会对应一个8005的端口，这个一般是运维操作的端口。</li>\n<li>HTTP 1.1：指定连接器承载的Http协议，也可以用AJP协议。</li>\n<li>SSL：https</li>\n<li>AJP（ Apache JServ Protocol）二进制协议，apache 私有协议，用于 apache 反向代理Tomcat。</li>\n</ul>\n</li>\n<li>Container<ul>\n<li>连接器拿到请求后就发送给引擎Engine,Engine又可以把请求丢给多个虚拟机Host</li>\n<li>Engine: 引擎(catalina)，唯一的。 </li>\n<li>Host: 虚拟机，可以配置多个。分发哪个虚拟机是基于域名，分发请求。正常会配置一个默认。</li>\n<li>Context: 隔离各个WEB应用，每个Context的，ClassLoader都是独立。</li>\n</ul>\n</li>\n<li>Component <ul>\n<li>Manager （管理器）</li>\n<li>logger （日志管理）</li>\n<li>loader （载入器）</li>\n<li>pipeline (管道)</li>\n<li>valve （管道中的阀）</li>\n</ul>\n</li>\n</ul>\n<p>和我们的Nginx有一些相似之处，Nginx是从service到localhost到upstream，而Tomcat是从service到localhost到Context。</p>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fwcfcjzwxxj30w00amgmq.jpg\" alt=\"\"></p>\n<h3 id=\"3-Tomcat启动参数说明\"><a href=\"#3-Tomcat启动参数说明\" class=\"headerlink\" title=\"3.Tomcat启动参数说明\"></a>3.Tomcat启动参数说明</h3><p>我们平时启动Tomcat过程是怎么样的？ </p>\n<ol>\n<li>复制WAR包至Tomcat webapp 目录。</li>\n<li>执行starut.bat 脚本启动。</li>\n<li>启动过程中war 包会被自动解压装载。</li>\n</ol>\n<p>但是我们在 Eclipse 或 idea 中启动 WEB 项目的时候，也是把War包复制到 webapps 目录解压吗？显然不是，其真正做法是在Tomcat程序文件之外创建了一个部署目录，在一般生产环境中也是这么做的，即：Tomcat 程序目录和部署目录分开。<br>我们只需要在启动时指定 CATALINA_HOME 与 CATALINA_BASE 参数即可实现。</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\"><strong>启动参数</strong></th>\n<th style=\"text-align:left\"><strong>描述说明</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">JAVA_OPTS</td>\n<td style=\"text-align:left\">jvm 启动参数，设置内存编码等 -Xms100m -Xmx200m -Dfile.encoding=UTF-8</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">JAVA_HOME</td>\n<td style=\"text-align:left\">指定jdk目录，如果未设置，会从java环境变量当中去找。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">CATALINA_HOME</td>\n<td style=\"text-align:left\">Tomcat 程序根目录</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">CATALINA_BASE</td>\n<td style=\"text-align:left\">应用部署目录，默认为$CATALINA_HOME</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">CATALINA_OUT</td>\n<td style=\"text-align:left\">应用日志输出目录：默认$CATALINA_BASE/log</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">CATALINA_TMPDIR</td>\n<td style=\"text-align:left\">应用临时目录：默认：$CATALINA_BASE/temp</td>\n</tr>\n</tbody>\n</table>\n<p>可以编写一个脚本 来实现自定义配置：<br><strong>安装Tomcat</strong><br>1.下载 Tomcat 8.5.34    </p>\n<pre><code>https://tomcat.apache.org/download-80.cgi#8.5.34\n</code></pre><p>2.发送到我们的虚拟机</p>\n<pre><code>scp apache-tomcat-8.5.34.zip root@xxx.xx.xxx.xxx:~\n</code></pre><p>3.解压 apache-tomcat-8.5.34.zip</p>\n<pre><code>unzip apache-tomcat-8.5.34.zip\n</code></pre><p>4.把解压好的目录移动到 /usr/local/</p>\n<pre><code>mv apache-tomcat-8.5.34 /usr/local/\n</code></pre><p>5.我们新建一个 apps 文件夹，一会将我们应用都放到这里</p>\n<pre><code>mkdir apps\npwd: /usr/local/apps\n</code></pre><p>6.在apps文件夹里，创建一个我们的应用文件夹</p>\n<pre><code>mkdir murasakiseifu-web/\n</code></pre><p>7.然后把apache-tomcat-8.5.34文件夹里的conf文件夹拷贝到我们的murasakiseifu-web/文件夹,为了演示，我们把webapps也拷贝进去</p>\n<pre><code>cd /usr/local/apache-tomcat-8.5.34\ncp -r conf ../apps/murasakiseifu-web/\n</code></pre><p>8.我们在murasakiseifu-web/文件夹创建一个logs文件夹</p>\n<pre><code>mkdir logs\n</code></pre><p>9.这样我们就建立好了一个murasakiseifu-web的应用程序部署目录</p>\n<pre><code>conf  logs  webapps\n</code></pre><p><strong>创建自定义脚本</strong></p>\n<p>1.在murasakiseifu-web/文件夹，创建tomcat.sh脚本</p>\n<pre><code>vim tomcat.sh\n</code></pre><p>2.脚本内容<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">#!/bin/bash </span><br><span class=\"line\"># 配置java内存（当然生产环境不可能这么配）</span><br><span class=\"line\">export JAVA_OPTS=&quot;-Xms100m -Xmx200m&quot;</span><br><span class=\"line\"># 指定jdk目录，好处是可以用debug启动Tomcat</span><br><span class=\"line\">export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_144</span><br><span class=\"line\"># 对应Tomcat的部署目录</span><br><span class=\"line\">export CATALINA_HOME=/usr/local/apache-tomcat-8.5.34</span><br><span class=\"line\"># 对应我们程序的部署目录</span><br><span class=\"line\">export CATALINA_BASE=&quot;`pwd`&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">case $1 in</span><br><span class=\"line\">        start)</span><br><span class=\"line\">        $CATALINA_HOME/bin/catalina.sh start</span><br><span class=\"line\">                echo start success!!</span><br><span class=\"line\">        ;;</span><br><span class=\"line\">        stop)</span><br><span class=\"line\">                $CATALINA_HOME/bin/catalina.sh stop</span><br><span class=\"line\">                echo stop success!!</span><br><span class=\"line\">        ;;</span><br><span class=\"line\">        restart)</span><br><span class=\"line\">        $CATALINA_HOME/bin/catalina.sh stop</span><br><span class=\"line\">                echo stop success!!</span><br><span class=\"line\">                sleep 2</span><br><span class=\"line\">        $CATALINA_HOME/bin/catalina.sh start</span><br><span class=\"line\">        echo start success!!</span><br><span class=\"line\">        ;;</span><br><span class=\"line\">        version)</span><br><span class=\"line\">        $CATALINA_HOME/bin/catalina.sh version</span><br><span class=\"line\">        ;;</span><br><span class=\"line\">        configtest)</span><br><span class=\"line\">        $CATALINA_HOME/bin/catalina.sh configtest</span><br><span class=\"line\">        ;;</span><br><span class=\"line\">        esac</span><br><span class=\"line\">exit 0</span><br></pre></td></tr></table></figure></p>\n<p>3.给脚本配置权限</p>\n<pre><code>chmod +x tomcat.sh\n</code></pre><p>4.测试脚本配置是否正确</p>\n<pre><code>./tomcat.sh configtest\nUsing CATALINA_BASE:   /usr/local/apps/murasakiseifu-web\nUsing CATALINA_HOME:   /usr/local/apache-tomcat-8.5.34\nUsing CATALINA_TMPDIR: /usr/local/apps/murasakiseifu-web/temp\nUsing JRE_HOME:        /usr/lib/jvm/jdk1.8.0_144/jre\n......\n</code></pre><p>5.启动</p>\n<pre><code>./tomcat.sh start\nUsing CATALINA_BASE:   /usr/local/apps/murasakiseifu-web\nUsing CATALINA_HOME:   /usr/local/apache-tomcat-8.5.34\nUsing CATALINA_TMPDIR: /usr/local/apps/murasakiseifu-web/temp\nUsing JRE_HOME:        /usr/lib/jvm/jdk1.8.0_144/jre\nUsing CLASSPATH:       /usr/local/apache-tomcat-8.5.34/bin/bootstrap.jar:/usr/local/apache-tomcat-8.5.34/bin/tomcat-juli.jar\nTomcat started.\nstart success!!\n</code></pre><p>6.访问一下</p>\n<pre><code># 应用与应用之间是隔离的，当我们再配置一个应用时，同样可以启动8080端口\ncurl 127.0.0.1:8080\n</code></pre><p>这样建立apps的好处就是我们的log是独立的，conf配置也是独立的，而且当我们要升级Tomcat时，我们只需要升级apache-tomcat-8.5.34就好，这样我们的apps也会升级了。</p>\n<hr>\n<h2 id=\"二-Tomcat-server-xml-配置详解\"><a href=\"#二-Tomcat-server-xml-配置详解\" class=\"headerlink\" title=\"二.Tomcat server.xml 配置详解\"></a>二.Tomcat server.xml 配置详解</h2><hr>\n<p>Server 的基本基本配置：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;Server&gt;</span><br><span class=\"line\">    &lt;Listener /&gt;&lt;!-- 监听器 --&gt;</span><br><span class=\"line\">    &lt;GlobaNamingResources&gt; &lt;!-- 全局资源 --&gt;</span><br><span class=\"line\">    &lt;/GlobaNamingResources</span><br><span class=\"line\">    &lt;Service&gt;          &lt;!-- 服务 用于 绑定 连接器与 Engine --&gt;</span><br><span class=\"line\">        &lt;Connector 8080/&gt; &lt;!-- 连接器--&gt;</span><br><span class=\"line\">        &lt;Connector 8010 /&gt; &lt;!-- 连接器--&gt;</span><br><span class=\"line\">        &lt;Connector 8030/&gt; &lt;!-- 连接器--&gt;</span><br><span class=\"line\">        </span><br><span class=\"line\">        &lt;Engine&gt;      &lt;!-- 执行引擎--&gt;</span><br><span class=\"line\">            &lt;Logger /&gt;</span><br><span class=\"line\">            &lt;Realm /&gt;</span><br><span class=\"line\">               &lt;host &quot;www.tl.com&quot; appBase=&quot;&quot;&gt;  &lt;!-- 虚拟主机--&gt;</span><br><span class=\"line\">                   &lt;Logger /&gt; &lt;!-- 日志配置--&gt;</span><br><span class=\"line\">                   &lt;Context &quot;/luban&quot; path=&quot;&quot;/&gt; &lt;!-- 上下文配置--&gt;</span><br><span class=\"line\">               &lt;/host&gt;</span><br><span class=\"line\">        &lt;/Engine&gt;</span><br><span class=\"line\">    &lt;/Service&gt;</span><br><span class=\"line\">&lt;/Server&gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-参数说明\"><a href=\"#1-参数说明\" class=\"headerlink\" title=\"1.参数说明\"></a>1.参数说明</h3><p><strong>server  </strong><br>root元素：server 的顶级配置<br><strong>主要属性:</strong><br>port：执行关闭命令的端口号<br>shutdown：关闭命令    </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">#基于telent 执行SHUTDOWN 命令即可关闭</span><br><span class=\"line\">telent 127.0.0.1 8005</span><br><span class=\"line\">SHUTDOWN</span><br></pre></td></tr></table></figure>\n<p><strong>service</strong><br>服务：将多个connector与一个Engine组合成一个服务，可以配置多个服务,name属性不重复即可。</p>\n<p><strong>Connector</strong><br>连接器：用于接收 指定协议下的连接 并指定给唯一的Engine 进行处理。<br>主要属性：</p>\n<ul>\n<li>protocol 监听的协议，默认是http/1.1</li>\n<li>port 指定服务器端要创建的端口号</li>\n<li>minSpareThread    服务器启动时创建的处理请求的线程数</li>\n<li>maxThread    最大可以创建的处理请求的线程数</li>\n<li>enableLookups    如果为true，则可以通过调用request.getRemoteHost()进行DNS查询来得到远程客户端的实际主机名，若为false则不进行DNS查询，而是返回其ip地址</li>\n<li>redirectPort    指定服务器正在处理http请求时收到了一个SSL传输请求后重定向的端口号</li>\n<li>acceptCount    指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理</li>\n<li>connectionTimeout    指定超时的时间数(以毫秒为单位)</li>\n<li>SSLEnabled 是否开启 sll 验证，在Https 访问时需要开启。</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"> &lt;Connector port=&quot;8860&quot; protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot;</span><br><span class=\"line\">                connectionTimeout=&quot;20000&quot;</span><br><span class=\"line\">                redirectPort=&quot;8862&quot;</span><br><span class=\"line\">                URIEncoding=&quot;UTF-8&quot;</span><br><span class=\"line\">                useBodyEncodingForURI=&quot;true&quot;</span><br><span class=\"line\">                compression=&quot;on&quot; compressionMinSize=&quot;2048&quot;</span><br><span class=\"line\">compressableMimeType=&quot;text/html,text/xml,text/plain,text/javascript,text/css,application/x-json,application/json,application/x-javascript&quot;</span><br><span class=\"line\">                maxThreads=&quot;1024&quot; minSpareThreads=&quot;200&quot;</span><br><span class=\"line\">                acceptCount=&quot;800&quot;</span><br><span class=\"line\">                enableLookups=&quot;false&quot;</span><br><span class=\"line\">        /&gt;</span><br></pre></td></tr></table></figure>\n<p><strong>Engine</strong><br>引擎：用于处理连接的执行器，默认的引擎是catalina。一个service 中只能配置一个Engine。<br>主要属性：name 引擎名称 defaultHost 默认host</p>\n<p><strong>Host</strong><br>虚拟机：基于域名匹配至指定虚拟机。类似于nginx当中的server,默认的虚拟机是localhost.<br>主要属性：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;Host name=&quot;www.fzz.com&quot;  appBase=&quot;/usr/www/fzz&quot;</span><br><span class=\"line\">            unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;</span><br><span class=\"line\">        &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot;               prefix=&quot;www.fzz.com.access_log&quot; suffix=&quot;.txt&quot;</span><br><span class=\"line\">               pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt;</span><br><span class=\"line\">&lt;/Host&gt;</span><br></pre></td></tr></table></figure>\n<p><strong>Context</strong><br>应用上下文：一个host下可以配置多个Context，每个Context都有其独立的classPath。相互隔离，以免造成ClassPath 冲突。<br>主要属性：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;Context docBase=&quot;hello&quot; path=&quot;/h&quot; reloadable=&quot;true&quot;/&gt;</span><br></pre></td></tr></table></figure>\n<p><strong>Valve</strong><br>阀门：可以理解成request的过滤器，具体配置要基于具体的Valve接口的子类。以下即为一个访问日志的Valve.<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"> &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot;</span><br><span class=\"line\">               prefix=&quot;www.fzz.com.access_log&quot; suffix=&quot;.txt&quot;</span><br><span class=\"line\">               pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt;</span><br></pre></td></tr></table></figure></p>\n<hr>\n<h2 id=\"三-Tomcat-IO模型介绍\"><a href=\"#三-Tomcat-IO模型介绍\" class=\"headerlink\" title=\"三.Tomcat IO模型介绍\"></a>三.Tomcat IO模型介绍</h2><hr>\n<p>主要内容：</p>\n<ol>\n<li>Tomcat支持的IO模型说明</li>\n<li>BIO与NIO的区别</li>\n</ol>\n<h3 id=\"1-Tomcat支持的IO模型说明\"><a href=\"#1-Tomcat支持的IO模型说明\" class=\"headerlink\" title=\"1.Tomcat支持的IO模型说明\"></a>1.Tomcat支持的IO模型说明</h3><table>\n<thead>\n<tr>\n<th style=\"text-align:left\">IO</th>\n<th style=\"text-align:left\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">BIO</td>\n<td style=\"text-align:left\">阻塞式IO，即Tomcat使用传统的java.io进行操作。该模式下每个请求都会创建一个线程，对性能开销大，不适合高并发场景。优点是稳定，适合连接数目小且固定架构。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">NIO</td>\n<td style=\"text-align:left\">非阻塞式IO，jdk1.4 之后实现的新IO。该模式基于多路复用选择器监测连接状态，再通知线程处理，从而达到非阻塞的目的。比传统BIO能更好的支持并发性能。Tomcat 8.0之后默认采用该模式</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">APR</td>\n<td style=\"text-align:left\">全称是 Apache Portable Runtime（Apache可移植运行库），是Apache HTTP服务器的支持库。可以简单地理解为，Tomcat将以JNI的形式调用Apache HTTP服务器的核心动态链接库来处理文件读取，或网络传输操作。使用需要编译安装APR 库</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">AIO</td>\n<td style=\"text-align:left\">异步非阻塞式IO，jdk1.7后之支持 。与nio不同在于不需要多路复用选择器，而是请求处理线程执行完成，进行回调调知，已继续执行后续操作。Tomcat 8之后支持。</td>\n</tr>\n</tbody>\n</table>\n<p><strong>使用指定IO模型的配置方式:</strong><br>配置 server.xml。</p>\n<pre><code>&lt;Connector protocol=&quot;HTTP/1.1&quot;&gt; \n</code></pre><p>默认配置 8.0：protocol=“HTTP/1.1”  8.0之前是BIO，8.0之后是NIO。</p>\n<p><strong>BIO</strong>    </p>\n<pre><code>protocol=“org.apache.coyote.http11.Http11Protocol“\n</code></pre><p><strong>NIO</strong>    </p>\n<pre><code>protocol=”org.apache.coyote.http11.Http11NioProtocol“\n</code></pre><p><strong>AIO</strong>    </p>\n<pre><code>protocol=”org.apache.coyote.http11.Http11Nio2Protocol“\n</code></pre><p><strong>APR</strong>    </p>\n<pre><code>protocol=”org.apache.coyote.http11.Http11AprProtocol“\n</code></pre><h3 id=\"2-BIO与NIO有什么区别\"><a href=\"#2-BIO与NIO有什么区别\" class=\"headerlink\" title=\"2.BIO与NIO有什么区别\"></a>2.BIO与NIO有什么区别</h3><p><strong>在高并发场景下BIO与NIO的线程数的变化</strong><br><strong>演示数据：</strong>    </p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\"></th>\n<th style=\"text-align:left\">每秒提交数</th>\n<th style=\"text-align:left\">BIO执行线程</th>\n<th style=\"text-align:left\">NIO执行线程</th>\n<th style=\"text-align:left\"></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">预测</td>\n<td style=\"text-align:left\">200</td>\n<td style=\"text-align:left\">200</td>\n<td style=\"text-align:left\">50</td>\n<td style=\"text-align:left\"></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">实验环境</td>\n<td style=\"text-align:left\">200</td>\n<td style=\"text-align:left\">48</td>\n<td style=\"text-align:left\">37</td>\n<td style=\"text-align:left\"></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">生产环境</td>\n<td style=\"text-align:left\">200</td>\n<td style=\"text-align:left\">419</td>\n<td style=\"text-align:left\">23</td>\n</tr>\n</tbody>\n</table>\n<p><strong>结论：</strong><br>表格中的线程指的是我们的work业务线程，业务线程就是处理servlet服务代码的线程，我们实验的生产环境是在实验环境的基础上人为阻塞了2s，BIO模型下，work业务线程同样也会阻塞。为了达到200的并发，就会继续创建线程来达到并发量。    </p>\n<p><strong>BIO 线程模型</strong><br><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fwdiqnjbsij30tf0dmq40.jpg\" alt=\"\"><br>当客户端和服务端通过Acceptor建立完连接之后，要交给线程池来处理，也就是work线程，这个work线程除了要处理IO的读和写，还要处理我们的业务执行(数据库的增删改查)，当work处理IO的读和写时，我们在这里阻塞了2s，所以work线程也要阻塞，因为它和IO线程一一对应的。</p>\n<p><strong>NIO 线程模型</strong><br><img src=\"https://ws2.sinaimg.cn/large/006tNbRwly1fwdiqpqdgpj31350fc76n.jpg\" alt=\"\"><br>IO线程和work线程已经分开了，当work线程处理业务时，处理的是IO线程发送过来的已经打包好的Http包，就可以直接从内存里取了。<br>IO线程一直轮询整个请求列表，看哪些请求已经完整过来了。</p>\n","categories":["分布式专题"],"tags":[]},{"title":"Nginx 性能优化时间---性能参数调优","url":"http://ilovenorth.cn/2018/10/17/Nginx-性能优化时间-性能参数调优/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"Nginx-性能参数调优\"><a href=\"#Nginx-性能参数调优\" class=\"headerlink\" title=\"Nginx 性能参数调优\"></a>Nginx 性能参数调优</h1><h2 id=\"1-worker-processes-number\"><a href=\"#1-worker-processes-number\" class=\"headerlink\" title=\"1.worker_processes number\"></a>1.worker_processes number</h2><p>Nginx是多进程单线程的应用。专门处理请求的进程是worker process，处理缓存的进程是cache manager process(只有我们配置了缓存这个进程才会启动)。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@root /]# ps -ef | grep nginx</span><br><span class=\"line\">root      15809      1  0 11:51 ?        00:00:00 nginx: master process sbin/nginx</span><br><span class=\"line\">root      16530  15809  0 15:21 ?        00:00:00 nginx: worker process</span><br><span class=\"line\">root      16531  15809  0 15:21 ?        00:00:00 nginx: cache manager process</span><br></pre></td></tr></table></figure></p>\n<p>当我们请求太多时，我们可以多配几个worker process进程。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 在配置文件的顶部 修改worker_processes参数，默认为1.</span><br><span class=\"line\">worker_processes\t2;</span><br></pre></td></tr></table></figure></p>\n<p>但并不是配的越多越好，worker_processes的数值是根据CPU来决定的，如果你的CPU是双核的，那么worker_processes最好就配置2个。    </p>\n<p>如果你配置了5个worker_processes，那么最多工作时只有两个worker_processes在启用，剩下3个是闲置的状态，并且当请求来的时候，这5个worker_processes会争抢资源，反而会使性能下降。    </p>\n<p><font color=\"orange\"><strong>并不是等于CPU数就是最好的</strong>    </font><br>每个worker进程都是单线程的进程，它们会调用各个模块以实现多种多样的功能。如果这些模块确认不会出现阻塞式的调用，那么，有多少CPU内核就应该配置多少个进程；反之，如果有可能出现阻塞式调用，那么需要配置稍多一些的worker进程。</p>\n<p><font color=\"green\">例如:</font> 如果业务方面会致使用户请求大量读取本地磁盘上的静态资源文件，而且服务器上的内存较小，以至于大部分的请求访问静态资源文件时都必须读取磁盘（磁头的寻址是缓慢的），而不是内存中的磁盘缓存，那么磁盘I/O调用可能会阻塞住worker进程少量时间，进而导致服务整体性能下降。</p>\n<h2 id=\"2-每个worker进程的最大连接数\"><a href=\"#2-每个worker进程的最大连接数\" class=\"headerlink\" title=\"2.每个worker进程的最大连接数\"></a>2.每个worker进程的最大连接数</h2><p>指每个worker最大能接受的请求数。</p>\n<p><strong>语法</strong>：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">worker_connections number;</span><br></pre></td></tr></table></figure></p>\n<p><strong>默认</strong>：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">worker_connections 1024</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"3-绑定Nginx-worker进程到指定的CPU内核\"><a href=\"#3-绑定Nginx-worker进程到指定的CPU内核\" class=\"headerlink\" title=\"3.绑定Nginx worker进程到指定的CPU内核\"></a>3.绑定Nginx worker进程到指定的CPU内核</h2><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">worker_cpu_affinity cpumask[cpumask……]</span><br></pre></td></tr></table></figure>\n<p>为什么要绑定worker进程到指定的CPU内核呢？    </p>\n<p>如下图所示，假定每一个worker进程都是非常繁忙的，如果多个worker进程都在抢同一个CPU，那么这就会出现同步问题。</p>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fwb7u7wnyyj30po0fsq3z.jpg\" alt=\"\"></p>\n<p>如果每一个worker进程都独享一个CPU，就在内核的调度策略上实现了完全的并发。</p>\n<p><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fwb7vry2sjj30py0fyt98.jpg\" alt=\"\"></p>\n<p>例如，如果有4颗CPU内核，就可以进行如下配置    </p>\n<p><font color=\"orange\">注意 worker_cpu_affinity 配置仅对 Linux 操作系统有效。</font><br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">worker_processes 4;\t</span><br><span class=\"line\">worker_cpu_affinity 1000 0100 0010 0001;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"3-Nginx-worker-进程优先级设置\"><a href=\"#3-Nginx-worker-进程优先级设置\" class=\"headerlink\" title=\"3.Nginx worker 进程优先级设置\"></a>3.Nginx worker 进程优先级设置</h2><p><strong>语法</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">worker_priority nice;</span><br></pre></td></tr></table></figure></p>\n<p><strong>默认</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">worker_priority 0;</span><br></pre></td></tr></table></figure></p>\n<p>优先级,由静态优先级和内核,根据进程执行情况所做的动态调整（目前只有±5的调整）共同决定。nice值是进程的静态优先级，它的取值范围是–20～+19，–20是最高优先级，+19是最低优先级。因此，如果用户希望Nginx占有更多的系统资源，那么可以把nice值配置得更小一些，但不建议比内核进程的nice值（通常为–5）还要小。</p>\n<h2 id=\"4-Nginx-worker进程可以打开的最大句柄描述符个数\"><a href=\"#4-Nginx-worker进程可以打开的最大句柄描述符个数\" class=\"headerlink\" title=\"4.Nginx worker进程可以打开的最大句柄描述符个数\"></a>4.Nginx worker进程可以打开的最大句柄描述符个数</h2><p><strong>语法</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">worker_rlimit_nofile limit;</span><br></pre></td></tr></table></figure></p>\n<p><strong>默认</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">无</span><br></pre></td></tr></table></figure></p>\n<p>更改worker进程的最大打开文件数限制。如果没设置的话，这个值为操作系统的限制。设置后你的操作系统和Nginx可以处理比 “ulimit -a” 命令更多的文件，所以把这个值设高，这样 nginx 就不会有“too many open files”问题了。</p>\n<h2 id=\"5-是否打开accept锁\"><a href=\"#5-是否打开accept锁\" class=\"headerlink\" title=\"5.是否打开accept锁\"></a>5.是否打开accept锁</h2><p><strong>语法</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">accept_mutex[on|off]</span><br></pre></td></tr></table></figure></p>\n<p><strong>默认</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">accept_mutext on;</span><br></pre></td></tr></table></figure></p>\n<p>accept_mutex 是 Nginx 的负载均衡锁，当某一个worker进程建立的连接数量达到worker_connections配置的最大连接数的7/8时，会大大地减小该worker进程试图建立新TCP连接的机会，accept锁默认是打开的，如果关闭它，那么建立TCP连接的耗时会更短，但worker进程之间的负载会非常不均衡，因此不建议关闭它。</p>\n<h2 id=\"6-使用accept锁后到真正建立连接之间的延迟时间\"><a href=\"#6-使用accept锁后到真正建立连接之间的延迟时间\" class=\"headerlink\" title=\"6.使用accept锁后到真正建立连接之间的延迟时间\"></a>6.使用accept锁后到真正建立连接之间的延迟时间</h2><p><strong>语法</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">accept_mutex_delay Nms;</span><br></pre></td></tr></table></figure></p>\n<p><strong>默认</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">accept_mutex_delay 500ms;</span><br></pre></td></tr></table></figure></p>\n<p>在使用accept锁后，同一时间只有一个worker进程能够取到accept锁。这个accept锁不是堵塞锁，如果取不到会立刻返回。如果只有一个worker进程试图取锁而没有取到，他至少要等待accept_mutex_delay定义的时间才能再次试图取锁。</p>\n","categories":["分布式专题"],"tags":[]},{"title":"Nginx 性能优化实践---高速缓存","url":"http://ilovenorth.cn/2018/10/17/Nginx-性能优化实践-高速缓存/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"Nginx-高速缓存\"><a href=\"#Nginx-高速缓存\" class=\"headerlink\" title=\"Nginx 高速缓存\"></a>Nginx 高速缓存</h1><hr>\n<h2 id=\"主要内容：\"><a href=\"#主要内容：\" class=\"headerlink\" title=\"主要内容：\"></a>主要内容：</h2><ol>\n<li>缓存案例分析</li>\n<li>Nginx 静态缓存基本配置</li>\n<li>缓存更新</li>\n</ol>\n<h2 id=\"一-案例分析：\"><a href=\"#一-案例分析：\" class=\"headerlink\" title=\"一.案例分析：\"></a><strong>一.案例分析：</strong></h2><pre><code>某电商平台商品详情页需要实现 700+ QPS，如何着手去做？\n</code></pre><p>首先为分析下一个商品详情页有哪些信息</p>\n<p><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fwb29hqilhj31kw10inpd.jpg\" alt=\"\"></p>\n<h5 id=\"对于商品详情页涉及了如下主要服务：\"><a href=\"#对于商品详情页涉及了如下主要服务：\" class=\"headerlink\" title=\"对于商品详情页涉及了如下主要服务： \"></a><strong>对于商品详情页涉及了如下主要服务： </strong></h5><ul>\n<li>商品详情页HTML页面渲染</li>\n<li>价格服务</li>\n<li>促销服务</li>\n<li>库存状态/配送至服务</li>\n<li>广告词服务</li>\n<li>预售/秒杀服务</li>\n<li>评价服务</li>\n<li>试用服务</li>\n<li>推荐服务</li>\n<li>商品介绍服务</li>\n<li>各品类相关的一些特殊服务</li>\n</ul>\n<h4 id=\"解决方案：\"><a href=\"#解决方案：\" class=\"headerlink\" title=\"解决方案：\"></a><strong>解决方案：</strong></h4><ol>\n<li>采用Ajax 动态加载 价格、广告、库存等服务</li>\n<li>采用key value 缓存详情页主体html。<br><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fwb63xb257j30h80ert97.jpg\" alt=\"\"></li>\n</ol>\n<h4 id=\"问题：\"><a href=\"#问题：\" class=\"headerlink\" title=\"问题：\"></a><strong>问题：</strong></h4><pre><code>当达到500QPS 的时候很难继续压测上去。    \n</code></pre><h4 id=\"分析原因：\"><a href=\"#分析原因：\" class=\"headerlink\" title=\"分析原因：\"></a><strong>分析原因</strong>：</h4><p>一个详情页html  主体达平均150 kb  那么在500QPS 已接近千M局域网宽带极限。必须减少内网通信。</p>\n<h4 id=\"基于Nginx-静态缓存的解决方案：\"><a href=\"#基于Nginx-静态缓存的解决方案：\" class=\"headerlink\" title=\"基于Nginx 静态缓存的解决方案：\"></a><strong>基于Nginx 静态缓存的解决方案：</strong></h4><p><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fwb64zn4cfj30na0e33z6.jpg\" alt=\"\"><br>1.用户请求访问详情页<br>2.首先Nginx会请求本地文件，查找静态文件缓存。<br>3.如果缓存没有，再去加载商品详情页，去请求商品详情页服务。<br>4.当我们对页面详情进行更新时，直接去Nginx清楚指定的商品缓存。</p>\n<h2 id=\"二-Nginx-静态缓存基本配置\"><a href=\"#二-Nginx-静态缓存基本配置\" class=\"headerlink\" title=\"二.Nginx 静态缓存基本配置\"></a><strong>二.Nginx 静态缓存基本配置</strong></h2><h4 id=\"1-在http元素模块下添加缓存区声明。\"><a href=\"#1-在http元素模块下添加缓存区声明。\" class=\"headerlink\" title=\"1.在http元素模块下添加缓存区声明。\"></a>1.在http元素模块下添加缓存区声明。</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># proxy_cache_path 缓存路径,在Tomcat(服务器)所在目录中创建</span><br><span class=\"line\"># levels 缓存层级及目录位数 1:2 一级目录存一个字符 二级目录存2个字符</span><br><span class=\"line\"># keys_zone 缓存区内存大小</span><br><span class=\"line\"># inactive 有效期</span><br><span class=\"line\"># max_size 硬盘大小</span><br><span class=\"line\">proxy_cache_path /data/nginx/cache_murasakiseifu levels=1:2 keys_zone=cache_murasakiseifu:500m inactive=20d max_size=1g;</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-为指定location模块设定缓存策略。\"><a href=\"#2-为指定location模块设定缓存策略。\" class=\"headerlink\" title=\"2.为指定location模块设定缓存策略。\"></a>2.为指定location模块设定缓存策略。</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 指定缓存区</span><br><span class=\"line\">proxy_cache cache_murasakiseifu;</span><br><span class=\"line\"># 以全路径md5值做为Key </span><br><span class=\"line\">proxy_cache_key $host$uri$is_args$args;</span><br><span class=\"line\"># 对不同的HTTP状态码设置不同的缓存时间</span><br><span class=\"line\">proxy_cache_valid 200 304 12h;</span><br></pre></td></tr></table></figure>\n<h4 id=\"3-缓存参数详细说明\"><a href=\"#3-缓存参数详细说明\" class=\"headerlink\" title=\"3.缓存参数详细说明\"></a>3.缓存参数详细说明</h4><table>\n<thead>\n<tr>\n<th style=\"text-align:left\">父元素</th>\n<th style=\"text-align:left\">名称</th>\n<th style=\"text-align:left\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">http</td>\n<td style=\"text-align:left\">proxy_cache_path</td>\n<td style=\"text-align:left\">指定缓存区的根路径</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">levels</td>\n<td style=\"text-align:left\">缓存目录层级最高三层，每层1~2个字符表示。如1:1:2 表示三层。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">keys_zone</td>\n<td style=\"text-align:left\">缓存块名称 及内存块大小。如 cache_item:500m 。表示声明一个名为cache_item 大小为500m。超出大小后最早的数据将会被清除。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">inactive</td>\n<td style=\"text-align:left\">最长闲置时间 如:10d 如果一个数据被闲置10天将会被清除</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">max_size</td>\n<td style=\"text-align:left\">缓存区硬盘最大值。超出闲置数据将会被清除</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">location</td>\n<td style=\"text-align:left\">proxy_cache</td>\n<td style=\"text-align:left\">指定缓存区，对应keys_zone 中设置的值</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">proxy_cache_key</td>\n<td style=\"text-align:left\">通过参数拼装缓存key 如：$host$uri$is_args$args 则会以全路径md5值做做为Key</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">proxy_cache_valid</td>\n<td style=\"text-align:left\">为不同的状态码设置缓存有效期</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"三-缓存的清除：\"><a href=\"#三-缓存的清除：\" class=\"headerlink\" title=\"三.缓存的清除：\"></a><strong>三.缓存的清除：</strong></h2><p>当我们更新数据时，需要清除缓存。    </p>\n<pre><code>该功能可以采用第三方模块 ngx_cache_purge 实现。    \n</code></pre><p><strong>为 nginx 添加 ngx_cache_purge 模块</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 下载ngx_cache_purge 模块包 ,这里nginx 版本为1.6.2 purge 对应2.0版</span><br><span class=\"line\">wget http://labs.frickle.com/files/ngx_cache_purge-2.3.tar.gz</span><br><span class=\"line\"># 查看已安装模块</span><br><span class=\"line\">./sbin/nginx -V</span><br><span class=\"line\"># 进入nginx安装包目录 重新安装 --add-module为模块解压的全路径</span><br><span class=\"line\">./configure --prefix=/root/svr/nginx --with-http_stub_status_module --with-http_ssl_module --add-module=/root/svr/nginx/models/ngx_cache_purge-2.0</span><br><span class=\"line\"># 重新编译</span><br><span class=\"line\">make</span><br><span class=\"line\"># 拷贝 安装目录/objs/nginx 文件用于替换原nginx 文件</span><br><span class=\"line\"># 检测查看安装是否成功</span><br><span class=\"line\">nginx -t</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"清除配置：\"><a href=\"#清除配置：\" class=\"headerlink\" title=\"清除配置：\"></a><strong>清除配置：</strong></h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">location ~ /clear(/.*) &#123;</span><br><span class=\"line\">   # 允许访问的IP</span><br><span class=\"line\">   allow           127.0.0.1;</span><br><span class=\"line\">   allow           192.168.0.193;</span><br><span class=\"line\">   # 禁止访问的IP</span><br><span class=\"line\">   deny            all;</span><br><span class=\"line\">   # 配置清除指定缓存区和路径(与proxy_cache_key一至)</span><br><span class=\"line\">   proxy_cache_purge    cache_item $host$1$is_args$args;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>配置好以后 直接访问 ：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 访问生成缓存文件</span><br><span class=\"line\">http://www.fzz.com/?a=1</span><br><span class=\"line\"># 清除生成的缓存,如果指定缓存不存在 则会报404 错误。</span><br><span class=\"line\">http://www.fzz.com/clear/?a=1</span><br></pre></td></tr></table></figure></p>\n","categories":["分布式专题"],"tags":[]},{"title":"Nginx 性能优化实践---反向代理","url":"http://ilovenorth.cn/2018/10/16/Nginx-性能优化实践/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h2 id=\"一、Nginx-反向代理实现\"><a href=\"#一、Nginx-反向代理实现\" class=\"headerlink\" title=\"一、Nginx 反向代理实现\"></a>一、Nginx 反向代理实现</h2><hr>\n<h3 id=\"主要内容：\"><a href=\"#主要内容：\" class=\"headerlink\" title=\"主要内容：\"></a>主要内容：</h3><ol>\n<li>反向代理基本配置</li>\n<li>负载均衡配置与参数解析</li>\n<li>负载均衡算法详解</li>\n</ol>\n<h3 id=\"1-反向代理基本配置\"><a href=\"#1-反向代理基本配置\" class=\"headerlink\" title=\"1. 反向代理基本配置\"></a>1. 反向代理基本配置</h3><p>提问：什么是反向代理其与正向代理有什么区别？    </p>\n<h5 id=\"正向代理的概念：\"><a href=\"#正向代理的概念：\" class=\"headerlink\" title=\"正向代理的概念：\"></a><strong>正向代理的概念：</strong></h5><p>正向代理是指客户端与目标服务器之间增加一个代理服务器，客户端直接访问代理服务器，在由代理服务器访问目标服务器并返回客户端并返回 。这个过程当中客户端需要知道代理服务器地址，并配置连接。</p>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fw9x1jhba1j30il088q2u.jpg\" alt=\"\"></p>\n<h5 id=\"反向代理的概念：\"><a href=\"#反向代理的概念：\" class=\"headerlink\" title=\"反向代理的概念：\"></a><strong>反向代理的概念：</strong></h5><p>反向代理是指 客户端访问目标服务器，在目标服务内部有一个统一接入网关将请求转发至后端真正处理的服务器并返回结果。这个过程当中客户端不需要知道代理服务器地址，代理对客户端而言是透明的。</p>\n<p><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fw9x1s24bjj30iz067t8m.jpg\" alt=\"\"></p>\n<p><strong>PS:</strong> 因为一个端口只能绑定一个进程，如果我们一个服务器，有2个域名网站，如果访问80端口就只能访问其中一个，使用了反向代理，我们可以直接访问8080端口，由代理服务器来选择域名。</p>\n<h5 id=\"反向代理与正向代理的区别\"><a href=\"#反向代理与正向代理的区别\" class=\"headerlink\" title=\"反向代理与正向代理的区别\"></a><strong>反向代理与正向代理的区别</strong></h5><table>\n<thead>\n<tr>\n<th style=\"text-align:left\"></th>\n<th style=\"text-align:left\"><strong>正向代理</strong></th>\n<th style=\"text-align:left\"><strong>反向代理</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">代理服务器位置</td>\n<td style=\"text-align:left\">客户端与服务都能连接的们位置</td>\n<td style=\"text-align:left\">目标服务器内部</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">主要作用</td>\n<td style=\"text-align:left\">屏蔽客户端IP、集中式缓存、解决客户端不能直连服务端的问题。</td>\n<td style=\"text-align:left\">屏蔽服务端内部实现、负载均衡、缓存。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">应用场景</td>\n<td style=\"text-align:left\">爬虫、翻墙、maven 的nexus 服务</td>\n<td style=\"text-align:left\">Nginx 、Apache负载均衡应用</td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"Nginx代理基本配置\"><a href=\"#Nginx代理基本配置\" class=\"headerlink\" title=\"Nginx代理基本配置\"></a><strong>Nginx代理基本配置</strong></h5><p>Nginx 代理只需要配置 location 中配置proxy_pass 属性即可。其指向代理的服务器地址。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 正向代理到 baidu服务</span><br><span class=\"line\">location = /baidu.html &#123;</span><br><span class=\"line\">         proxy_pass http://www.baidu.com;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 反向代理至 本机的8010服务</span><br><span class=\"line\">location /luban/ &#123;</span><br><span class=\"line\">\t # 只是分发到后端的一个 Tomcat服务器</span><br><span class=\"line\">     proxy_pass http://127.0.0.1:8010;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h5 id=\"代理相关参数：\"><a href=\"#代理相关参数：\" class=\"headerlink\" title=\"代理相关参数：\"></a><strong>代理相关参数：</strong></h5><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">proxy_pass           # 代理服务</span><br><span class=\"line\">proxy_redirect off;   # 是否允许重定向</span><br><span class=\"line\">proxy_set_header Host $host; # 传 header 参数至后端服务</span><br><span class=\"line\">proxy_set_header X-Forwarded-For $remote_addr; # 设置request header 即客户端IP 地址</span><br><span class=\"line\">proxy_connect_timeout 90; # 连接代理服务超时时间</span><br><span class=\"line\">proxy_send_timeout 90; # 请求发送最大时间</span><br><span class=\"line\">proxy_read_timeout 90;  # 读取最大时间</span><br><span class=\"line\">proxy_buffer_size 4k; </span><br><span class=\"line\">proxy_buffers 4 32k;</span><br><span class=\"line\">proxy_busy_buffers_size 64k; </span><br><span class=\"line\">proxy_temp_file_write_size 64k;</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-负载均衡配置与参数解析\"><a href=\"#2-负载均衡配置与参数解析\" class=\"headerlink\" title=\"2.负载均衡配置与参数解析\"></a>2.负载均衡配置与参数解析</h3><p>通过 proxy_pass 可以把请求代理至后端服务，但是为了实现更高的负载及性能， 我们的后端服务通常是多个， 这个是时候可以通过upstream模块实现负载均衡。</p>\n<h5 id=\"演示upstream-的实现\"><a href=\"#演示upstream-的实现\" class=\"headerlink\" title=\"演示upstream 的实现\"></a><strong>演示upstream 的实现</strong></h5><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream backend &#123;     </span><br><span class=\"line\">   server 127.0.0.1:8010;</span><br><span class=\"line\">   server 127.0.0.1:8080;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">location / &#123;</span><br><span class=\"line\">          proxy_pass http://backend;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>我们执行 curl 127.0.0.1 命令，nginx会轮询这两个server，而不是随机的。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">147 8010</span><br><span class=\"line\">147 8080</span><br><span class=\"line\">147 8010</span><br><span class=\"line\">147 8080</span><br></pre></td></tr></table></figure></p>\n<h5 id=\"upstream-权重\"><a href=\"#upstream-权重\" class=\"headerlink\" title=\"upstream 权重\"></a><strong>upstream 权重</strong></h5><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream backend &#123;     </span><br><span class=\"line\">   server 127.0.0.1:8010 weight=1;</span><br><span class=\"line\">   server 127.0.0.1:8080 weight=2;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">location / &#123;</span><br><span class=\"line\">          proxy_pass http://backend;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>配置weight权重参数，我们重新执行curl 127.0.0.1 命令，结果如下。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">#第一次会走一遍两个server 然后开始权重轮询</span><br><span class=\"line\">147 8080</span><br><span class=\"line\">147 8010</span><br><span class=\"line\">147 8080</span><br><span class=\"line\">147 8080</span><br><span class=\"line\">147 8010</span><br></pre></td></tr></table></figure></p>\n<h5 id=\"upstream-相关参数\"><a href=\"#upstream-相关参数\" class=\"headerlink\" title=\"upstream 相关参数:\"></a><strong>upstream 相关参数:</strong></h5><ul>\n<li><strong>service：</strong>    反向服务地址 加端口</li>\n<li><strong>weight：</strong>    权重</li>\n<li><strong>max_fails：</strong>    失败多少次 认为主机已挂掉则，踢出</li>\n<li><p><strong>fail_timeout：</strong>    踢出后重新探测时间，当我们的server挂了之后，nginx会一直检测server服务的心跳来确定何时server会重新启动，这样会占用nginx的性能空间，因此我们设置fail_timeout参数，来在规定时间到了之后再检测server服务。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream backend &#123;     </span><br><span class=\"line\">   server 127.0.0.1:8010 weight=1;</span><br><span class=\"line\">   server 127.0.0.1:8080 weight=2 fail_timeout=30s;</span><br><span class=\"line\">   </span><br><span class=\"line\">   server 127.0.0.1:8090 backup;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">location / &#123;</span><br><span class=\"line\">          proxy_pass http://backend;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><strong>backup：</strong>    备用服务，当我们正在用的server挂了，就会启用备用服务。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream backend &#123;     </span><br><span class=\"line\">   server 127.0.0.1:8010 weight=1;</span><br><span class=\"line\">   server 127.0.0.1:8080 weight=2;</span><br><span class=\"line\">   </span><br><span class=\"line\">   server 127.0.0.1:8090 backup;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">location / &#123;</span><br><span class=\"line\">          proxy_pass http://backend;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><strong>max_conns：</strong>    允许最大连接数</p>\n</li>\n<li><strong>slow_start：</strong>    当节点恢复，不立即加入,而是等待 slow_start    后加入服务对列。<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream backend &#123;     </span><br><span class=\"line\">   server 127.0.0.1:8010 weight=1;</span><br><span class=\"line\">   server 127.0.0.1:8080 weight=2 fail_timeout=30s slow_start=30s;</span><br><span class=\"line\">   </span><br><span class=\"line\">   server 127.0.0.1:8090 backup;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">location / &#123;</span><br><span class=\"line\">          proxy_pass http://backend;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"3-upstream-负载均衡算法介绍\"><a href=\"#3-upstream-负载均衡算法介绍\" class=\"headerlink\" title=\"3.upstream 负载均衡算法介绍\"></a><strong>3.upstream 负载均衡算法介绍</strong></h3><ul>\n<li><strong>ll+weight：</strong><br>轮询加权重 (默认) 。  <font color=\"red\">坏处:</font><font color=\"orange\">权重越高轮询次数越多有一个坏处，就是如果权重高的服务器快满了，就会恶性循环。</font></li>\n<li><strong>ip_hash：</strong>    <figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream backend &#123; </span><br><span class=\"line\">   ip_hash;</span><br><span class=\"line\">   server 127.0.0.1:8010;</span><br><span class=\"line\">   server 127.0.0.1:8080;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">location / &#123;</span><br><span class=\"line\">          proxy_pass http://backend;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>基于Hash计算，用于保持session一至性。    </p>\n<p><font color=\"green\"><strong>eg：</strong></font>我们有两个tomcat，当用户第一次登陆，nginx将session记录在Tomcat1，当用户再一次请求时，nginx将请求发送到Tomcat2，因为Tomcat2中没有记录用户session，用户就需要再登陆一次，很显然这种情况是不应该发生的。这时我们就会用<strong>ip_hash</strong>算法，先将用户ip进行hash运算然后对服务器的个数进行取模，我们这里有两个，就是对2取模运行，得到的结果只有0或者1，如果是0，就记录到第一台Tomcat，如果是1，就记录到第二台Tomcat，当用户在一个请求时，就是根据<strong>ip_hash</strong>算法直接找到对应存session状态信息的Tomcat服务器了。    </p>\n<p><font color=\"red\">坏处:</font><font color=\"orange\">如果其中一台Tomcat挂了，就会有50%的用户会话丢失。</font><br><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fwa3gofbbqj30xm0i8t9w.jpg\" alt=\"\"></p>\n<ul>\n<li><strong>url_hash:</strong><br>静态资源缓存，节约存储，加快速度。<br><font color=\"green\"><strong>eg：</strong></font>原理和上面ip_hash一样，如果我们有210T的图片存储，每一个服务器都存210T是很不现实的，最好的是把210T平均分配到服务器上。根据<strong>url_hash</strong>算法，就可以定位。<br><font color=\"red\">坏处:</font><font color=\"orange\">如果其中一台Tomcat挂了……</font><br><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fwa46aunopj30wm0l2gn6.jpg\" alt=\"\"></li>\n<li><strong>least_conn：</strong><br>最少链接（第三方）</li>\n<li><p><strong>least_time ：</strong><br>最小的响应时间,计算节点平均响应时间，然后取响应最快的那个，分配更高权重（第三方）</p>\n</li>\n<li><p><strong>一致性hash</strong><br>因为上述两个hash算法都有一些可能出现坏处，这里我们介绍一下一致性hash，可以尽可能的减少坏处发生时所带来的影响。<br><font color=\"green\"><strong>eg：</strong></font>如图所示，这是一个链路hash，hash值的范围是0~2^23，分布在这个链路hash上，我们的3台Tomcat服务器分布在这个链路上，每个服务器之间我们放置一些虚拟节点，当来了一个url的hash值时，会找到这个hash值在链路上的位置(五角星位置)，然后顺时针沿着这个链路找到最近的虚拟节点，保存在这里，假如第2台Tomcat挂了，也只会影响第2台Tomcat和顺时针最近的虚拟节点之间的数据，将影响降低了很多。<br><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fwa5uglffcj30wi0me770.jpg\" alt=\"\"></p>\n</li>\n</ul>\n","categories":["分布式专题"],"tags":[]},{"title":"Nginx 核心模块与配置实践","url":"http://ilovenorth.cn/2018/10/15/Nginx-核心模块与配置实践/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"Nginx-简介与安装\"><a href=\"#Nginx-简介与安装\" class=\"headerlink\" title=\"Nginx 简介与安装\"></a>Nginx 简介与安装</h1><h2 id=\"1、Nginx简介：\"><a href=\"#1、Nginx简介：\" class=\"headerlink\" title=\"1、Nginx简介：\"></a>1、Nginx简介：</h2><p>Nginx是一个高性能WEB服务器，除它之外Apache、Tomcat、Jetty、IIS，它们都是Web服务器，或者叫做WWW（World Wide Web）服务器，相应地也都具备Web服务器的基本功能。Nginx  相对基它WEB服务有什么优势呢？</p>\n<ol>\n<li>Tomcat、Jetty 面向java语言，先天就是重量级的WEB服务器，其性能与Nginx没有可比性。</li>\n<li>IIS只能在Windows操作系统上运行。Windows作为服务器在稳定性与其他一些性能上都不如类UNIX操作系统，因此，在需要高性能Web服务器的场合下IIS并不占优。</li>\n<li>Apache的发展时期很长，而且是目前毫无争议的世界第一大Web服务器，其有许多优点，如稳定、开源、跨平台等，但它出现的时间太长了，在它兴起的年代，互联网的产业规模远远比不上今天，所以它被设计成了一个重量级的、不支持高并发的Web服务器。在Apache服务器上，如果有数以万计的并发HTTP请求同时访问，就会导致服务器上消耗大量内存，操作系统内核对成百上千的Apache进程做进程间切换也会消耗大量CPU资源，并导致HTTP请求的平均响应速度降低，这些都决定了Apache不可能成为高性能Web服务器，这也促使了Lighttpd和Nginx的出现。 下图可以看出07年到17 年强劲增长势头。<br><img src=\"https://ws2.sinaimg.cn/large/006tNbRwly1fw8rpn1pmdj30i30f4dgq.jpg\" alt=\"\"></li>\n</ol>\n<h2 id=\"2、编译与安装\"><a href=\"#2、编译与安装\" class=\"headerlink\" title=\"2、编译与安装\"></a><strong>2、编译与安装</strong></h2><p><strong>安装环境准备：</strong><br><strong>（1）linux 内核2.6及以上版本:</strong><br>只有2.6之后才支持epool ，在此之前使用select或pool多路复用的IO模型，无法解决高并发压力的问题。通过命令uname -a 即可查看。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">#查看 linux 内核</span><br><span class=\"line\">uname -a</span><br></pre></td></tr></table></figure></p>\n<p><strong>（2）GCC编译器</strong><br>GCC（GNU Compiler Collection）可用来编译C语言程序。Nginx不会直接提供二进制可执行程序,只能下载源码进行编译。</p>\n<p><strong>（3）PCRE库</strong><br>PCRE（Perl Compatible Regular Expressions，Perl兼容正则表达式）是由Philip Hazel开发的函数库，目前为很多软件所使用，该库支持正则表达式。</p>\n<p><strong>（4）zlib库</strong><br>zlib库用于对HTTP包的内容做gzip格式的压缩，如果我们在nginx.conf里配置了gzip on，并指定对于某些类型（content-type）的HTTP响应使用gzip来进行压缩以减少网络传输量。</p>\n<p><strong>（5）OpenSSL开发库</strong><br>如果我们的服务器不只是要支持HTTP，还需要在更安全的SSL协议上传输HTTP，那么就需要拥有OpenSSL了。另外，如果我们想使用MD5、SHA1等散列函数，那么也需要安装它。<br>上面几个库都是Nginx 基础功能所必需的，为简单起见我们可以通过yum 命令统一安装。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">#yum 安装nginx 环境</span><br><span class=\"line\">yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel pcre pcre-devel</span><br></pre></td></tr></table></figure>\n<p><strong>源码获取：</strong><br>nginx 下载页：<a href=\"http://nginx.org/en/download.html\" target=\"_blank\" rel=\"noopener\">http://nginx.org/en/download.html</a> 。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 下载nginx 最新稳定版本</span><br><span class=\"line\">wget http://nginx.org/download/nginx-1.14.0.tar.gz</span><br><span class=\"line\">#解压</span><br><span class=\"line\">tar -zxvf nginx-1.14.0.tar.gz</span><br></pre></td></tr></table></figure></p>\n<p>最简单的安装：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 全部采用默认安装</span><br><span class=\"line\">./configure</span><br><span class=\"line\">make &amp;&amp; make install</span><br></pre></td></tr></table></figure></p>\n<p>执行完成之后 nginx 运行文件 就会被安装在 /usr/local/nginx 下。</p>\n<p>基于参数构建<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module --with-debug</span><br><span class=\"line\">make</span><br><span class=\"line\">进入objs文件夹 会生成nginx文件 我们需要用它替换掉/usr/local/nginx/sbin/下的nginx文件</span><br><span class=\"line\">/usr/local/nginx/sbin/nginx -s stop</span><br><span class=\"line\">cp nginx /usr/local/nginx/sbin/</span><br><span class=\"line\">cp: overwrite `/usr/local/nginx/sbin/nginx&apos;? y</span><br></pre></td></tr></table></figure></p>\n<p><strong>控制命令：</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">#默认方式启动：</span><br><span class=\"line\">./sbin/nginx </span><br><span class=\"line\">#指定配置文件启动 </span><br><span class=\"line\">./sbing/nginx -c /tmp/nginx.conf </span><br><span class=\"line\">#指定nginx程序目录启动</span><br><span class=\"line\">./sbin/nginx -p /usr/local/nginx/</span><br><span class=\"line\"></span><br><span class=\"line\">#快速停止 不管有没有未执行完的请求 直接停止进程</span><br><span class=\"line\">./sbin/nginx -s stop</span><br><span class=\"line\">#优雅停止 等待当前请求执行完 再停止进程</span><br><span class=\"line\">./sbin/nginx -s quit</span><br><span class=\"line\">#检测配置文件是否正确</span><br><span class=\"line\">./sbin/nginx -t</span><br><span class=\"line\"></span><br><span class=\"line\"># 热装载配置文件 在不停止nginx的情况下更新配置文件</span><br><span class=\"line\">./sbin/nginx -s reload</span><br><span class=\"line\"># 重新打开日志文件</span><br><span class=\"line\">./sbin/nginx -s reopen</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"二、Nginx-架构说明\"><a href=\"#二、Nginx-架构说明\" class=\"headerlink\" title=\"二、Nginx 架构说明\"></a>二、Nginx 架构说明</h2><hr>\n<p><strong>Nginx 架构图:</strong><br><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fw8w7tipm3j30q80gbwfh.jpg\" alt=\"\"></p>\n<p><strong>架构说明：</strong><br>1）nginx启动时，会生成两种类型的进程，一个是主进程（Master），一个（windows版本的目前只有一个）和多个工作进程（Worker）。主进程并不处理网络请求，主要负责调度工作进程，也就是图示的三项：加载配置、启动工作进程及非停升级。所以，nginx启动以后，查看操作系统的进程列表，我们就能看到至少有两个nginx进程。</p>\n<p>2）服务器实际处理网络请求及响应的是工作进程（worker），在类unix系统上，nginx可以配置多个worker，而每个worker进程都可以同时处理数以千计的网络请求。    </p>\n<p>3）模块化设计。nginx的worker，包括核心和功能性模块，核心模块负责维持一个运行循环（run-loop），执行网络请求处理的不同阶段的模块功能，如网络读写、存储读写、内容传输、外出过滤，以及将请求发往上游服务器等。而其代码的模块化设计，也使得我们可以根据需要对功能模块进行适当的选择和修改，编译成具有特定功能的服务器。</p>\n<p>4）事件驱动、异步及非阻塞，可以说是nginx得以获得高并发、高性能的关键因素，同时也得益于对Linux、Solaris及类BSD等操作系统内核中事件通知及I/O性能增强功能的采用，如kqueue、epoll及event ports。</p>\n<p><strong>简单说明流程:</strong><br><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fw8w9tfiktj31280kc78n.jpg\" alt=\"\"><br>正常流程：浏览器发送请求—&gt;连接到网卡—&gt;内核从硬盘读取Html文件到内核态—&gt;内核再把文件发送到nginx应用态—&gt;应用态在复制到网卡</p>\n<p>最早的nginx的流程：通过eqoll/select IO模型来完成非阻塞，所有需要I/O操作的进程进入selet队列。nginx会轮询队列是否有I/O进程，如果有，再去硬盘读写。</p>\n<p>现在：如果轮询需要10万个，也是很耗时间的，所以在内核里会增加一个事件，通过AIO的方式，不需要轮询，当有可读可写的I/O时，不通过select，内核自己来通知nginx，nginx在通过进一步的配置，内核态就可以不经过nginx直接到网卡。</p>\n<h2 id=\"三、Nginx-配置与使用\"><a href=\"#三、Nginx-配置与使用\" class=\"headerlink\" title=\"三、Nginx 配置与使用\"></a>三、Nginx 配置与使用</h2><h3 id=\"主要内容\"><a href=\"#主要内容\" class=\"headerlink\" title=\"主要内容\"></a><strong>主要内容</strong></h3><ol>\n<li>配置文件语法格式</li>\n<li>配置第一个静态WEB服务</li>\n<li>配置案例<ol>\n<li>动静分离实现</li>\n<li>防盗链</li>\n<li>多域名站点</li>\n<li>下载限速</li>\n<li>IP 黑名单</li>\n<li>基于user-agent分流</li>\n</ol>\n</li>\n<li>日志配置<h3 id=\"1、配置文件的语法格式：\"><a href=\"#1、配置文件的语法格式：\" class=\"headerlink\" title=\"1、配置文件的语法格式：\"></a><strong>1、配置文件的语法格式：</strong></h3>先来看一个简单的nginx 配置<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">worker_processes  1;</span><br><span class=\"line\">events &#123;</span><br><span class=\"line\">    worker_connections  1024;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">http &#123;</span><br><span class=\"line\">    include       mime.types;</span><br><span class=\"line\">    default_type  application/octet-stream;</span><br><span class=\"line\">    # 开启后 内核态就可以不经过nginx直接发送文件到网卡。</span><br><span class=\"line\">    sendfile        on;</span><br><span class=\"line\">    # 长连接保活时间</span><br><span class=\"line\">    keepalive_timeout  65;</span><br><span class=\"line\">    </span><br><span class=\"line\">    # 代表虚拟机</span><br><span class=\"line\">    server &#123;</span><br><span class=\"line\">    \t# 监听端口(不要重复)</span><br><span class=\"line\">        listen       80;</span><br><span class=\"line\">        # 配置域名</span><br><span class=\"line\">        server_name  localhost;</span><br><span class=\"line\">        # 请求地址</span><br><span class=\"line\">        location / &#123;</span><br><span class=\"line\">            root   html;</span><br><span class=\"line\">            index  index.html index.htm;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        location /nginx_status &#123;</span><br><span class=\"line\">    \t   stub_status on;</span><br><span class=\"line\">    \t   access_log   off;</span><br><span class=\"line\">  \t    &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>上述配置中的events、http、server、location、upstream等属于配置项块。<br>而worker_processes 、worker_connections、include、listen  属于配置项块中的属性。<br>/nginx_status：属于配置块的特定参数参数。其中server块嵌套于http块，其可以直接继承访问Http块当中的参数。<br>| <strong>配置块</strong>   | 名称开头用大口号包裹其对应属性   |<br>|:—-|:—-|<br>| <strong>属性</strong>   | 基于空格切分属性名与属性值，属性值可能有多个项 都以空格进行切分 如：  access_log  logs/host.access.log  main   |<br>| <strong>参数</strong>   | 其配置在 块名称与大括号间，其值如果有多个也是通过空格进行拆   | </p>\n<p>注意 如果配置项值中包括语法符号，比如空格符，那么需要使用单引号或双引号括住配置项值，否则Nginx会报语法错误。例如：<br>    log_format  main  ‘$remote_addr - $remote_user [$time_local] “$request” ‘<br>                     ‘$status $body_bytes_sent “$http_referer” ‘<br>                     ‘“$http_user_agent” “$http_x_forwarded_for”‘;</p>\n<h3 id=\"2、配置第一个静态WEB服务\"><a href=\"#2、配置第一个静态WEB服务\" class=\"headerlink\" title=\"2、配置第一个静态WEB服务\"></a>2、配置第一个静态WEB服务</h3><p>基本配置介绍说明：<br>（1）监听端口<br>语法：listen address：<br>默认：listen 80;<br>配置块：server    </p>\n<p>（2）主机名称<br>语法：server_name name[……];<br>默认：server_name “”;<br>配置块：server<br>server_name后可以跟多个主机名称，如server_name <a href=\"http://www.testweb.com\" target=\"_blank\" rel=\"noopener\">www.testweb.com</a>、download.testweb.com;。 支持通配符与正则</p>\n<p>（3）location<br>语法：location[=|～|～*|^～|@]/uri/{……}<br>配置块：server</p>\n<ol>\n<li>/ 基于uri目录匹配</li>\n<li>=表示把URI作为字符串，以便与参数中的uri做完全匹配。</li>\n<li>～表示正则匹配URI时是字母大小写敏感的。</li>\n<li>～*表示正则匹配URI时忽略字母大小写问题。</li>\n<li>^～表示正则匹配URI时只需要其前半部分与uri参数匹配即可。</li>\n</ol>\n<p><strong>动静分离：</strong></p>\n<ul>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 创建静态站点</li>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 配置 location /static</li>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 配置 ~* .(gif|png|css|js)$ </li>\n</ul>\n<p>基于目录动静分离<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">   server &#123;</span><br><span class=\"line\">        listen 80;</span><br><span class=\"line\">        server_name *.MurasakiSeiFu.com;</span><br><span class=\"line\">        root /usr/www/MurasakiSeiFu;</span><br><span class=\"line\">        location / &#123;</span><br><span class=\"line\">                index MurasakiSeiFu.html;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"># 静态资源配置</span><br><span class=\"line\"># 访问/static/***.jpg</span><br><span class=\"line\">        location /static &#123;</span><br><span class=\"line\"> # 创建static文件夹 然后放入一张图片 在这里指定路径</span><br><span class=\"line\">         alias /usr/www/static;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure></p>\n<p>基于正则动静分离(如果配置正则表达式 最先匹配正则 其次是static 最后是 /)<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">location ~* \\.(gif|jpg|png|css|js)$ &#123;</span><br><span class=\"line\">      root /usr/www/static;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><strong>防盗链配置演示：</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 加入至指定location 即可实现</span><br><span class=\"line\">valid_referers none blocked *.MurasakiSeiFu.com;</span><br><span class=\"line\"> if ($invalid_referer) &#123;</span><br><span class=\"line\">       return 403;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><strong>下载限速：</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">location /download &#123;</span><br><span class=\"line\">    limit_rate 1m;</span><br><span class=\"line\">    limit_rate_after 30m;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><strong>创建IP黑名单: </strong><br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 创建黑名单文件</span><br><span class=\"line\">echo &apos;deny 192.168.0.132;&apos; &gt;&gt; balck.ip</span><br><span class=\"line\">#http 配置块中引入 黑名单文件</span><br><span class=\"line\">include       black.ip;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"3、日志配置：\"><a href=\"#3、日志配置：\" class=\"headerlink\" title=\"3、日志配置：\"></a>3、日志配置：</h3><p><strong>日志格式：</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">log_format  main  &apos;$remote_addr - $remote_user [$time_local]   &quot;$request&quot; &apos;</span><br><span class=\"line\">                     &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;</span><br><span class=\"line\">                  &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;</span><br><span class=\"line\">access_log  logs/access.log  main;</span><br><span class=\"line\">#基于域名打印日志</span><br><span class=\"line\">access_log logs/$host.access.log main;</span><br></pre></td></tr></table></figure></p>\n<p><strong>error日志的设置</strong></p>\n<p>语法：error_log /path/file level;<br>默认：error_log logs/error.log error;<br>level是日志的输出级别，取值范围是debug、info、notice、warn、error、crit、alert、emerg.</p>\n<p><strong>针对指定的客户端输出debug级别的日志</strong><br>语法：<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">debug_connection[IP|CIDR]</span><br><span class=\"line\">events &#123;</span><br><span class=\"line\">\tdebug_connection 192.168.0.147; </span><br><span class=\"line\">\tdebug_connection 10.224.57.0/200;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p><a href=\"https://attachments-cdn.shimo.im/fWYRhqhjvfIxcISK/nginx.conf\" target=\"_blank\" rel=\"noopener\">nginx.conf</a></p>\n","categories":["分布式专题"],"tags":[]},{"title":"Mybatis 自定义拦截器","url":"http://ilovenorth.cn/2018/09/19/Mybatis-自定义拦截器/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>完成一个拦截器，测试每条查询sql的运行时间。</p>\n<h2 id=\"实现\"><a href=\"#实现\" class=\"headerlink\" title=\"实现\"></a>实现</h2><p>完成Mybatis 自定义拦截器，我们需要实现 Interceptor 接口。<br>我们看一下Interceptor接口源码<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">Interceptor</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\">Object <span class=\"title\">intercept</span><span class=\"params\">(Invocation invocation)</span> <span class=\"keyword\">throws</span> Throwable</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\">Object <span class=\"title\">plugin</span><span class=\"params\">(Object target)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">setProperties</span><span class=\"params\">(Properties properties)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>简单的三个接口，我们需要的其实就是前两个，实现接口后重写三个方法。<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Intercepts</span>(&#123;<span class=\"meta\">@Signature</span>(type = Executor<span class=\"class\">.<span class=\"keyword\">class</span>, <span class=\"title\">method</span> </span>= <span class=\"string\">\"query\"</span>, args = &#123;MappedStatement<span class=\"class\">.<span class=\"keyword\">class</span>, <span class=\"title\">Object</span>.<span class=\"title\">class</span>, <span class=\"title\">RowBounds</span>.<span class=\"title\">class</span>, <span class=\"title\">ResultHandler</span>.<span class=\"title\">class</span>&#125;)&#125;)</span></span><br><span class=\"line\"><span class=\"class\">@<span class=\"title\">Component</span></span></span><br><span class=\"line\"><span class=\"class\"><span class=\"title\">public</span> <span class=\"title\">class</span> <span class=\"title\">MybatisInterceptor</span> <span class=\"keyword\">implements</span> <span class=\"title\">Interceptor</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> Logger logger = LoggerFactory.getLogger(MybatisInterceptor<span class=\"class\">.<span class=\"keyword\">class</span>)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">intercept</span><span class=\"params\">(Invocation invocation)</span> <span class=\"keyword\">throws</span> Throwable </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">long</span> start = System.currentTimeMillis();</span><br><span class=\"line\">        <span class=\"comment\">//执行被拦截的sql</span></span><br><span class=\"line\">        Object o = invocation.proceed();</span><br><span class=\"line\">        <span class=\"keyword\">long</span> end = System.currentTimeMillis();</span><br><span class=\"line\">        logger.info(<span class=\"string\">\"当前 query sql耗时：[&#123;&#125;]ms\"</span>, end - start);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> o;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">plugin</span><span class=\"params\">(Object target)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">//要执行拦截的代理对象</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> Plugin.wrap(target, <span class=\"keyword\">this</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setProperties</span><span class=\"params\">(Properties properties)</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\" ========== \"</span> + properties);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"注解\"><a href=\"#注解\" class=\"headerlink\" title=\"注解\"></a>注解</h2><p>我们会发现代码很简单，通过plugin方法拿到代理的目标对象，然后执行拦截方法。<br>其中有两个注解很重要。</p>\n<h3 id=\"Intercepts\"><a href=\"#Intercepts\" class=\"headerlink\" title=\"@Intercepts\"></a>@Intercepts</h3><p>用于表明当前的对象是一个Interceptor</p>\n<h3 id=\"Signature\"><a href=\"#Signature\" class=\"headerlink\" title=\"@Signature\"></a>@Signature</h3><p>则表明要拦截的接口、方法以及对应的参数类型。<br>可以从两个类拦截，首先是咱们例子中的Executor.class，作为执行器，在这里我们能找到所有的sql类型，我们会发现没有insert、delete方法，因为在mybatis中，默认为update。<br><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fvf06s1bonj31kw0v2e82.jpg\" alt=\"\"><br>通过图片我们可以发现，method对应就是拦截接口的接口方法，args对应的就是接口方法需要的参数，通过反射的方式拿到参数。<br>再一个就是从statementHandler执行时进行拦截，在这一步会拿到更多的信息。<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Intercepts</span>(&#123;<span class=\"meta\">@Signature</span>(type = StatementHandler<span class=\"class\">.<span class=\"keyword\">class</span>, <span class=\"title\">method</span> </span>= <span class=\"string\">\"query\"</span>,  args = &#123;Statement<span class=\"class\">.<span class=\"keyword\">class</span>, <span class=\"title\">ResultHandler</span>.<span class=\"title\">class</span>&#125;)</span></span><br></pre></td></tr></table></figure></p>\n<p>参数的选取和之前一样。</p>\n","categories":["Utils"],"tags":[]},{"title":"IOC容器设计理念与源码解读","url":"http://ilovenorth.cn/2018/08/27/IOC容器设计理念与源码解读/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<p><a href=\"https://attachments-cdn.shimo.im/4F3pLR0Mkwgyopi5/Spring_Framework_开发参考手册.chm\" target=\"_blank\" rel=\"noopener\">Spring Framework 开发参考手册.chm</a></p>\n<p>课程概要：</p>\n<ol>\n<li>IOC核心知识点回顾</li>\n<li>IOC 设计原理</li>\n</ol>\n<h2 id=\"一、IOC核心理论回顾\"><a href=\"#一、IOC核心理论回顾\" class=\"headerlink\" title=\"一、IOC核心理论回顾\"></a>一、IOC核心理论回顾</h2><hr>\n<h3 id=\"知识点：\"><a href=\"#知识点：\" class=\"headerlink\" title=\"知识点：\"></a>知识点：</h3><ol>\n<li>Ioc理念概要</li>\n<li>实体Bean的创建</li>\n<li>Bean的基本特性</li>\n<li><p>依赖注入</p>\n<ol>\n<li>set方法注入</li>\n<li>构造方法注入</li>\n<li>自动注入(byName、byType）</li>\n<li>依赖检测<h3 id=\"1、Ioc理论概要\"><a href=\"#1、Ioc理论概要\" class=\"headerlink\" title=\"1、Ioc理论概要\"></a>1、Ioc理论概要</h3>在JAVA的世界中，一个对象A怎么才能调用对象B？通常有以下几种方法。    </li>\n</ol>\n<p>类别 | 描述 | 时间点<br>:—: | :—: | :—:<br>外部传入|构造方法传入|<br>| |属性设置传入|设置对象状态时<br>| |运行时做为参数传入|调用时<br>内部创建|属性中直接创建|创建引用对象时<br>| |初始化方法创建|创建引用对象时<br>| |运行时动态创建|调用时</p>\n</li>\n</ol>\n<p>上表可以看到， 引用一个对象可以在不同地点（其它引用者）、不同时间由不同的方法完成。如果B只是一个非常简单的对象  如直接new B()，怎样都不会觉得复杂，比如你从来不会觉得创建一个String 是一个件复杂的事情。但如果B 是一个有着复杂依赖的Service对象，这时在不同时机引用B将会变得很复杂。</p>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fuo8uy1q29j30r9084glq.jpg\" alt=\"\"><br>无时无刻都要维护B的复杂依赖关系，试想B对象如果项目中有上百过，系统复杂度将会成陪数增加。<br>IOC容器 的出现正是为解决这一问题，其可以将对象的构建方式统一，并且自动维护对象的依赖关系，从而降低系统的实现成本。前提是需要提前对目标对象基于XML进行声明。</p>\n<h3 id=\"2、实体Bean的构建\"><a href=\"#2、实体Bean的构建\" class=\"headerlink\" title=\"2、实体Bean的构建\"></a>2、实体Bean的构建</h3><ol>\n<li>基于Class构建</li>\n<li>构造方法构建</li>\n<li>静态工厂方法创建</li>\n<li>FactoryBean创建</li>\n</ol>\n<p>1、基于ClassName构建<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;bean class=&quot;com.tuling.spring.HelloSpring&quot;&gt;&lt;/bean&gt;</span><br></pre></td></tr></table></figure></p>\n<p>这是最常规的方法，其原理是在spring底层会基于class 属性 通过反射进行构建。</p>\n<p>2、构造方法构建<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;bean class=&quot;com.tuling.spring.HelloSpring&quot;&gt;</span><br><span class=\"line\">    &lt;constructor-arg name=&quot;name&quot; type=&quot;java.lang.String&quot; value=&quot;luban&quot;/&gt;</span><br><span class=\"line\">    &lt;constructor-arg index=&quot;1&quot; type=&quot;java.lang.String&quot; value=&quot;sex&quot; /&gt;</span><br><span class=\"line\">&lt;/bean&gt;</span><br></pre></td></tr></table></figure></p>\n<p> 如果需要基于参数进行构建，就采用构造方法构建，其对应属性如下：<br><strong>name:</strong>构造方法参数变量名称<br><strong>type:</strong>参数类型<br><strong>index:</strong>参数索引，从0开始<br><strong>value:</strong>参数值，spring 会自动转换成参数实际类型值<br><strong>ref:</strong>引用容串的其它对象</p>\n<p>3、静态工厂方法创建<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;bean class=&quot;com.tuling.spring.HelloSpring&quot; factory-method=&quot;build&quot;&gt;</span><br><span class=\"line\">    &lt;constructor-arg name=&quot;type&quot; type=&quot;java.lang.String&quot; value=&quot;B&quot;/&gt;</span><br><span class=\"line\">&lt;/bean&gt;</span><br></pre></td></tr></table></figure></p>\n<p>如果你正在对一个对象进行A/B测试 ，就可以采用静态工厂方法的方式创建，其于策略创建不同的对像或填充不同的属性。<br>该模式下必须创建一个静态工厂方法，并且方法返回该实例，spring 会调用该静态方法创建对象。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">public static HelloSpring build(String type) &#123;</span><br><span class=\"line\">    if (type.equals(&quot;A&quot;)) &#123;</span><br><span class=\"line\">        return new HelloSpring(&quot;luban&quot;, &quot;man&quot;);</span><br><span class=\"line\">    &#125; else if (type.equals(&quot;B&quot;)) &#123;</span><br><span class=\"line\">        return new HelloSpring(&quot;diaocan&quot;, &quot;woman&quot;);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        throw new IllegalArgumentException(&quot;type must A or B&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>4、FactoryBean创建<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;bean class=&quot;com.tuling.spring.LubanFactoryBean&quot; id=&quot;helloSpring123&quot;&gt;&lt;/bean&gt;</span><br></pre></td></tr></table></figure></p>\n<p>指定一个Bean工厂来创建对象，对象构建初始化 完全交给该工厂来实现。配置Bean时指定该工厂类的类名。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">public class LubanFactoryBean implements FactoryBean &#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public Object getObject() throws Exception &#123;</span><br><span class=\"line\">        return new HelloSpring();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public Class&lt;?&gt; getObjectType() &#123;</span><br><span class=\"line\">        return HelloSpring.class;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public boolean isSingleton() &#123;</span><br><span class=\"line\">        return false;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"3、bean的基本特性\"><a href=\"#3、bean的基本特性\" class=\"headerlink\" title=\"3、bean的基本特性\"></a><strong>3、bean的基本特性</strong></h3><ul>\n<li>作用范围</li>\n<li>生命周期</li>\n<li>装载机制</li>\n</ul>\n<p>a、作用范围<br>很多时候Bean对象是无状态的 ，而有些又是有状态的 无状态的对象我们采用单例即可，而有状态则必须是多例的模式，通过scope 即可创建<br>scope=“prototype”<br>scope=“singleton”<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">scope=“prototype</span><br><span class=\"line\">&lt;bean class=&quot;com.tuling.spring.HelloSpring&quot; scope=&quot;prototype&quot;&gt;</span><br><span class=\"line\">&lt;/bean&gt;</span><br></pre></td></tr></table></figure></p>\n<p>如果一个Bean设置成 prototype 我们可以 通过BeanFactoryAware 获取 BeanFactory 对象即可每次获取的都是新对像。</p>\n<p>b、生命周期<br>Bean对象的创建、初始化、销毁即是Bean的生命周期。通过 init-method、destroy-method 属性可以分别指定期构建方法与初始方法。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;bean class=&quot;com.tuling.spring.HelloSpring&quot; init-method=&quot;init&quot; destroy-method=&quot;destroy&quot;&gt;&lt;/bean&gt;</span><br></pre></td></tr></table></figure></p>\n<p>如果觉得麻烦，可以让Bean去实现 InitializingBean.afterPropertiesSet()、DisposableBean.destroy()方法。分别对应 初始和销毁方法</p>\n<p>c、加载机制<br>指示Bean在何时进行加载。设置lazy-init 即可，其值如下：<br>true: 懒加载，即延迟加载<br>false:非懒加载，容器启动时即创建对象<br>default:默认，采用default-lazy-init 中指定值，如果default-lazy-init  没指定就是false<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;</span><br><span class=\"line\">       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span><br><span class=\"line\">       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;</span><br><span class=\"line\">default-lazy-init=&quot;true&quot;&gt;</span><br></pre></td></tr></table></figure></p>\n<p>什么时候使用懒加载？<br>懒加载会容器启动的更快，而非懒加载可以容器启动时更快的发现程序当中的错误 ，选择哪一个就看追求的是启动速度，还是希望更早的发现错误，一般我们会选 择后者。</p>\n<h3 id=\"4、依赖注入\"><a href=\"#4、依赖注入\" class=\"headerlink\" title=\"4、依赖注入\"></a>4、依赖注入</h3><p>试想IOC中如果没有依赖注入，那这个框架就只能帮助我们构建一些简单的Bean，而之前所说的复杂Bean的构建问题将无法解决，spring这个框架不可能会像现在这样成功。 spring 中 ioc 如何依赖注入呢。有以下几种方式：</p>\n<ol>\n<li>set方法注入</li>\n<li>构造方法注入</li>\n<li>自动注入(byName、byType）</li>\n<li>方法注入(lookup-method)</li>\n</ol>\n<p>2、set方法注入<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;bean class=&quot;com.tuling.spring.HelloSpring&quot;&gt;</span><br><span class=\"line\">    &lt;property name=&quot;fine&quot; ref=&quot;fineSpring&quot;/&gt;</span><br><span class=\"line\">&lt;/bean&gt;</span><br></pre></td></tr></table></figure></p>\n<p>3、构造方法注入<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;bean class=&quot;com.tuling.spring.HelloSpring&quot;&gt;</span><br><span class=\"line\">    &lt;constructor-arg name=&quot;fine&quot;&gt;</span><br><span class=\"line\">        &lt;bean class=&quot;com.tuling.spring.FineSpring&quot;/&gt;</span><br><span class=\"line\">    &lt;/constructor-arg&gt;</span><br><span class=\"line\">&lt;/bean&gt;</span><br></pre></td></tr></table></figure></p>\n<p>4、自动注入（byName\\byType\\constructor)<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;bean id=&quot;helloSpringAutowireConstructor&quot; class=&quot;com.tuling.spring.HelloSpring&quot; autowire=&quot;byName&quot;&gt;</span><br><span class=\"line\">&lt;/bean&gt;</span><br></pre></td></tr></table></figure></p>\n<p>byName：基于变量名与bean 名称相同作为依据插入<br>byType：基于变量类别与bean 名称作<br>constructor：基于IOC中bean 与构造方法进行匹配（语义模糊，不推荐）</p>\n<p>5、依赖方法注入(lookup-method)<br>当一个单例的Bean，依赖于一个多例的Bean，用常规方法只会被注入一次，如果每次都想要获取一个全新实例就可以采用lookup-method 方法来实现。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">#编写一个抽像类</span><br><span class=\"line\">public abstract class MethodInject &#123;</span><br><span class=\"line\">    public void handlerRequest() &#123;</span><br><span class=\"line\">      // 通过对该抽像方法的调用获取最新实例</span><br><span class=\"line\">        getFine();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    # 编写一个抽像方法</span><br><span class=\"line\">    public abstract FineSpring getFine();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">// 设定抽像方法实现</span><br><span class=\"line\">&lt;bean id=&quot;MethodInject&quot; class=&quot;com.tuling.spring.MethodInject&quot;&gt;</span><br><span class=\"line\">    &lt;lookup-method name=&quot;getFine&quot; bean=&quot;fine&quot;&gt;&lt;/lookup-method&gt;</span><br><span class=\"line\">&lt;/bean&gt;</span><br></pre></td></tr></table></figure></p>\n<p>该操作的原理是基于动态代理技术，重新生成一个继承至目标类，然后重写抽像方法到达注入目的。<br>前面说所单例Bean依赖多例Bean这种情况也可以通过实现 ApplicationContextAware 、BeanFactoryAware 接口来获取BeanFactory 实例，从而可以直接调用getBean方法获取新实例，推荐使用该方法，相比lookup-method语义逻辑更清楚一些。</p>\n<h2 id=\"二、IOC-设计原理与实现\"><a href=\"#二、IOC-设计原理与实现\" class=\"headerlink\" title=\"二、IOC 设计原理与实现\"></a>二、IOC 设计原理与实现</h2><hr>\n<h3 id=\"知识点：-1\"><a href=\"#知识点：-1\" class=\"headerlink\" title=\"知识点：\"></a>知识点：</h3><p>1、源码学习的目标<br>2、Bean的构建过程<br>3、BeanFactory与ApplicationContext区别</p>\n<h3 id=\"1、源码学习目标：\"><a href=\"#1、源码学习目标：\" class=\"headerlink\" title=\"1、源码学习目标：\"></a>1、源码学习目标：</h3><p>不要为了读书而读书，同样不要为了阅读源码而读源码。没有目的一头扎进源码的黑森林当中很快就迷路了。到时就不是我们读源码了，而是源码‘毒’我们。毕竟一个框架是由专业团队，历经N次版本迭代的产物，我们不能指望像读一本书的方式去阅读它。 所以必须在读源码之前找到目标。是什么呢？<br>大家会想，读源码的目标不就是为了学习吗？这种目标太过抽像，目标无法验证。通常我们会设定两类型目标：一种是对源码进行改造，比如添加修改某些功能，在实现这种目标的过程当中自然就会慢慢熟悉了解该项目。但然这个难度较大，耗费的成本也大。另一个做法是 自己提出一些问题，阅读源码就是为这些问题寻找答案。以下就是我们要一起在源码中寻找答案的问题：</p>\n<ol>\n<li>Bean工厂是如何生产Bean的？</li>\n<li>Bean的依赖关系是由谁解来决的？</li>\n<li>Bean工厂和应用上文的区别？<h3 id=\"2、Bean的构建过程\"><a href=\"#2、Bean的构建过程\" class=\"headerlink\" title=\"2、Bean的构建过程\"></a>2、Bean的构建过程</h3>spring.xml  文件中保存了我们对Bean的描述配置，BeanFactory 会读取这些配置然后生成对应的Bean。这是我们对ioc 原理的一般理解。但在深入一些我们会有更多的问题？</li>\n<li>配置信息最后是谁JAVA中哪个对象承载的？</li>\n<li>这些承载对象是谁业读取XML文件并装载的？</li>\n<li>这些承载对象又是保存在哪里？</li>\n</ol>\n<p><strong>BeanDefinition （Bean定义）</strong><br>ioc 实现中 我们在xml 中描述的Bean信息最后 都将保存至BeanDefinition （定义）对象中，其中xml bean 与BeanDefinition 程一对一的关系。<br><img src=\"https://ws2.sinaimg.cn/large/006tNbRwly1fuo8w0fohnj30ex08h74q.jpg\" alt=\"\"></p>\n<p>由此可见，xml  bean中设置的属性最后都会体现在BeanDefinition中。如:<br>| <strong>XML-bean </strong>   | <strong>BeanDefinition</strong>   |<br>|:—-|:—-|<br>|  class   | beanClassName   |<br>| scope   | scope   |<br>| lazy-init | lazyInit   |<br>| constructor-arg   | ConstructorArgument   |<br>| property   | MutablePropertyValues   |<br>| factory-method   | factoryMethodName   |<br>| destroy-method   | AbstractBeanDefinition.destroyMethodName   |<br>| init-method   | AbstractBeanDefinition.initMethodName   |<br>| autowire   | AbstractBeanDefinition.autowireMode   |<br>| id   |    |<br>| name   |    | </p>\n<ul>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 演示查看 BeanDefinition 属性结构</li>\n</ul>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fuo90i9jbpj30dd054jra.jpg\" alt=\"\"></p>\n<p><strong>BeanDefinitionRegistry（Bean注册器）</strong><br>在上表中我们并没有看到 xml bean 中的 id  和name属性没有体现在定义中，原因是ID 其作为当前Bean的存储key注册到了BeanDefinitionRegistry 注册器中。name 作为别名key 注册到了 AliasRegistry 注册中心。其最后都是指向其对应的BeanDefinition。</p>\n<ul>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 演示查看 BeanDefinitionRegistry属性结构</li>\n</ul>\n<p><img src=\"https://ws2.sinaimg.cn/large/006tNbRwly1fuo91jbelmj30ej0clglv.jpg\" alt=\"\"></p>\n<p><strong>BeanDefinitionReader（Bean定义读取）</strong><br>至此我们学习了 BeanDefinition 中存储了Xml Bean信息，而BeanDefinitionRegister 基于ID和name 保存了Bean的定义。接下要学习的是从xml Bean到BeanDefinition 然后在注册至BeanDefinitionRegister 整个过程。<br><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fuo92y28t9j30k109zt9b.jpg\" alt=\"\"></p>\n<p>上图中可以看出Bean的定义是由BeanDefinitionReader 从xml 中读取配置并构建出 BeanDefinitionReader,然后在基于别名注册到BeanDefinitionRegister中。</p>\n<ul>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 查看BeanDefinitionReader结构</li>\n</ul>\n<p><img src=\"https://ws3.sinaimg.cn/large/006tNbRwly1fuo94l1j2pj30da079q30.jpg\" alt=\"\"><br>方法说明：</p>\n<ul>\n<li><strong>loadBeanDefinitions(Resource resource) </strong><ul>\n<li>基于资源装载Bean定义并注册至注册器</li>\n</ul>\n</li>\n<li><strong>int loadBeanDefinitions(String location)</strong><ul>\n<li>基于资源路径装载Bean定义并注册至注册器</li>\n</ul>\n</li>\n<li><strong>BeanDefinitionRegistry getRegistry()</strong><ul>\n<li>获取注册器</li>\n</ul>\n</li>\n<li><strong>ResourceLoader getResourceLoader()</strong><ul>\n<li>获取资源装载器</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 基于示例演示BeanDefinitionReader装载过程<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">//创建一个简单注册器</span><br><span class=\"line\">BeanDefinitionRegistry register = new SimpleBeanDefinitionRegistry();</span><br><span class=\"line\">//创建bean定义读取器</span><br><span class=\"line\">BeanDefinitionReader reader = new XmlBeanDefinitionReader(register);</span><br><span class=\"line\">// 创建资源读取器</span><br><span class=\"line\">DefaultResourceLoader resourceLoader = new DefaultResourceLoader();</span><br><span class=\"line\">// 获取资源</span><br><span class=\"line\">Resource xmlResource = resourceLoader.getResource(&quot;spring.xml&quot;);</span><br><span class=\"line\">// 装载Bean的定义</span><br><span class=\"line\">reader.loadBeanDefinitions(xmlResource);</span><br><span class=\"line\">// 打印构建的Bean 名称</span><br><span class=\"line\">System.out.println(Arrays.toString(register.getBeanDefinitionNames());</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p><strong>Beanfactory(bean 工厂)</strong><br> 有了Bean的定义就相当于有了产品的配方，接下来就是要把这个配方送到工厂进行生产了。在ioc当中Bean的构建是由BeanFactory 负责的。其结构如下：<br><img src=\"https://ws1.sinaimg.cn/large/006tNbRwly1fuo95fjpbdj30d60al0sy.jpg\" alt=\"\"><br>方法说明：</p>\n<ul>\n<li><strong>getBean(String) </strong><ul>\n<li>基于ID或name 获取一个Bean</li>\n</ul>\n</li>\n<li><strong><t> T getBean(Class<t> requiredType) </t></t></strong><ul>\n<li>基于Bean的类别获取一个Bean（如果出现多个该类的实例，将会报错。但可以指定 primary=“true” 调整优先级来解决该错误 ）</li>\n</ul>\n</li>\n<li><strong>Object getBean(String name, Object… args)</strong><ul>\n<li>基于名称获取一个Bean，并覆盖默认的构造参数</li>\n</ul>\n</li>\n<li><strong>boolean isTypeMatch(String name, Class&lt;?&gt; typeToMatch)</strong><ul>\n<li>指定Bean与指定Class 是否匹配</li>\n</ul>\n</li>\n</ul>\n<p>以上方法中重点要关注getBean，当用户调用getBean的时候就会触发 Bean的创建动作，其是如何创建的呢？</p>\n<ul>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 演示基本BeanFactory获取一个Bean<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">#创建Bean堆栈</span><br><span class=\"line\">// 其反射实例化Bean</span><br><span class=\"line\">java.lang.reflect.Constructor.newInstance(Unknown Source:-1)</span><br><span class=\"line\">BeanUtils.instantiateClass()</span><br><span class=\"line\">//基于实例化策略 实例化Bean</span><br><span class=\"line\">SimpleInstantiationStrategy.instantiate()</span><br><span class=\"line\">AbstractAutowireCapableBeanFactory.instantiateBean()</span><br><span class=\"line\">// 执行Bean的实例化方法</span><br><span class=\"line\">AbstractAutowireCapableBeanFactory.createBeanInstance()</span><br><span class=\"line\">AbstractAutowireCapableBeanFactory.doCreateBean()</span><br><span class=\"line\">// 执行Bean的创建</span><br><span class=\"line\">AbstractAutowireCapableBeanFactory.createBean()</span><br><span class=\"line\">// 缓存中没有，调用指定Bean工厂创建Bean</span><br><span class=\"line\">AbstractBeanFactory$1.getObject()</span><br><span class=\"line\">// 从单例注册中心获取Bean缓存</span><br><span class=\"line\">DefaultSingletonBeanRegistry.getSingleton()</span><br><span class=\"line\">AbstractBeanFactory.doGetBean()</span><br><span class=\"line\">// 获取Bean</span><br><span class=\"line\">AbstractBeanFactory.getBean()</span><br><span class=\"line\">// 调用的客户类</span><br><span class=\"line\">com.tuling.spring.BeanFactoryExample.main()</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p><strong>Bean创建时序图：</strong><br><img src=\"https://ws4.sinaimg.cn/large/006tNbRwly1fuo96eb3k4j30z90foq3x.jpg\" alt=\"\"></p>\n<p>从调用过程可以总结出以下几点：</p>\n<ol>\n<li>调用BeanFactory.getBean() 会触发Bean的实例化。</li>\n<li>DefaultSingletonBeanRegistry 中缓存了单例Bean</li>\n<li>Bean的创建与初始化是由AbstractAutowireCapableBeanFactory 完成的。<h3 id=\"3、BeanFactory-与-ApplicationContext区别\"><a href=\"#3、BeanFactory-与-ApplicationContext区别\" class=\"headerlink\" title=\"3、BeanFactory 与 ApplicationContext区别\"></a>3、BeanFactory 与 ApplicationContext区别</h3>BeanFactory  看下去可以去做IOC当中的大部分事情，为什么还要去定义一个ApplicationContext 呢？<br>ApplicationContext 结构图<br><img src=\"https://ws2.sinaimg.cn/large/006tNbRwly1fuo9701kg8j315407qwem.jpg\" alt=\"\"></li>\n</ol>\n<p>从图中可以看到 ApplicationContext 它由BeanFactory接口派生而来，因而提供了BeanFactory所有的功能。除此之外context包还提供了以下的功能：</p>\n<ol>\n<li>MessageSource, 提供国际化的消息访问</li>\n<li>资源访问，如URL和文件</li>\n<li>事件传播，实现了ApplicationListener接口的bean</li>\n<li>载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的web层</li>\n</ol>\n","categories":["源码分析"],"tags":[]},{"title":"泛型程序设计","url":"http://ilovenorth.cn/2018/08/08/泛型程序设计/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>使用泛型程序设计，意味着编写的代码可以被很多不同类型的对象所重用。例如，一个ArrayList类可以聚集任何类型的对象。这是一个泛型程序设计的实例。</p>\n<h3 id=\"参数类型的好处\"><a href=\"#参数类型的好处\" class=\"headerlink\" title=\"参数类型的好处\"></a>参数类型的好处</h3><p>在Java增加泛型类之前，泛型式的程序设计是通过继承来实现的。例如，早先的ArrayList类只维护一个Object引用的数组。<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ArrayList</span> </span>&#123;\t</span><br><span class=\"line\">\t<span class=\"keyword\">private</span> Object[] elementData;\t</span><br><span class=\"line\">\t· · ·\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">get</span><span class=\"params\">(<span class=\"keyword\">int</span> i)</span> </span>&#123;...&#125;\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">add</span><span class=\"params\">(Obejct o)</span> </span>&#123;...&#125;\t</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>这种方法有两个问题    </p>\n<ul>\n<li>当获取一个值时必须进行强制类型转换</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">ArrayList files = <span class=\"keyword\">new</span> ArrayList();</span><br><span class=\"line\">...</span><br><span class=\"line\">String fileName = (String) files.get(<span class=\"number\">0</span>);</span><br></pre></td></tr></table></figure>\n<ul>\n<li>没有错误检查，可以向数组列表中添加任何类的对象</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">files.add(<span class=\"keyword\">new</span> File(<span class=\"string\">\"...\"</span>));</span><br></pre></td></tr></table></figure>\n<p>对于这个调用，java在编译和运行的时候都不会报错。但是，如果在其他地方调用的时候，若将get的结果强制转换为String类型时，就会产生错误了。<br>针对此种情况，泛型变提供了一个更好的解决方案：使用参数类型。<br>ArrayList类有一个类型参数，用来指定存储元素的类型：<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">ArrayList&lt;String&gt; files = <span class=\"keyword\">new</span> ArrayList&lt;String&gt;();</span><br></pre></td></tr></table></figure></p>\n<p>这个特性，使得代码可读性很强。并且编译器会很好的用这个信息，当调用get方法时，不用强制类型转换，编译器就会知道返回值类型为String，而不是Obejct。</p>\n<h2 id=\"定义简单泛型类\"><a href=\"#定义简单泛型类\" class=\"headerlink\" title=\"定义简单泛型类\"></a>定义简单泛型类</h2><p>一个泛型类就是具有一个或多个类型变量的类。我们简单举一个例子。<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Pair</span>&lt;<span class=\"title\">T</span>&gt; </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> T first;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> T second;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Pair</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        first = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        second = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Pair</span><span class=\"params\">(T first, T second)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.first = first;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.second = second;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> T <span class=\"title\">getFirst</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> first;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setFirst</span><span class=\"params\">(T first)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.first = first;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> T <span class=\"title\">getSecond</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> second;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setSecond</span><span class=\"params\">(T second)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.second = second;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n","categories":[],"tags":[]},{"title":"Git 底层原理","url":"http://ilovenorth.cn/2018/08/01/Git基本概念与核心命令掌握/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h2 id=\"Git-存储对象\"><a href=\"#Git-存储对象\" class=\"headerlink\" title=\"Git 存储对象\"></a>Git 存储对象</h2><p>Git 是一个内容寻址存储系统，其核心部分是一个简单的键值对数据库(KEY-VALUE DATA STORE),你可以向数据库插入任意内容，它会返回一个用于取回该值的hash键。<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">λ murasakiseifu [~/git] at  master ✔</span><br><span class=\"line\">→ <span class=\"built_in\">echo</span> <span class=\"string\">'hello world'</span> | git <span class=\"built_in\">hash</span>-object -w --stdin</span><br><span class=\"line\">3b18e512dba79e4c8300dd08aeb37f8e728b8dad</span><br></pre></td></tr></table></figure></p>\n<p>当我们把存入任意内容时，都会为该内容生成一个hash值。我们可以通过这个hash值来获取其对应的内容。<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">λ murasakiseifu [~/git] at  master ✔</span><br><span class=\"line\">→ git cat-file -p 3b18e512dba79e4c8300dd08aeb37f8e728b8dad</span><br><span class=\"line\">hello world</span><br></pre></td></tr></table></figure></p>\n<p>Git 基于该功能，把每个文件的版本中内容都保存在数据库中，当要进行版本回滚的时候就通过其中一个键将期取回并替换。</p>\n<p>所以我们平常用的 git add 其实就是把修改之后的内容 插入到键值库中。当我们执行 git add README.MF 等同于执行了 git hash-object -w README.MF 把文件写到数据库中。</p>\n<p>我们解决了存储的问题，但其只能存储内容同并没有存储文件名，如果要进行回滚 怎么知道哪个内容对应哪个文件呢？接下要讲的就是树对象，它解决了文件名存储的问题 。</p>\n<h2 id=\"Git-树对象\"><a href=\"#Git-树对象\" class=\"headerlink\" title=\"Git 树对象\"></a>Git 树对象</h2><p>树对像解决了文件名的问题，它的目的将多个文件名组织在一起，其内包含多个文件名称与其对应的Key和其它树对像的用引用，可以理解成操作系统当中的文件夹，一个文件夹包含多个文件和多个其它文件夹。<br><img src=\"https://ws1.sinaimg.cn/large/0069RVTdly1ftu6oskha9j31h60j6tbx.jpg\" alt=\"\"><br>每一次提交，都会生成一个hash值，这个我们已经知道了。当我们提交的是一个带路径的对象时，比如 如图所示的 src/man/com/hello.java ，git 会为每一个路径文件夹建立一个hash值，类似我们java中的链表一样，通过对于hash值的判断，我们可以知道我们文件在何时提交的，可以用作回滚等操作。</p>\n<p>每一个分支当中都关联了一个树对像，他存储了当前分支下所有的文件名及对应的 key。<br>通过以下命令即可查看分指树。<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">λ murasakiseifu [src/man/hi.txt] at  master ✔</span><br><span class=\"line\">→ git cat-file -p master^&#123;tree&#125;</span><br><span class=\"line\">100644 blob 31e0fce560e96c8b357f5b8630c7d8fbeb0a3ec8\thello.txt</span><br><span class=\"line\">040000 tree 85537e99ded58c97e62560f7f26644db5723da20\tsrc</span><br></pre></td></tr></table></figure></p>\n<p>其中我们可以看到 hello.txt为TXT格式的文档，所以显示了它的文件类型，文件类型为blob，而src为一个文件夹，所以git采用树对象的形式来存储，并会为每一个文件夹生成一个Key，并且文件类型为tree，也就是顶级树对象。</p>\n<h2 id=\"Git-提交对象\"><a href=\"#Git-提交对象\" class=\"headerlink\" title=\"Git 提交对象\"></a>Git 提交对象</h2><p>一次提交即为当前版本的一个快照，该快照就是通过提交对像进行保存，其存储的内容为：一个顶级树对象、上一次提交的对像啥希、提交者用户名及邮箱、提交时间戳、提交评论。<br><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ git cat-file -p b2395925b5f1c12bf8cb9602f05fc8d580311836</span><br><span class=\"line\">tree 002adb8152f7cd49f400a0480ef2d4c09b060c07</span><br><span class=\"line\">parent 8be903f5e1046b851117a21cdc3c80bdcaf97570</span><br><span class=\"line\">author murasakeseifu &lt;murasakeseifu@gmail.com&gt;</span><br><span class=\"line\">committer murasakeseifu &lt;murasakeseifu@gmail.com&gt;</span><br></pre></td></tr></table></figure></p>\n<p>通过上面的知识，我们可以推测出从修改一个文件到提交的过程总共生成了三个对像：<br>一个内容对象 ==&gt; 存储了文件内容<br>一个树对像 ==&gt; 存储了文件名及内容对像的key<br>一个提交对像 ==&gt; 存储了树对像的key 及提交评论。    </p>\n<h2 id=\"Git-引用\"><a href=\"#Git-引用\" class=\"headerlink\" title=\"Git 引用\"></a>Git 引用</h2><p>当我们执行 git branch {branchName} 时创建了一个分支，其本质就是在git 基于指定提交创建了一个引用文件，保存在 .git\\refs\\heads\\ 下。<br>git branch dev<br>cat.git\\refs\\heads\\dev<br>git 总共 有三种类型的引用：</p>\n<ol>\n<li>分支引用</li>\n<li>远程分支引用</li>\n<li>标签引用</li>\n</ol>\n","categories":[],"tags":[]},{"title":"Mysql 通过sql批量插入10万条数据","url":"http://ilovenorth.cn/2018/07/10/Mysql-通过sql批量插入10万条数据/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>最近在做数据同步中间件项目，老大希望测试同步10万条数据的准确性，特此记录一下sql。</p>\n<h2 id=\"SQL\"><a href=\"#SQL\" class=\"headerlink\" title=\"SQL\"></a>SQL</h2><ul>\n<li>开始创建一个函数</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">delimiter ;;</span><br><span class=\"line\">create procedure myproc ()</span><br><span class=\"line\"></span><br><span class=\"line\">begin</span><br><span class=\"line\">declare num int ;</span><br><span class=\"line\">set num = 1 ;</span><br><span class=\"line\">while num &lt; 100000 do</span><br><span class=\"line\">    insert into demo_20180423 (id, value)</span><br><span class=\"line\">values</span><br><span class=\"line\">    (num, num) ;</span><br><span class=\"line\">set num = num + 1 ;</span><br><span class=\"line\">end</span><br><span class=\"line\">while ;</span><br><span class=\"line\">end;;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>执行函数</li>\n</ul>\n<figure class=\"highlight sql\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">call</span> myproc();</span><br></pre></td></tr></table></figure>\n<ul>\n<li>删除函数</li>\n</ul>\n<figure class=\"highlight sql\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">drop</span> <span class=\"keyword\">procedure</span> myproc;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>上图<br><img src=\"https://ws1.sinaimg.cn/large/006tNc79ly1ft4woyrx3tj31gs0qk0vf.jpg\" alt=\"\"><br><img src=\"https://ws4.sinaimg.cn/large/006tNc79ly1ft4wpkj39mj31gs0w0tao.jpg\" alt=\"\"></li>\n</ul>\n<p>还是很方便的，就是有点点慢。</p>\n","categories":["Utils"],"tags":[]},{"title":"Springboot 统一异常拦截处理","url":"http://ilovenorth.cn/2018/04/24/Springboot-统一异常拦截处理/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>我们在做项目的时候，在请求处理中发生错误是非常常见的情况。Spring Boot提供了一个默认的映射：/error，当处理中抛出异常之后，会转到该请求中处理，并且该请求有一个全局的错误页面用来展示异常内容。虽然，Spring Boot中实现了默认的error映射，但是在实际应用中，对用户来说并不够友好，需要去实现我们自己的异常拦截处理。</p>\n<h2 id=\"ControllerAdvice\"><a href=\"#ControllerAdvice\" class=\"headerlink\" title=\"@ControllerAdvice\"></a>@ControllerAdvice</h2><p>在完成统一异常处理之前，我们先看一下核心注解<strong> @ControllerAdvice。</strong><br>点进去我们看一下源码和注释，大致翻译一下：</p>\n<ul>\n<li><strong>@ControllerAdvice</strong>是一个<strong>@Component</strong>，用于定义<strong>@ExceptionHandler</strong>，<strong>@InitBinder</strong>和<strong>@ModelAttribute</strong>方法，适用于所有使用<strong>@RequestMapping</strong>方法。</li>\n<li>具有<strong>@ControllerAdvice</strong>的类可以显式的声明为Spring的bean，或者通过类路径扫描可以自动检测出来。 所有这些bean都遵循<strong>@Order</strong>，并在运行时按此顺序应用。 </li>\n<li>为了处理异常，将在第一个通知中选择一个{@Exception @ HandHandler}，并使用匹配的异常处理程序方法。 对于模型属性和初始化，@code @ModelAttribute和@InitBinder}方法也将遵循{@code @ControllerAdvice}顺序。</li>\n</ul>\n<p>但其实，配合@ExceptionHandler最有用，其它两个不常用。</p>\n<h2 id=\"自定义异常类\"><a href=\"#自定义异常类\" class=\"headerlink\" title=\"自定义异常类\"></a>自定义异常类</h2><p>spring 对于 RuntimeException 异常才会进行事务回滚。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BaseException</span> <span class=\"keyword\">extends</span> <span class=\"title\">RuntimeException</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> serialVersionUID = <span class=\"number\">6626868446456726497L</span>;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> String messageCode;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> String messageInformation;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> String exceptionSource;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">BaseException</span><span class=\"params\">(String messageCode, String messageInformation)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(messageCode + <span class=\"string\">\",\"</span> + messageInformation);</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.messageCode = messageCode;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.messageInformation = messageInformation;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">//get and set</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"全局异常处理类\"><a href=\"#全局异常处理类\" class=\"headerlink\" title=\"全局异常处理类\"></a>全局异常处理类</h2><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@ControllerAdvice</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">GlobalExceptionHandler</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> Logger logger = LoggerFactory.getLogger(GlobalExceptionHandler<span class=\"class\">.<span class=\"keyword\">class</span>)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@ExceptionHandler</span>(Exception<span class=\"class\">.<span class=\"keyword\">class</span>)</span></span><br><span class=\"line\"><span class=\"class\">    @<span class=\"title\">ResponseBody</span></span></span><br><span class=\"line\"><span class=\"class\">    <span class=\"title\">public</span> <span class=\"title\">Map</span> <span class=\"title\">inspector</span>(<span class=\"title\">Exception</span> <span class=\"title\">exception</span>, <span class=\"title\">HttpServletRequest</span> <span class=\"title\">request</span>, <span class=\"title\">HttpServletResponse</span> <span class=\"title\">response</span>) </span>&#123;</span><br><span class=\"line\">        Map map = <span class=\"keyword\">new</span> HashMap();</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (exception <span class=\"keyword\">instanceof</span> BaseException) &#123;</span><br><span class=\"line\">            logger.info(exception.getMessage(), exception);</span><br><span class=\"line\">            BaseException e = (BaseException) exception;</span><br><span class=\"line\">            map.put(<span class=\"string\">\"messageCode\"</span>, Integer.valueOf(e.getMessageCode() != <span class=\"keyword\">null</span> ? e.getMessageCode() : <span class=\"string\">\"0\"</span>);</span><br><span class=\"line\">            map.put(<span class=\"string\">\"messageInformation\"</span>, e.getMessage());</span><br><span class=\"line\">            <span class=\"keyword\">return</span> map;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            ...</span><br><span class=\"line\">        &#125; </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n","categories":["Springboot"],"tags":[]},{"title":"Springboot mybatis复制表结构和数据到指定表","url":"http://ilovenorth.cn/2018/04/23/Springboot-mybatis复制表结构和数据到指定表/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>在项目中新增了一个功能：</p>\n<pre><code>明天凌晨2点启动定时器，删除前天以前的数据，删除的数据转移到新的表中 \n名称=表名_yyyyMMdd  时间为当前时间。\n</code></pre><p>看到这个功能，首先我们得知道mysql中复制表结构和数据的语句怎么写。</p>\n<h2 id=\"复制表结构和数据的语句\"><a href=\"#复制表结构和数据的语句\" class=\"headerlink\" title=\"复制表结构和数据的语句\"></a>复制表结构和数据的语句</h2><h3 id=\"复制表结构及数据到新表-第一种\"><a href=\"#复制表结构及数据到新表-第一种\" class=\"headerlink\" title=\"复制表结构及数据到新表 第一种\"></a>复制表结构及数据到新表 第一种</h3><figure class=\"highlight sql\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> 新表 <span class=\"keyword\">SELECT</span> * <span class=\"keyword\">FROM</span> 旧表</span><br></pre></td></tr></table></figure>\n<p>这一条语句就可以搞定复制表表结构和数据到新表，但是这种方法的一个最不好的地方就是新表中没有旧表的字段属性。比如primary key、auto等。<br>而且，这条语句如果直接执行会报一个错误：</p>\n<pre><code>MYSQL Statement violates GTID consistency: CREATE TABLE ... SELECT. 错误代码： 1786 问题\n</code></pre><p>解决办法<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">在 my.cnf 中将</span><br><span class=\"line\">gtid_mode = ON</span><br><span class=\"line\">enforce_gtid_consistency = ON</span><br><span class=\"line\"></span><br><span class=\"line\">改为</span><br><span class=\"line\"></span><br><span class=\"line\">gtid_mode = OFF</span><br><span class=\"line\">enforce_gtid_consistency = OFF</span><br></pre></td></tr></table></figure></p>\n<p>一般我们是没有这种DBA权限的，所以这种方法我们pass。</p>\n<h3 id=\"复制表结构及数据到新表-第二种\"><a href=\"#复制表结构及数据到新表-第二种\" class=\"headerlink\" title=\"复制表结构及数据到新表 第二种\"></a>复制表结构及数据到新表 第二种</h3><p>没法一条语句就过，我们就得用两条语句来分别执行。</p>\n<h4 id=\"只复制表结构到新表\"><a href=\"#只复制表结构到新表\" class=\"headerlink\" title=\"只复制表结构到新表\"></a>只复制表结构到新表</h4><figure class=\"highlight sql\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">create</span> <span class=\"keyword\">table</span> <span class=\"keyword\">new</span>表 <span class=\"keyword\">like</span> <span class=\"keyword\">old</span>表</span><br></pre></td></tr></table></figure>\n<h4 id=\"复制旧表的数据到新表-当两个表结构一样\"><a href=\"#复制旧表的数据到新表-当两个表结构一样\" class=\"headerlink\" title=\"复制旧表的数据到新表(当两个表结构一样)\"></a>复制旧表的数据到新表(当两个表结构一样)</h4><figure class=\"highlight sql\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">insert</span> <span class=\"keyword\">into</span> <span class=\"keyword\">new</span>表 <span class=\"keyword\">select</span> * <span class=\"keyword\">from</span> <span class=\"keyword\">old</span>表 <span class=\"keyword\">where</span> ...</span><br></pre></td></tr></table></figure>\n<h2 id=\"mybatis\"><a href=\"#mybatis\" class=\"headerlink\" title=\"mybatis\"></a>mybatis</h2><p>最好是能在一次调用时就把这两条语句都执行了，mybatis也为我们提供了这个方法。<br>首先，在jdbc连接串上我们需要加上allowMultiQueries=true<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">jdbc:mysql://127.0.0.1:3306/test?allowMultiQueries=true</span><br></pre></td></tr></table></figure></p>\n<p>然后在xml文件里，用“;”隔开两个sql语句就可以啦。<br><figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!-- 复制表结构和数据到新表 --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">update</span> <span class=\"attr\">id</span>=<span class=\"string\">\"createTable\"</span>&gt;</span></span><br><span class=\"line\">    create table $&#123;mrJobTasksMonitorName&#125; like mr_job_tasks_monitor;</span><br><span class=\"line\">    insert into $&#123;mrJobTasksMonitorName&#125; select * from mr_job_tasks_monitor where monitor_date <span class=\"symbol\">&amp;lt;</span> #&#123;newDate&#125;;</span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">update</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"${} #{}\"></a>${} #{}</h2><p>#{} 这种取值是编译好SQL语句再取值<br>${} 这种是取值以后再去编译SQL语句 一般用于传入数据库对象，比如表名。</p>\n<h2 id=\"mapper\"><a href=\"#mapper\" class=\"headerlink\" title=\"mapper\"></a>mapper</h2><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * 复制表结构和数据到新表</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@param</span> mrNodesScheduleName</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@param</span> newDate</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">createTable</span><span class=\"params\">(@Param(<span class=\"string\">\"mrNodesScheduleName\"</span>)</span> String mrNodesScheduleName, </span></span><br><span class=\"line\"><span class=\"function\">                 @<span class=\"title\">Param</span><span class=\"params\">(<span class=\"string\">\"newDate\"</span>)</span> String newDate)</span>;</span><br></pre></td></tr></table></figure>\n<p>核心内容就是这些了，配合定时器就可以完成这个功能了。</p>\n","categories":["Springboot"],"tags":[]},{"title":"Util:java对日期date类运算","url":"http://ilovenorth.cn/2018/04/23/Util-java对日期date类运算/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<p>项目中需要对日期进行运算，定期删除一些不再需要的监控日志，所以自己也是研究了一下日期运算，后来决定自己写一个工具类，可以自由的使用时间格式，可以返回String类型和Date类型，可以简单对一些月日年进行加减运算，正数就是加，负数就是减，第一次些工具类，哪里写的不好，还希望大家多多指正！时分秒也很简单，根据需要大家可以自行加上~<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> java.text.ParseException;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.text.SimpleDateFormat;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.Calendar;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.Date;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@author</span> MurasakiSeiFu</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DateMathUtils</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> String PATTERN_LONG_DAY = <span class=\"string\">\"yyyy-MM-dd\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> String PATTERN_SHORT_DAY = <span class=\"string\">\"yyyyMMdd\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> String PATTERN_LONG_MONTH = <span class=\"string\">\"yyyy-MM\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> String PATTERN_SHORT_MONTH = <span class=\"string\">\"yyyyMM\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> String PATTERN_LONG_SECOND = <span class=\"string\">\"yyyy-MM-dd HH:mm:ss\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> String PATTERN_LONG_MILLISECOND = <span class=\"string\">\"yyyy-MM-dd HH:mm:ss:SSS\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 日期格式转化</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> pattern</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> date</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> Date <span class=\"title\">parseDate</span><span class=\"params\">(String pattern, String date)</span> </span>&#123;</span><br><span class=\"line\">        SimpleDateFormat sdf = <span class=\"keyword\">new</span> SimpleDateFormat(pattern);</span><br><span class=\"line\">        Date d = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            d = sdf.parse(date);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (ParseException e) &#123;</span><br><span class=\"line\">            e.printStackTrace();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> d;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 日期运算</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> date</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> calendarType</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> account</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> Date <span class=\"title\">mathDate</span><span class=\"params\">(Date date, <span class=\"keyword\">int</span> calendarType, <span class=\"keyword\">int</span> account)</span> </span>&#123;</span><br><span class=\"line\">        Calendar calendar = Calendar.getInstance();</span><br><span class=\"line\">        calendar.setTime(date);</span><br><span class=\"line\">        calendar.add(calendarType, account);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> calendar.getTime();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获取加减年份后的日期 String</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> pattern</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> date</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> year</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> String <span class=\"title\">dateAddYears</span><span class=\"params\">(String pattern, String date, <span class=\"keyword\">int</span> year)</span> </span>&#123;</span><br><span class=\"line\">        SimpleDateFormat sdf = <span class=\"keyword\">new</span> SimpleDateFormat(pattern);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> sdf.format(mathDate(parseDate(pattern, date), Calendar.YEAR, year));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获取加减年份后的日期 Date</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> date</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> year</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> Date <span class=\"title\">dateAddYears</span><span class=\"params\">(Date date, <span class=\"keyword\">int</span> year)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> mathDate(date, Calendar.YEAR, year);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获取加减月份后的日期 String</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> pattern</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> date</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> month</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> String <span class=\"title\">dateAddMonths</span><span class=\"params\">(String pattern, String date, <span class=\"keyword\">int</span> month)</span> </span>&#123;</span><br><span class=\"line\">        SimpleDateFormat sdf = <span class=\"keyword\">new</span> SimpleDateFormat(pattern);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> sdf.format(mathDate(parseDate(pattern, date), Calendar.MONTH, month));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获取加减月份后的日期 Date</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> date</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> month</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> Date <span class=\"title\">dateAddMonths</span><span class=\"params\">(Date date, <span class=\"keyword\">int</span> month)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> mathDate(date, Calendar.MONTH, month);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获取加减天数后的日期 String</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> pattern</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> date</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> day</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> String <span class=\"title\">dateAddDays</span><span class=\"params\">(String pattern, String date, <span class=\"keyword\">int</span> day)</span> </span>&#123;</span><br><span class=\"line\">        SimpleDateFormat sdf = <span class=\"keyword\">new</span> SimpleDateFormat(pattern);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> sdf.format(mathDate(parseDate(pattern, date), Calendar.DAY_OF_YEAR, day));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获取加减天数后的日期 Date</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> date</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> day</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> Date <span class=\"title\">dateAddDays</span><span class=\"params\">(Date date, <span class=\"keyword\">int</span> day)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> mathDate(date, Calendar.DAY_OF_YEAR, day);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获取加减分钟后的日期 String</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> pattern</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> date</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> minute</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> String <span class=\"title\">dateAddMinutes</span><span class=\"params\">(String pattern, String date, <span class=\"keyword\">int</span> minute)</span> </span>&#123;</span><br><span class=\"line\">        SimpleDateFormat sdf = <span class=\"keyword\">new</span> SimpleDateFormat(pattern);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> sdf.format(mathDate(parseDate(pattern, date), Calendar.MINUTE, minute));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获取加减分钟后的日期 Date</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> date</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> minute</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> Date <span class=\"title\">dateAddMinutes</span><span class=\"params\">(Date date, <span class=\"keyword\">int</span> minute)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> mathDate(date, Calendar.MINUTE, minute);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>源码：<a href=\"https://github.com/MurasakiSeiFu/Util\" target=\"_blank\" rel=\"noopener\">Java 日期date类运算</a></p>\n","categories":["Utils"],"tags":[]},{"title":"Springboot 初始化加载菜单","url":"http://ilovenorth.cn/2018/04/20/Springboot-初始化加载菜单/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<p>实际应用中，我们会有在项目服务启动的时候就去加载一些数据或做一些事情这样的需求。比如我们一直在做的这个菜单，就在项目启动的时候把数据提前加载到静态变量里。</p>\n<h2 id=\"MenuUtils\"><a href=\"#MenuUtils\" class=\"headerlink\" title=\"MenuUtils\"></a>MenuUtils</h2><p>依然是准备工作，我们先完成初始加载时需要的数据。基本思路也就是在这个工具类里把获取到的数据库数据存放到静态变量里，在加载的时候执行它就可以了~<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MenuUtils</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">protected</span> Logger logger = LoggerFactory.getLogger(<span class=\"keyword\">this</span>.getClass());</span><br><span class=\"line\">    <span class=\"comment\">// 存放菜单的静态变量:ROLE_MENU</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> Map&lt;String, CMenu&gt; ROLE_MENU = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> MenuUtils instance;</span><br><span class=\"line\">    <span class=\"comment\">// 实例化 MenuUtils</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> MenuUtils <span class=\"title\">getInstance</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (instance == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            instance = <span class=\"keyword\">new</span> MenuUtils();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> instance;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// 初始化</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">init</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        logger.info(<span class=\"string\">\"MenuUtils init\"</span>);</span><br><span class=\"line\">        loadRoleMenu();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">void</span> <span class=\"title\">loadRoleMenu</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        CMenuService cMenuService = ApplicationContextUtil.getBean(CMenuServiceImpl<span class=\"class\">.<span class=\"keyword\">class</span>)</span>;</span><br><span class=\"line\">        CRoleService cRoleService = ApplicationContextUtil.getBean(CRoleServiceImpl<span class=\"class\">.<span class=\"keyword\">class</span>)</span>;</span><br><span class=\"line\">        <span class=\"comment\">// 查询所有角色</span></span><br><span class=\"line\">        List&lt;CRole&gt; roles = cRoleService.findAll();</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (CRole cRole : roles) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 根据不同角色生成菜单树</span></span><br><span class=\"line\">            CMenu cMenu = cMenuService.menuTree(cRole.getRoleCode());</span><br><span class=\"line\">            ROLE_MENU.put(cRole.getRoleCode(), cMenu);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>ApplicationContextUtil 是我们自己封装的一个工具类，用来获取Bean的实例。就在这里:<a href=\"/2018/04/19/Util-Springboot类beans获取/\">ApplicationContextUtil</a><br>cMenuService.menuTree 是我们根据角色获取菜单的接口，在这里:<a href=\"/2018/04/20/springboot-根据角色权限生成菜单树/\">cMenuService.menuTree</a></p>\n<h2 id=\"如何启动加载数据\"><a href=\"#如何启动加载数据\" class=\"headerlink\" title=\"如何启动加载数据\"></a>如何启动加载数据</h2><p>Springboot为我们提供了一个接口：CommandLineRunner<br>我们点进去看看源码和注释。<br>简单翻译一下：用来表示一个bean被包含在一个SpringApplication中时应该运行的接口。 多个CommandLineRunner bean可以在同一个应用程序上下文中定义，并且可以使用Ordered接口或@Order注解进行排序。<br>我们只需要重写这个run方法，就可以使我们这个bean在程序启动时就能加载了，并且如果有多个实现CommandLineRunner的实现类，可以用@Order注解进行排序，数字越小优先级越高。<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">CommandLineRunner</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">\t * Callback used to run the bean.</span></span><br><span class=\"line\"><span class=\"comment\">\t * <span class=\"doctag\">@param</span> args incoming main method arguments</span></span><br><span class=\"line\"><span class=\"comment\">\t * <span class=\"doctag\">@throws</span> Exception on error</span></span><br><span class=\"line\"><span class=\"comment\">\t */</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">(String... args)</span> <span class=\"keyword\">throws</span> Exception</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"完成我们的初始化工具类\"><a href=\"#完成我们的初始化工具类\" class=\"headerlink\" title=\"完成我们的初始化工具类\"></a>完成我们的初始化工具类</h2><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Component</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">StoredDataInit</span> <span class=\"keyword\">implements</span> <span class=\"title\">CommandLineRunner</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">protected</span> Logger logger = LoggerFactory.getLogger(<span class=\"keyword\">this</span>.getClass());</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">(String... args)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">        logger.info(<span class=\"string\">\"MenuUtils run...\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            MenuUtils.getInstance().init();</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">            logger.error(<span class=\"string\">\"MenuUtils run...error!!!!\"</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>打上断点 ，我们就会发现，在启动完成前，就会加载我们的StoredDataInit了。<br>我们也会好奇是在什么时候加载的~<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@SpringBootApplication</span></span><br><span class=\"line\"><span class=\"meta\">@MapperScan</span>(<span class=\"string\">\"com.datas.manager.core.mapper\"</span>)</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ManagerBootApplication</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> Logger LOGGER = LoggerFactory.getLogger(ManagerBootApplication<span class=\"class\">.<span class=\"keyword\">class</span>)</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">        SpringApplication app = <span class=\"keyword\">new</span> SpringApplication(ManagerBootApplication<span class=\"class\">.<span class=\"keyword\">class</span>)</span>;</span><br><span class=\"line\">        app.setBannerMode(Banner.Mode.OFF);</span><br><span class=\"line\">        <span class=\"comment\">// 就是在这步之后哦！</span></span><br><span class=\"line\">        ConfigurableApplicationContext context = app.run(args);</span><br><span class=\"line\"></span><br><span class=\"line\">        ....</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>我们现在完成了所有关于菜单以及角色权限菜单的工作，接着就要开始完成我们的登录了!</p>\n","categories":["Springboot"],"tags":[]},{"title":"springboot 根据角色权限生成菜单树","url":"http://ilovenorth.cn/2018/04/20/springboot-根据角色权限生成菜单树/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<p>在之前我们已经完成了通过递归的方式生成菜单树：<a href=\"/2018/04/18/springboot-登录技巧/\">递归生成菜单树</a>,然而在登录功能中，不可能所有用户的菜单权限都一样，因此在这基础上，我们要完成权限菜单的功能。</p>\n<h2 id=\"准备数据\"><a href=\"#准备数据\" class=\"headerlink\" title=\"准备数据\"></a>准备数据</h2><p>我们需要两张表，权限表和权限菜单关联表。加上之前的菜单表，现在我们已经有3张表了。</p>\n<h3 id=\"角色表\"><a href=\"#角色表\" class=\"headerlink\" title=\"角色表\"></a>角色表</h3><figure class=\"highlight sql\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> <span class=\"string\">`c_role`</span> (</span><br><span class=\"line\">  <span class=\"string\">`id`</span> <span class=\"built_in\">BIGINT</span>(<span class=\"number\">20</span>) <span class=\"keyword\">NOT</span> <span class=\"literal\">NULL</span> AUTO_INCREMENT <span class=\"keyword\">COMMENT</span> <span class=\"string\">'主键'</span>,</span><br><span class=\"line\">  <span class=\"string\">`role_code`</span> <span class=\"built_in\">VARCHAR</span>(<span class=\"number\">100</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'角色编号'</span>,</span><br><span class=\"line\">  <span class=\"string\">`role_name`</span> <span class=\"built_in\">VARCHAR</span>(<span class=\"number\">100</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'角色名称'</span>,</span><br><span class=\"line\">  <span class=\"string\">`sort`</span> <span class=\"built_in\">INT</span>(<span class=\"number\">5</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"string\">'0'</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'角色排序'</span>,</span><br><span class=\"line\">  <span class=\"string\">`iscancel`</span> <span class=\"built_in\">INT</span>(<span class=\"number\">2</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"string\">'0'</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'是否作废'</span>,</span><br><span class=\"line\">  <span class=\"string\">`type`</span> <span class=\"built_in\">INT</span>(<span class=\"number\">5</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"string\">'1'</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'类型'</span>,</span><br><span class=\"line\">  <span class=\"string\">`state`</span> <span class=\"built_in\">INT</span>(<span class=\"number\">5</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"string\">'1'</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'状态'</span>,</span><br><span class=\"line\">  <span class=\"string\">`remark`</span> <span class=\"built_in\">VARCHAR</span>(<span class=\"number\">200</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'备注'</span>,</span><br><span class=\"line\">  PRIMARY <span class=\"keyword\">KEY</span> (<span class=\"string\">`id`</span>)</span><br><span class=\"line\">) <span class=\"keyword\">ENGINE</span>=<span class=\"keyword\">INNODB</span> AUTO_INCREMENT=<span class=\"number\">5</span> <span class=\"keyword\">DEFAULT</span> <span class=\"keyword\">CHARSET</span>=utf8 <span class=\"keyword\">COMMENT</span>=<span class=\"string\">'角色表'</span>;</span><br></pre></td></tr></table></figure>\n<h4 id=\"初始化角色表\"><a href=\"#初始化角色表\" class=\"headerlink\" title=\"初始化角色表\"></a>初始化角色表</h4><figure class=\"highlight sql\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">INSERT</span>  <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role`</span>(<span class=\"string\">`id`</span>,<span class=\"string\">`role_code`</span>,<span class=\"string\">`role_name`</span>,<span class=\"string\">`sort`</span>,<span class=\"string\">`iscancel`</span>,<span class=\"string\">`type`</span>,<span class=\"string\">`state`</span>,<span class=\"string\">`remark`</span>) <span class=\"keyword\">VALUES</span> </span><br><span class=\"line\">(<span class=\"number\">1</span>,<span class=\"string\">'A0001'</span>,<span class=\"string\">'超级管理员'</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"string\">'超级管理员'</span>),</span><br><span class=\"line\">(<span class=\"number\">2</span>,<span class=\"string\">'A0002'</span>,<span class=\"string\">'普通管理员'</span>,<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"string\">'普通管理员'</span>),</span><br><span class=\"line\">(<span class=\"number\">3</span>,<span class=\"string\">'B0001'</span>,<span class=\"string\">'监控观察者'</span>,<span class=\"number\">2</span>,<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"string\">'观察者'</span>),</span><br><span class=\"line\">(<span class=\"number\">4</span>,<span class=\"string\">'C0001'</span>,<span class=\"string\">'访客'</span>,<span class=\"number\">4</span>,<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"string\">'访客'</span>);</span><br></pre></td></tr></table></figure>\n<h3 id=\"角色菜单关联表\"><a href=\"#角色菜单关联表\" class=\"headerlink\" title=\"角色菜单关联表\"></a>角色菜单关联表</h3><figure class=\"highlight sql\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> <span class=\"string\">`c_role_menu`</span> (</span><br><span class=\"line\">  <span class=\"string\">`id`</span> <span class=\"built_in\">BIGINT</span>(<span class=\"number\">20</span>) <span class=\"keyword\">NOT</span> <span class=\"literal\">NULL</span> AUTO_INCREMENT <span class=\"keyword\">COMMENT</span> <span class=\"string\">'主键'</span>,</span><br><span class=\"line\">  <span class=\"string\">`role_code`</span> <span class=\"built_in\">VARCHAR</span>(<span class=\"number\">100</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'角色id'</span>,</span><br><span class=\"line\">  <span class=\"string\">`menu_code`</span> <span class=\"built_in\">VARCHAR</span>(<span class=\"number\">100</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'菜单code'</span>,</span><br><span class=\"line\">  PRIMARY <span class=\"keyword\">KEY</span> (<span class=\"string\">`id`</span>)</span><br><span class=\"line\">) <span class=\"keyword\">ENGINE</span>=<span class=\"keyword\">INNODB</span> <span class=\"keyword\">DEFAULT</span> <span class=\"keyword\">CHARSET</span>=utf8 <span class=\"keyword\">COMMENT</span>=<span class=\"string\">'角色菜单关联表'</span>;</span><br></pre></td></tr></table></figure>\n<h4 id=\"初始化角色菜单关联表\"><a href=\"#初始化角色菜单关联表\" class=\"headerlink\" title=\"初始化角色菜单关联表\"></a>初始化角色菜单关联表</h4><figure class=\"highlight sql\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">1</span>, <span class=\"string\">'A0002'</span>, <span class=\"string\">'F001'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">2</span>, <span class=\"string\">'A0002'</span>, <span class=\"string\">'J001'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">3</span>, <span class=\"string\">'A0002'</span>, <span class=\"string\">'J001001'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">4</span>, <span class=\"string\">'A0002'</span>, <span class=\"string\">'N001'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">5</span>, <span class=\"string\">'A0002'</span>, <span class=\"string\">'N001001'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">6</span>, <span class=\"string\">'A0002'</span>, <span class=\"string\">'B001'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">7</span>, <span class=\"string\">'A0002'</span>, <span class=\"string\">'B001001'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">8</span>, <span class=\"string\">'A0002'</span>, <span class=\"string\">'B001002'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">9</span>, <span class=\"string\">'A0002'</span>, <span class=\"string\">'M001'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">10</span>, <span class=\"string\">'A0002'</span>, <span class=\"string\">'M001001'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">11</span>, <span class=\"string\">'A0002'</span>, <span class=\"string\">'M001002'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">12</span>, <span class=\"string\">'A0002'</span>, <span class=\"string\">'M001003'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">13</span>, <span class=\"string\">'B0001'</span>, <span class=\"string\">'F001'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">14</span>, <span class=\"string\">'B0001'</span>, <span class=\"string\">'M001'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">15</span>, <span class=\"string\">'B0001'</span>, <span class=\"string\">'M001001'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">16</span>, <span class=\"string\">'B0001'</span>, <span class=\"string\">'M001002'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">17</span>, <span class=\"string\">'B0001'</span>, <span class=\"string\">'M001003'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">18</span>, <span class=\"string\">'C0001'</span>, <span class=\"string\">'F001'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">19</span>, <span class=\"string\">'C0001'</span>, <span class=\"string\">'M001'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">20</span>, <span class=\"string\">'C0001'</span>, <span class=\"string\">'M001001'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">21</span>, <span class=\"string\">'C0001'</span>, <span class=\"string\">'M001002'</span>);</span><br><span class=\"line\"><span class=\"keyword\">INSERT</span> <span class=\"keyword\">INTO</span> <span class=\"string\">`c_role_menu`</span> <span class=\"keyword\">VALUES</span> (<span class=\"number\">22</span>, <span class=\"string\">'C0001'</span>, <span class=\"string\">'M001003'</span>);</span><br></pre></td></tr></table></figure>\n<p>你一定会发现，关联表里并没有超级管理员的信息，因为超级管理员拥有所有菜单的权限，所以我们只需要在查询时判断一下，如果是超级管理员我们就查询所有菜单就好啦，这也是个小技巧~</p>\n<h2 id=\"接口\"><a href=\"#接口\" class=\"headerlink\" title=\"接口\"></a>接口</h2><h3 id=\"CMenuServiceImpl\"><a href=\"#CMenuServiceImpl\" class=\"headerlink\" title=\"CMenuServiceImpl\"></a>CMenuServiceImpl</h3><p>在我们的菜单接口实现类里，我们完成一个接受角色code的方法。<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> CMenu <span class=\"title\">menuTree</span><span class=\"params\">(String roleCode)</span> </span>&#123;</span><br><span class=\"line\">    List&lt;CMenu&gt; menulist = cmenuMapper.findByRoleCode(roleCode);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> parentMenu(menulist);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>parentMenu()方法就是我们之前完成的递归方法的入口。</p>\n<h2 id=\"xml\"><a href=\"#xml\" class=\"headerlink\" title=\"xml\"></a>xml</h2><figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!-- 根据权限查询菜单 --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">select</span> <span class=\"attr\">id</span>=<span class=\"string\">\"findByRoleCode\"</span> <span class=\"attr\">resultType</span>=<span class=\"string\">\"com.datas.manager.core.entity.CMenu\"</span>&gt;</span></span><br><span class=\"line\">    select t.id, t.code, t.fathercode, t.name, t.menu_url AS menuUrl,</span><br><span class=\"line\">        t.menu_image AS menuImage, t.level, t.sort, t.iscancel, t.type, t.isleaf</span><br><span class=\"line\">        from c_menu t</span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">where</span>&gt;</span></span><br><span class=\"line\">        1 = 1</span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">if</span> <span class=\"attr\">test</span>=<span class=\"string\">\" roleCode != 'A0001'\"</span>&gt;</span></span><br><span class=\"line\">            AND code IN (select menu_code from c_role_menu a where role_code = #&#123;roleCode&#125;)</span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">if</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">where</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">select</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>这样，我们就完成根据不同角色权限生成菜单树，这些都是准备工作，下一篇我们将完成初始化加载这些菜单，慢慢就会完成登录功能了~</p>\n","categories":["Springboot"],"tags":[]},{"title":"Springboot 定时器用法","url":"http://ilovenorth.cn/2018/04/20/Springboot-定时器用法/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>顾名思义，定时器的意思就是每隔固定时间就执行一次的方法。</p>\n<h2 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h2><h3 id=\"1-开关\"><a href=\"#1-开关\" class=\"headerlink\" title=\"1.开关\"></a>1.开关</h3><p>我们都知道 springboot 有一个自己的入口，就是@SpringBootApplication，我们的第一步，当然就是在启动类上打开定时器开关：@EnableScheduling，我们点开这个注解就会看到，在注释里，就已经告诉我该如何使用啦。因为太长，就不铺在这里了。</p>\n<h3 id=\"2-创建一个定时器类\"><a href=\"#2-创建一个定时器类\" class=\"headerlink\" title=\"2.创建一个定时器类\"></a>2.创建一个定时器类</h3><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Component</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DemoScheduler</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> Logger logger = LoggerFactory.getLogger(<span class=\"keyword\">this</span>.getClass());</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"meta\">@Scheduled</span>(cron = <span class=\"string\">\"0/10 * * * * ?\"</span>)</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">createtable</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        logger.info(<span class=\"string\">\"10秒一次定时器！\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这个方法的意思就是每10秒打印一次日志。</p>\n<h3 id=\"3-注解详解\"><a href=\"#3-注解详解\" class=\"headerlink\" title=\"3.注解详解\"></a>3.注解详解</h3><h4 id=\"Component\"><a href=\"#Component\" class=\"headerlink\" title=\"@Component\"></a>@Component</h4><p>@Component注解，我们都不陌生，就是将这个类作为组件扫描到spring容器中，这样我们就可以通过类路径扫描自动发现这个组件了。</p>\n<h4 id=\"Scheduled\"><a href=\"#Scheduled\" class=\"headerlink\" title=\"@Scheduled\"></a>@Scheduled</h4><p>@Scheduled 就是定时器的核心注解。<br>源码注释上是这么说的，简单翻译一下：<br>一个用来标记要安排的方法的注释(翻译的不是太好..嘿嘿就是一个注释，用来标记要安排定时的方法)。 必须指定 cron(),fixedDelay()或fixedRate()属性中的一个。</p>\n<p>注释的方法不能有任何参数。这是方法通常会有一个void返回类型; 如果不是，则通过调度程序调用时，返回的值将被忽略。也就是说被安排的方法是不期望有返回值的，即使有也会被忽略。</p>\n<p>此注解可以用作元注解以创建具有属性覆盖的自定义组合批注。<br>我们看一下这个注解的源码。<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Target</span>(&#123;ElementType.METHOD, ElementType.ANNOTATION_TYPE&#125;)  </span><br><span class=\"line\"><span class=\"meta\">@Retention</span>(RetentionPolicy.RUNTIME)  </span><br><span class=\"line\"><span class=\"meta\">@Documented</span>  </span><br><span class=\"line\"><span class=\"meta\">@Repeatable</span>(Schedules<span class=\"class\">.<span class=\"keyword\">class</span>)  </span></span><br><span class=\"line\"><span class=\"class\"><span class=\"title\">public</span> @<span class=\"title\">interface</span> <span class=\"title\">Scheduled</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\">String <span class=\"title\">cron</span><span class=\"params\">()</span> <span class=\"keyword\">default</span> \"\"</span>;  </span><br><span class=\"line\">  </span><br><span class=\"line\">    <span class=\"function\">String <span class=\"title\">zone</span><span class=\"params\">()</span> <span class=\"keyword\">default</span> \"\"</span>;  </span><br><span class=\"line\">  </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">long</span> <span class=\"title\">fixedDelay</span><span class=\"params\">()</span> <span class=\"keyword\">default</span> -1L</span>;  </span><br><span class=\"line\">  </span><br><span class=\"line\">    <span class=\"function\">String <span class=\"title\">fixedDelayString</span><span class=\"params\">()</span> <span class=\"keyword\">default</span> \"\"</span>;  </span><br><span class=\"line\">  </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">long</span> <span class=\"title\">fixedRate</span><span class=\"params\">()</span> <span class=\"keyword\">default</span> -1L</span>;  </span><br><span class=\"line\">  </span><br><span class=\"line\">    <span class=\"function\">String <span class=\"title\">fixedRateString</span><span class=\"params\">()</span> <span class=\"keyword\">default</span> \"\"</span>;  </span><br><span class=\"line\">  </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">long</span> <span class=\"title\">initialDelay</span><span class=\"params\">()</span> <span class=\"keyword\">default</span> -1L</span>;  </span><br><span class=\"line\">  </span><br><span class=\"line\">    <span class=\"function\">String <span class=\"title\">initialDelayString</span><span class=\"params\">()</span> <span class=\"keyword\">default</span> \"\"</span>;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>这些属性我们一个个说。</p>\n<h5 id=\"1-cron\"><a href=\"#1-cron\" class=\"headerlink\" title=\" 1.cron \"></a><strong> 1.cron </strong></h5><p>这个是比较常用的属性。一种类似于cron的表达方式。可以作为一个触发器，时间包括时分秒月日年星期等，格式为”0*…MON-FRI”。<br>“星号” 表示为占位符，从左至右：秒分时日月年，最后一位则表示星期。</p>\n<h5 id=\"2-zone\"><a href=\"#2-zone\" class=\"headerlink\" title=\" 2.zone \"></a><strong> 2.zone </strong></h5><p>将被cron表达式解析的时区。 默认情况下，此属性是空字符串（即使用服务器的本地时区将）。</p>\n<h5 id=\"3-fixedDelay\"><a href=\"#3-fixedDelay\" class=\"headerlink\" title=\" 3.fixedDelay \"></a><strong> 3.fixedDelay </strong></h5><p>以毫秒为时间间隔。为Long型</p>\n<h5 id=\"4-fixedDelayString\"><a href=\"#4-fixedDelayString\" class=\"headerlink\" title=\" 4.fixedDelayString \"></a><strong> 4.fixedDelayString </strong></h5><p>以毫秒为时间间隔。为String类型</p>\n<h5 id=\"5-fixedRate\"><a href=\"#5-fixedRate\" class=\"headerlink\" title=\" 5.fixedRate \"></a><strong> 5.fixedRate </strong></h5><p>在调用之间以毫秒为单位,执行带有固定时间段的注释方法。为Long型</p>\n<h5 id=\"6-fixedRateString\"><a href=\"#6-fixedRateString\" class=\"headerlink\" title=\" 6.fixedRateString \"></a><strong> 6.fixedRateString </strong></h5><p>在调用之间以毫秒为单位,执行带有固定时间段的注释方法。为String类型</p>\n<h5 id=\"7-initialDelay\"><a href=\"#7-initialDelay\" class=\"headerlink\" title=\" 7.initialDelay \"></a><strong> 7.initialDelay </strong></h5><p>第一次执行fixedRate()或fixedDelay()任务之前要延迟的毫秒数。为Long型</p>\n<h5 id=\"8-initialDelayString\"><a href=\"#8-initialDelayString\" class=\"headerlink\" title=\" 8.initialDelayString \"></a><strong> 8.initialDelayString </strong></h5><p>第一次执行fixedRate()或fixedDelay()任务之前要延迟的毫秒数。为String类型</p>\n<p>一般我们常用的就是 cron 属性。但是cron表达式我们一般也不是很了解 -。-、<br>在这里我给大家推荐一个网站 可以在线生成cron表达式，很方便~<br>网址：<a href=\"http://cron.qqe2.com/\" target=\"_blank\" rel=\"noopener\">在线cron表达式生成器</a></p>\n","categories":["Springboot"],"tags":[]},{"title":"Util:Springboot类beans获取","url":"http://ilovenorth.cn/2018/04/19/Util-Springboot类beans获取/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<p>在项目中看到这个工具类，感觉很神奇，决定记录下来，并好好分析一下是如何实现的。<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Component</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ApplicationContextUtil</span> <span class=\"keyword\">implements</span> <span class=\"title\">ApplicationContextAware</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 上下文对象实例</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> ApplicationContext applicationContext;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setApplicationContext</span><span class=\"params\">(ApplicationContext applicationContext)</span> <span class=\"keyword\">throws</span> BeansException </span>&#123;</span><br><span class=\"line\">        ApplicationContextUtil.applicationContext = applicationContext;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 通过name获取Bean.</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> name</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@SuppressWarnings</span>(<span class=\"string\">\"unchecked\"</span>)</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> &lt;T&gt; <span class=\"function\">T <span class=\"title\">getBean</span><span class=\"params\">(String name)</span> </span>&#123;</span><br><span class=\"line\">        checkApplicationContext();</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (T) applicationContext.getBean(name);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 通过class获取Bean.</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> name</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span></span></span><br><span class=\"line\"><span class=\"comment\">     */</span>\t</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> &lt;T&gt; <span class=\"function\">T <span class=\"title\">getBean</span><span class=\"params\">(Class&lt;T&gt; clazz)</span> </span>&#123;</span><br><span class=\"line\">        checkApplicationContext();</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (T) applicationContext.getBean(clazz);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">cleanApplicationContext</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        applicationContext = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">checkApplicationContext</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (applicationContext == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalStateException(<span class=\"string\">\"applicaitonContext未注入\"</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h5 id=\"ApplicationContextAware\"><a href=\"#ApplicationContextAware\" class=\"headerlink\" title=\"ApplicationContextAware\"></a><strong>ApplicationContextAware</strong></h5><p>这里最引人注意的就要数这个接口了，我们点开去看看它的源码和注释。<br>大致翻译一下：任何希望接受到运行的 ApplicationContext 通知的对象都可以实现这个接口。比如，当一个对象需要访问一组 bean 时，实现这个接口是有意义的。<br>在这里它有一个小提示，就是如果你实现该接口的目的是引用bean并对其进行配置，这个目的是可取，比仅为查找某个 bean 要好得多~<br>在这个接口里就只有一个方法，我们看一下。<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">setApplicationContext</span><span class=\"params\">(ApplicationContext applicationContext)</span> <span class=\"keyword\">throws</span> BeansException</span>;</span><br></pre></td></tr></table></figure><br>这个方法就是用来设置ApplicationContext。通常，这个调用将用于初始化对象。<br>说白了，实现这个接口就是为了去获取 ApplicationContext 。<br>当我们获取到了ApplicationContext，就可以使用里面的方法。打上断点我们就会知道，这个工具类在springboot启动初始化加载后，就会把ApplicationContext对象注入到我们的工具类中。因为我们的实例和方法都是static修饰的，所以在外部依然可以获取到指定Bean的实例。</p>\n<p>在单元测试的时候，这个工具类尤其好用，或者在我们想要初始化某些自定义的数据的时候。<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">CMenuService cMenuService = ApplicationContextUtil.getBean(CMenuServiceImpl<span class=\"class\">.<span class=\"keyword\">class</span>)</span>;</span><br><span class=\"line\">CMenu cMenu = cMenuService.findAll();</span><br></pre></td></tr></table></figure><br>像这样，我们就可以在外部使用这个功能模块的接口了。</p>\n","categories":["Utils"],"tags":[]},{"title":"springboot java递归生成菜单树","url":"http://ilovenorth.cn/2018/04/18/springboot-登录技巧/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<p>首先我们要准备数据.<br><figure class=\"highlight sql\"><figcaption><span>菜单表sql</span></figcaption><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> <span class=\"string\">`c_menu`</span> (</span><br><span class=\"line\">  <span class=\"string\">`id`</span> <span class=\"built_in\">BIGINT</span>(<span class=\"number\">20</span>) <span class=\"keyword\">NOT</span> <span class=\"literal\">NULL</span> AUTO_INCREMENT <span class=\"keyword\">COMMENT</span> <span class=\"string\">'主键'</span>,</span><br><span class=\"line\">  <span class=\"string\">`code`</span> <span class=\"built_in\">VARCHAR</span>(<span class=\"number\">10</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'编号'</span>,</span><br><span class=\"line\">  <span class=\"string\">`fathercode`</span> <span class=\"built_in\">VARCHAR</span>(<span class=\"number\">10</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"string\">'-1'</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'父类编号'</span>,</span><br><span class=\"line\">  <span class=\"string\">`name`</span> <span class=\"built_in\">VARCHAR</span>(<span class=\"number\">100</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'目录名称'</span>,</span><br><span class=\"line\">  <span class=\"string\">`menu_url`</span> <span class=\"built_in\">VARCHAR</span>(<span class=\"number\">200</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"string\">'#'</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'目录路径'</span>,</span><br><span class=\"line\">  <span class=\"string\">`menu_image`</span> <span class=\"built_in\">VARCHAR</span>(<span class=\"number\">200</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"string\">'#'</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'图片'</span>,</span><br><span class=\"line\">  <span class=\"string\">`level`</span> <span class=\"built_in\">INT</span>(<span class=\"number\">5</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"string\">'-1'</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'目录等级'</span>,</span><br><span class=\"line\">  <span class=\"string\">`sort`</span> <span class=\"built_in\">INT</span>(<span class=\"number\">5</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"string\">'0'</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'目录排序'</span>,</span><br><span class=\"line\">  <span class=\"string\">`isleaf`</span> <span class=\"built_in\">int</span>(<span class=\"number\">2</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'是否叶子 1是 0不是'</span>,</span><br><span class=\"line\">  <span class=\"string\">`iscancel`</span> <span class=\"built_in\">INT</span>(<span class=\"number\">2</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"string\">'0'</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'是否作废'</span>,</span><br><span class=\"line\">  <span class=\"string\">`type`</span> <span class=\"built_in\">INT</span>(<span class=\"number\">5</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"string\">'1'</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'类型'</span>,</span><br><span class=\"line\">  <span class=\"string\">`state`</span> <span class=\"built_in\">INT</span>(<span class=\"number\">5</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"string\">'1'</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'状态'</span>,</span><br><span class=\"line\">  <span class=\"string\">`remark`</span> <span class=\"built_in\">VARCHAR</span>(<span class=\"number\">200</span>) <span class=\"keyword\">DEFAULT</span> <span class=\"literal\">NULL</span> <span class=\"keyword\">COMMENT</span> <span class=\"string\">'备注'</span>,</span><br><span class=\"line\">  PRIMARY <span class=\"keyword\">KEY</span> (<span class=\"string\">`id`</span>)</span><br><span class=\"line\">) <span class=\"keyword\">ENGINE</span>=<span class=\"keyword\">INNODB</span> <span class=\"keyword\">DEFAULT</span> <span class=\"keyword\">CHARSET</span>=utf8 <span class=\"keyword\">COMMENT</span>=<span class=\"string\">'菜单目录表'</span>;</span><br></pre></td></tr></table></figure></p>\n<h6 id=\"叶子节点\"><a href=\"#叶子节点\" class=\"headerlink\" title=\" 叶子节点 \"></a><strong> 叶子节点 </strong></h6><p>我们一级菜单的fathercode为 #，二级菜单的fathercode指向一级菜单的code，多级菜单以此类推。在这里有一个重要的字段，就是 isleaf(是否为叶子节点)，这个字段就是作为递归查询时的条件。当一个目录被定义为叶子节点，也就是说这个目录下就没有叶子目录了。</p>\n<h6 id=\"准备工作\"><a href=\"#准备工作\" class=\"headerlink\" title=\" 准备工作 \"></a><strong> 准备工作 </strong></h6><p>我们要组装的数据格式是在菜单实体中组装一个菜单list，每一个list也就是对应着一个级别的菜单。<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">（菜单实体）      &#123;一级菜单list&#125;  &#123;二级菜单list&#125;</span><br><span class=\"line\">CMenu-list————---CMenu-list————---CMenu</span><br><span class=\"line\">               |\t       |--CMenu</span><br><span class=\"line\">               |\t       |--CMenu</span><br><span class=\"line\">               |</span><br><span class=\"line\">               |-CMenu-list————---CMenu</span><br><span class=\"line\">               \t\t       |--CMenu</span><br><span class=\"line\">               \t\t       |--CMenu</span><br></pre></td></tr></table></figure><br>基本的数据格式我们考虑好了之后，就可以开始完成功能了。</p>\n<h5 id=\"CMenu\"><a href=\"#CMenu\" class=\"headerlink\" title=\" CMenu \"></a><strong> CMenu </strong></h5><p>在CMenu实体中，加上一个初始化的list和初始化是否是叶子节点的构造方法。<br><figure class=\"highlight java\"><figcaption><span>list属性</span></figcaption><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">CMenu</span><span class=\"params\">(Integer isleaf)</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">this</span>.isleaf = isleaf;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">private</span> List&lt;CMenu&gt; menus = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\"><span class=\"comment\">//对应的get/set方法</span></span><br></pre></td></tr></table></figure></p>\n<h5 id=\"CMenuServiceImpl\"><a href=\"#CMenuServiceImpl\" class=\"headerlink\" title=\" CMenuServiceImpl \"></a><strong> CMenuServiceImpl </strong></h5><p>我们查询出所有的菜单。<br><figure class=\"highlight java\"><figcaption><span>CMenu实现类</span></figcaption><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> CMenu <span class=\"title\">findAll</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">\tList&lt;CMenu&gt; menulist = cmenuMapper.findAll();</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> parentMenu(menulist);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure><br>parentMenun()方法就是进入我们递归的方法啦。<br><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//菜单树</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> CMenu <span class=\"title\">parentMenu</span><span class=\"params\">(List&lt;CMenu&gt; menulist)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//初始化菜单的子节点</span></span><br><span class=\"line\">    CMenu parentMenu = <span class=\"keyword\">new</span> CMenu(<span class=\"number\">0</span>);</span><br><span class=\"line\">    <span class=\"comment\">//初始父亲节点为 -1，为了查出一级菜单</span></span><br><span class=\"line\">    parentMenu.setMenus(menus(<span class=\"string\">\"-1\"</span>, listtomap(menulist)));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> parentMenu;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//组装map</span></span><br><span class=\"line\"><span class=\"keyword\">private</span> Map&lt;String, List&lt;CMenu&gt;&gt; listtomap(List&lt;CMenu&gt; menulist) &#123;</span><br><span class=\"line\">    Map&lt;String, List&lt;CMenu&gt;&gt; menuMap = <span class=\"keyword\">new</span> HashMap&lt;&gt;();</span><br><span class=\"line\">    <span class=\"comment\">//组装map key:fatherCode value:旗下的子菜单</span></span><br><span class=\"line\">    <span class=\"comment\">//可以省略一次循环</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (CMenu cMenu : menulist) &#123;</span><br><span class=\"line\">        List&lt;CMenu&gt; menus = menuMap.get(cMenu.getFathercode());</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (menus == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            menus = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        menus.add(cMenu);</span><br><span class=\"line\">        menuMap.put(cMenu.getFathercode(), menus);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> menuMap;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//递归方法</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> List&lt;CMenu&gt; <span class=\"title\">menus</span><span class=\"params\">(String fatherCode, Map&lt;String, List&lt;CMenu&gt;&gt; menuMap)</span> </span>&#123;</span><br><span class=\"line\">    List&lt;CMenu&gt; childlist = menuMap.get(fatherCode);</span><br><span class=\"line\">    <span class=\"comment\">//退出递归的方法，不然就会死循环啦</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (childlist == <span class=\"keyword\">null</span> || childlist.size() == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">//根据父类id查询旗下子类</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (CMenu cMenu : childlist) &#123;</span><br><span class=\"line\">        <span class=\"comment\">//如果是叶子节点 则退出循环</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (cMenu == <span class=\"keyword\">null</span> || cMenu.getIsleaf() == <span class=\"keyword\">null</span> || cMenu.getIsleaf() == <span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//如果不是 继续递归</span></span><br><span class=\"line\">        cMenu.setMenus(menus(cMenu.getCode(), menuMap));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> childlist;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>生成菜单树这是第一步，下一篇是完成权限登陆下的菜单初始化，最终我们要完成一个完成的登录功能~</p>\n","categories":["Springboot"],"tags":[]},{"title":"test分类","url":"http://ilovenorth.cn/2018/04/16/test分类/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<p>难受 。。</p>\n","categories":["test"],"tags":["test"]},{"title":"JDBC与MySQL 因“CST”时区协商误解导致时间差了14或13小时","url":"http://ilovenorth.cn/2018/04/16/JDBC-与-MySQL-因-“CST”-时区协商误解导致时间差了-14-或-13-小时/","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><meta name=\"referrer\" content=\"no-referrer\">\n\n<h5 id=\"问题描述\"><a href=\"#问题描述\" class=\"headerlink\" title=\"问题描述\"></a>问题描述</h5><p>新项目是用的springboot+mybatis+mysql 6.0.6版本的驱动包来搭建的，在使用的过程中遇到以下2个问题</p>\n<p>1.从mysql取的的数据日期时间，与真实的时间往后错乱了14个小时。</p>\n<p>2.springboot jason序例日期时发现与真实的时间向前推了8小时。</p>\n<p>第一个问题解决的方案有很多 -。-，造成这个问题原因主要是因为mysql 6.x以上版本的驱动包，连接字符串默认时区不是东八区造成的。。</p>\n<p>1.如果你有所在库的权限，或者你们的DBA不是个懒蛋。。可以直接用sql去调~<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">SET GLOBAL time_zone = &apos;+8:00&apos;;</span><br><span class=\"line\">SET time_zone = &apos;+8:00&apos;;</span><br><span class=\"line\">FLUSH PRIVILEGES</span><br></pre></td></tr></table></figure></p>\n<p>2.在连接字符串上加上serverTimezone=Asia/Shanghai<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">jdbc:mysql://127.0.0.1:3306/test?serverTimezone=Asia/Shanghai</span><br><span class=\"line\">    </span><br><span class=\"line\">mysql 5.x的版本不存在的这个问题，所以遇到这个问题，可以选择用上面的方案解</span><br><span class=\"line\">决，也可以用mysql 5.x的版本驱动包解决。当然降版本不是好办法哦~</span><br></pre></td></tr></table></figure><br>第二个问题应该是序列化的原因，可能springboot自身的小bug吧~<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">在application.properties 配置文件里添序列化时区配置：spring.jackson.time-zone=GMT+8</span><br></pre></td></tr></table></figure> </p>\n<p>这里有位大佬对原因进行了剖析，感兴趣的朋友可以看一下~<br><a href=\"https://juejin.im/post/5902e087da2f60005df05c3d?utm_source=tuicool&amp;utm_medium=referral\" target=\"_blank\" rel=\"noopener\">原因</a></p>\n","categories":["Exception"],"tags":[]},{"title":"","url":"http://ilovenorth.cn/baidu_verify_i3urv8Ppjr.html","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script>i3urv8Ppjr","categories":[],"tags":[]},{"title":"About me","url":"http://ilovenorth.cn/about/index.html","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><blockquote>\n<p>It’ s a right thing to do, and I’ m tired of waiting someone else to do it for me.<br>———— Elon Musk</p>\n</blockquote>\n<p>欢迎你来到我的博客.<br><br>我来自北方，现在在北京.<br><br>大数据开发工程师.<br><br><br></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Name: MurasakiSeiFu</span><br><span class=\"line\">Github: https://github.com/jerryc127</span><br><span class=\"line\">Blog: http://ilovenorth.life/</span><br></pre></td></tr></table></figure>\n","categories":[],"tags":[]},{"title":"友情鏈接","url":"http://ilovenorth.cn/link/index.html","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script>","categories":[],"tags":[]},{"title":"分类","url":"http://ilovenorth.cn/categories/index.html","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script>","categories":[],"tags":[]},{"title":"","url":"http://ilovenorth.cn/css/personal-style.css","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script>html.page-home {\n    position: absolute;\n    top: 0;\n    left: 0;\n    right: 0;\n    bottom: 0;\n    background-image: url('../images/back.jpg');\n    /*background-image: url('https://ws3.sinaimg.cn/large/006tNc79ly1g283m2p70vj318y0u0kjt.jpg');*/\n    background-color: transparent;\n    background-size: cover;\n    background-position: center center;\n    background-repeat: no-repeat;\n\n    /*background: linear-gradient( #1abc9c, transparent), linear-gradient( 90deg, skyblue, transparent), linear-gradient( -90deg, coral, transparent);*/\n    /*background-blend-mode: screen;*/\n\n    /*background: linear-gradient(to left, #5f2c82, #49a09d);*/\n}\n\n\n","categories":[],"tags":[]},{"title":"me","url":"http://ilovenorth.cn/me/index.html","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script>","categories":[],"tags":[]},{"title":"search","url":"http://ilovenorth.cn/search/index.html","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script>","categories":[],"tags":[]},{"title":"project","url":"http://ilovenorth.cn/project/index.html","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script>","categories":[],"tags":[]},{"title":"標籤","url":"http://ilovenorth.cn/tags/index.html","content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script>","categories":[],"tags":[]}]